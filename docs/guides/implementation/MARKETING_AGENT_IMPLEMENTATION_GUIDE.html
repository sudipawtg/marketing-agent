<!DOCTYPE html><html><head>
<title>MARKETING_AGENT_IMPLEMENTATION_GUIDE.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/*

Arduino® Light Theme - Stefania Mellai <s.mellai@arduino.cc>

*/

.hljs {
  display: block;
  overflow-x: auto;
  padding: 0.5em;
  background: #FFFFFF;
}

.hljs,
.hljs-subst {
  color: #434f54;
}

.hljs-keyword,
.hljs-attribute,
.hljs-selector-tag,
.hljs-doctag,
.hljs-name {
  color: #00979D;
}

.hljs-built_in,
.hljs-literal,
.hljs-bullet,
.hljs-code,
.hljs-addition {
  color: #D35400;
}

.hljs-regexp,
.hljs-symbol,
.hljs-variable,
.hljs-template-variable,
.hljs-link,
.hljs-selector-attr,
.hljs-selector-pseudo {
  color: #00979D;
}

.hljs-type,
.hljs-string,
.hljs-selector-id,
.hljs-selector-class,
.hljs-quote,
.hljs-template-tag,
.hljs-deletion {
  color: #005C5F;
}

.hljs-title,
.hljs-section {
  color: #880000;
  font-weight: bold;
}

.hljs-comment {
  color: rgba(149,165,166,.8);
}

.hljs-meta-keyword {
  color: #728E00;
}

.hljs-meta {
  color: #434f54;
}

.hljs-emphasis {
  font-style: italic;
}

.hljs-strong {
  font-weight: bold;
}

.hljs-function {
  color: #728E00;
}

.hljs-number {
  color: #8A7B52;  
}

</style>

<style>
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family:   "HelveticaNeue-Light", sans-serif, "宋体","Segoe WPC", "Segoe UI", "SFUIText-Light","Droid Sans Fallback";
	font-size: 18px;
	padding: 0 12px;
	line-height: 1.6;
	word-wrap: break-word;
	color: #333333;
}

.content-wrapper{
	max-width: 860px;
    margin: 0 auto;
    padding: 0 30px;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}


body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	color: #4080D0;
	text-decoration: none;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom: 1px solid #eee;
}


h2{
	padding-bottom: .3em;
    font-size: 2em;
    line-height: 1.225;
    border-bottom: 1px solid #eee;
}

h3{
	font-size: 1.75em;
    line-height: 1.225;
}

h1, h2, h3 {
	font-weight: bold;
}

h1 code,
h2 code,
h3 code,
h4 code,
h5 code,
h6 code {
	font-size: inherit;
	line-height: auto;
}

a:hover {
	color: #4080D0;
	text-decoration: underline;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left: 5px solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 14px;
	line-height: 19px;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

.mac code {
	font-size: 12px;
	line-height: 18px;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

/** Theming */

.vscode-light,
.vscode-light pre code {
	color: rgb(30, 30, 30);
}

.vscode-dark,
.vscode-dark pre code {
	color: #DDD;
}

.vscode-high-contrast,
.vscode-high-contrast pre code {
	color: white;
}

.vscode-light code {
	color: #A31515;
}

.vscode-dark code {
	color: #D7BA7D;
}

.vscode-light pre:not(.hljs),
.vscode-light code > div {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre:not(.hljs),
.vscode-dark code > div {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre:not(.hljs),
.vscode-high-contrast code > div {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

.vscode-light blockquote,
.vscode-dark blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.vscode-high-contrast blockquote {
	background: transparent;
	border-color: #fff;
}
</style>

<style>
pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

.table-of-contents li{
	list-style-type: initial;
}
</style>

<style>
@font-face{font-family:KaTeX_AMS;font-style:normal;font-weight:400;src:url(fonts/KaTeX_AMS-Regular.woff2) format("woff2"),url(fonts/KaTeX_AMS-Regular.woff) format("woff"),url(fonts/KaTeX_AMS-Regular.ttf) format("truetype")}@font-face{font-family:KaTeX_Caligraphic;font-style:normal;font-weight:700;src:url(fonts/KaTeX_Caligraphic-Bold.woff2) format("woff2"),url(fonts/KaTeX_Caligraphic-Bold.woff) format("woff"),url(fonts/KaTeX_Caligraphic-Bold.ttf) format("truetype")}@font-face{font-family:KaTeX_Caligraphic;font-style:normal;font-weight:400;src:url(fonts/KaTeX_Caligraphic-Regular.woff2) format("woff2"),url(fonts/KaTeX_Caligraphic-Regular.woff) format("woff"),url(fonts/KaTeX_Caligraphic-Regular.ttf) format("truetype")}@font-face{font-family:KaTeX_Fraktur;font-style:normal;font-weight:700;src:url(fonts/KaTeX_Fraktur-Bold.woff2) format("woff2"),url(fonts/KaTeX_Fraktur-Bold.woff) format("woff"),url(fonts/KaTeX_Fraktur-Bold.ttf) format("truetype")}@font-face{font-family:KaTeX_Fraktur;font-style:normal;font-weight:400;src:url(fonts/KaTeX_Fraktur-Regular.woff2) format("woff2"),url(fonts/KaTeX_Fraktur-Regular.woff) format("woff"),url(fonts/KaTeX_Fraktur-Regular.ttf) format("truetype")}@font-face{font-family:KaTeX_Main;font-style:normal;font-weight:700;src:url(fonts/KaTeX_Main-Bold.woff2) format("woff2"),url(fonts/KaTeX_Main-Bold.woff) format("woff"),url(fonts/KaTeX_Main-Bold.ttf) format("truetype")}@font-face{font-family:KaTeX_Main;font-style:italic;font-weight:700;src:url(fonts/KaTeX_Main-BoldItalic.woff2) format("woff2"),url(fonts/KaTeX_Main-BoldItalic.woff) format("woff"),url(fonts/KaTeX_Main-BoldItalic.ttf) format("truetype")}@font-face{font-family:KaTeX_Main;font-style:italic;font-weight:400;src:url(fonts/KaTeX_Main-Italic.woff2) format("woff2"),url(fonts/KaTeX_Main-Italic.woff) format("woff"),url(fonts/KaTeX_Main-Italic.ttf) format("truetype")}@font-face{font-family:KaTeX_Main;font-style:normal;font-weight:400;src:url(fonts/KaTeX_Main-Regular.woff2) format("woff2"),url(fonts/KaTeX_Main-Regular.woff) format("woff"),url(fonts/KaTeX_Main-Regular.ttf) format("truetype")}@font-face{font-family:KaTeX_Math;font-style:italic;font-weight:700;src:url(fonts/KaTeX_Math-BoldItalic.woff2) format("woff2"),url(fonts/KaTeX_Math-BoldItalic.woff) format("woff"),url(fonts/KaTeX_Math-BoldItalic.ttf) format("truetype")}@font-face{font-family:KaTeX_Math;font-style:italic;font-weight:400;src:url(fonts/KaTeX_Math-Italic.woff2) format("woff2"),url(fonts/KaTeX_Math-Italic.woff) format("woff"),url(fonts/KaTeX_Math-Italic.ttf) format("truetype")}@font-face{font-family:"KaTeX_SansSerif";font-style:normal;font-weight:700;src:url(fonts/KaTeX_SansSerif-Bold.woff2) format("woff2"),url(fonts/KaTeX_SansSerif-Bold.woff) format("woff"),url(fonts/KaTeX_SansSerif-Bold.ttf) format("truetype")}@font-face{font-family:"KaTeX_SansSerif";font-style:italic;font-weight:400;src:url(fonts/KaTeX_SansSerif-Italic.woff2) format("woff2"),url(fonts/KaTeX_SansSerif-Italic.woff) format("woff"),url(fonts/KaTeX_SansSerif-Italic.ttf) format("truetype")}@font-face{font-family:"KaTeX_SansSerif";font-style:normal;font-weight:400;src:url(fonts/KaTeX_SansSerif-Regular.woff2) format("woff2"),url(fonts/KaTeX_SansSerif-Regular.woff) format("woff"),url(fonts/KaTeX_SansSerif-Regular.ttf) format("truetype")}@font-face{font-family:KaTeX_Script;font-style:normal;font-weight:400;src:url(fonts/KaTeX_Script-Regular.woff2) format("woff2"),url(fonts/KaTeX_Script-Regular.woff) format("woff"),url(fonts/KaTeX_Script-Regular.ttf) format("truetype")}@font-face{font-family:KaTeX_Size1;font-style:normal;font-weight:400;src:url(fonts/KaTeX_Size1-Regular.woff2) format("woff2"),url(fonts/KaTeX_Size1-Regular.woff) format("woff"),url(fonts/KaTeX_Size1-Regular.ttf) format("truetype")}@font-face{font-family:KaTeX_Size2;font-style:normal;font-weight:400;src:url(fonts/KaTeX_Size2-Regular.woff2) format("woff2"),url(fonts/KaTeX_Size2-Regular.woff) format("woff"),url(fonts/KaTeX_Size2-Regular.ttf) format("truetype")}@font-face{font-family:KaTeX_Size3;font-style:normal;font-weight:400;src:url(fonts/KaTeX_Size3-Regular.woff2) format("woff2"),url(fonts/KaTeX_Size3-Regular.woff) format("woff"),url(fonts/KaTeX_Size3-Regular.ttf) format("truetype")}@font-face{font-family:KaTeX_Size4;font-style:normal;font-weight:400;src:url(fonts/KaTeX_Size4-Regular.woff2) format("woff2"),url(fonts/KaTeX_Size4-Regular.woff) format("woff"),url(fonts/KaTeX_Size4-Regular.ttf) format("truetype")}@font-face{font-family:KaTeX_Typewriter;font-style:normal;font-weight:400;src:url(fonts/KaTeX_Typewriter-Regular.woff2) format("woff2"),url(fonts/KaTeX_Typewriter-Regular.woff) format("woff"),url(fonts/KaTeX_Typewriter-Regular.ttf) format("truetype")}.katex{text-rendering:auto;font:normal 1.21em KaTeX_Main,Times New Roman,serif;line-height:1.2;text-indent:0}.katex *{-ms-high-contrast-adjust:none!important;border-color:currentColor}.katex .katex-version:after{content:"0.16.2"}.katex .katex-mathml{clip:rect(1px,1px,1px,1px);border:0;height:1px;overflow:hidden;padding:0;position:absolute;width:1px}.katex .katex-html>.newline{display:block}.katex .base{position:relative;white-space:nowrap;width:-webkit-min-content;width:-moz-min-content;width:min-content}.katex .base,.katex .strut{display:inline-block}.katex .textbf{font-weight:700}.katex .textit{font-style:italic}.katex .textrm{font-family:KaTeX_Main}.katex .textsf{font-family:KaTeX_SansSerif}.katex .texttt{font-family:KaTeX_Typewriter}.katex .mathnormal{font-family:KaTeX_Math;font-style:italic}.katex .mathit{font-family:KaTeX_Main;font-style:italic}.katex .mathrm{font-style:normal}.katex .mathbf{font-family:KaTeX_Main;font-weight:700}.katex .boldsymbol{font-family:KaTeX_Math;font-style:italic;font-weight:700}.katex .amsrm,.katex .mathbb,.katex .textbb{font-family:KaTeX_AMS}.katex .mathcal{font-family:KaTeX_Caligraphic}.katex .mathfrak,.katex .textfrak{font-family:KaTeX_Fraktur}.katex .mathtt{font-family:KaTeX_Typewriter}.katex .mathscr,.katex .textscr{font-family:KaTeX_Script}.katex .mathsf,.katex .textsf{font-family:KaTeX_SansSerif}.katex .mathboldsf,.katex .textboldsf{font-family:KaTeX_SansSerif;font-weight:700}.katex .mathitsf,.katex .textitsf{font-family:KaTeX_SansSerif;font-style:italic}.katex .mainrm{font-family:KaTeX_Main;font-style:normal}.katex .vlist-t{border-collapse:collapse;display:inline-table;table-layout:fixed}.katex .vlist-r{display:table-row}.katex .vlist{display:table-cell;position:relative;vertical-align:bottom}.katex .vlist>span{display:block;height:0;position:relative}.katex .vlist>span>span{display:inline-block}.katex .vlist>span>.pstrut{overflow:hidden;width:0}.katex .vlist-t2{margin-right:-2px}.katex .vlist-s{display:table-cell;font-size:1px;min-width:2px;vertical-align:bottom;width:2px}.katex .vbox{align-items:baseline;display:inline-flex;flex-direction:column}.katex .hbox{width:100%}.katex .hbox,.katex .thinbox{display:inline-flex;flex-direction:row}.katex .thinbox{max-width:0;width:0}.katex .msupsub{text-align:left}.katex .mfrac>span>span{text-align:center}.katex .mfrac .frac-line{border-bottom-style:solid;display:inline-block;width:100%}.katex .hdashline,.katex .hline,.katex .mfrac .frac-line,.katex .overline .overline-line,.katex .rule,.katex .underline .underline-line{min-height:1px}.katex .mspace{display:inline-block}.katex .clap,.katex .llap,.katex .rlap{position:relative;width:0}.katex .clap>.inner,.katex .llap>.inner,.katex .rlap>.inner{position:absolute}.katex .clap>.fix,.katex .llap>.fix,.katex .rlap>.fix{display:inline-block}.katex .llap>.inner{right:0}.katex .clap>.inner,.katex .rlap>.inner{left:0}.katex .clap>.inner>span{margin-left:-50%;margin-right:50%}.katex .rule{border:0 solid;display:inline-block;position:relative}.katex .hline,.katex .overline .overline-line,.katex .underline .underline-line{border-bottom-style:solid;display:inline-block;width:100%}.katex .hdashline{border-bottom-style:dashed;display:inline-block;width:100%}.katex .sqrt>.root{margin-left:.27777778em;margin-right:-.55555556em}.katex .fontsize-ensurer.reset-size1.size1,.katex .sizing.reset-size1.size1{font-size:1em}.katex .fontsize-ensurer.reset-size1.size2,.katex .sizing.reset-size1.size2{font-size:1.2em}.katex .fontsize-ensurer.reset-size1.size3,.katex .sizing.reset-size1.size3{font-size:1.4em}.katex .fontsize-ensurer.reset-size1.size4,.katex .sizing.reset-size1.size4{font-size:1.6em}.katex .fontsize-ensurer.reset-size1.size5,.katex .sizing.reset-size1.size5{font-size:1.8em}.katex .fontsize-ensurer.reset-size1.size6,.katex .sizing.reset-size1.size6{font-size:2em}.katex .fontsize-ensurer.reset-size1.size7,.katex .sizing.reset-size1.size7{font-size:2.4em}.katex .fontsize-ensurer.reset-size1.size8,.katex .sizing.reset-size1.size8{font-size:2.88em}.katex .fontsize-ensurer.reset-size1.size9,.katex .sizing.reset-size1.size9{font-size:3.456em}.katex .fontsize-ensurer.reset-size1.size10,.katex .sizing.reset-size1.size10{font-size:4.148em}.katex .fontsize-ensurer.reset-size1.size11,.katex .sizing.reset-size1.size11{font-size:4.976em}.katex .fontsize-ensurer.reset-size2.size1,.katex .sizing.reset-size2.size1{font-size:.83333333em}.katex .fontsize-ensurer.reset-size2.size2,.katex .sizing.reset-size2.size2{font-size:1em}.katex .fontsize-ensurer.reset-size2.size3,.katex .sizing.reset-size2.size3{font-size:1.16666667em}.katex .fontsize-ensurer.reset-size2.size4,.katex .sizing.reset-size2.size4{font-size:1.33333333em}.katex .fontsize-ensurer.reset-size2.size5,.katex .sizing.reset-size2.size5{font-size:1.5em}.katex .fontsize-ensurer.reset-size2.size6,.katex .sizing.reset-size2.size6{font-size:1.66666667em}.katex .fontsize-ensurer.reset-size2.size7,.katex .sizing.reset-size2.size7{font-size:2em}.katex .fontsize-ensurer.reset-size2.size8,.katex .sizing.reset-size2.size8{font-size:2.4em}.katex .fontsize-ensurer.reset-size2.size9,.katex .sizing.reset-size2.size9{font-size:2.88em}.katex .fontsize-ensurer.reset-size2.size10,.katex .sizing.reset-size2.size10{font-size:3.45666667em}.katex .fontsize-ensurer.reset-size2.size11,.katex .sizing.reset-size2.size11{font-size:4.14666667em}.katex .fontsize-ensurer.reset-size3.size1,.katex .sizing.reset-size3.size1{font-size:.71428571em}.katex .fontsize-ensurer.reset-size3.size2,.katex .sizing.reset-size3.size2{font-size:.85714286em}.katex .fontsize-ensurer.reset-size3.size3,.katex .sizing.reset-size3.size3{font-size:1em}.katex .fontsize-ensurer.reset-size3.size4,.katex .sizing.reset-size3.size4{font-size:1.14285714em}.katex .fontsize-ensurer.reset-size3.size5,.katex .sizing.reset-size3.size5{font-size:1.28571429em}.katex .fontsize-ensurer.reset-size3.size6,.katex .sizing.reset-size3.size6{font-size:1.42857143em}.katex .fontsize-ensurer.reset-size3.size7,.katex .sizing.reset-size3.size7{font-size:1.71428571em}.katex .fontsize-ensurer.reset-size3.size8,.katex .sizing.reset-size3.size8{font-size:2.05714286em}.katex .fontsize-ensurer.reset-size3.size9,.katex .sizing.reset-size3.size9{font-size:2.46857143em}.katex .fontsize-ensurer.reset-size3.size10,.katex .sizing.reset-size3.size10{font-size:2.96285714em}.katex .fontsize-ensurer.reset-size3.size11,.katex .sizing.reset-size3.size11{font-size:3.55428571em}.katex .fontsize-ensurer.reset-size4.size1,.katex .sizing.reset-size4.size1{font-size:.625em}.katex .fontsize-ensurer.reset-size4.size2,.katex .sizing.reset-size4.size2{font-size:.75em}.katex .fontsize-ensurer.reset-size4.size3,.katex .sizing.reset-size4.size3{font-size:.875em}.katex .fontsize-ensurer.reset-size4.size4,.katex .sizing.reset-size4.size4{font-size:1em}.katex .fontsize-ensurer.reset-size4.size5,.katex .sizing.reset-size4.size5{font-size:1.125em}.katex .fontsize-ensurer.reset-size4.size6,.katex .sizing.reset-size4.size6{font-size:1.25em}.katex .fontsize-ensurer.reset-size4.size7,.katex .sizing.reset-size4.size7{font-size:1.5em}.katex .fontsize-ensurer.reset-size4.size8,.katex .sizing.reset-size4.size8{font-size:1.8em}.katex .fontsize-ensurer.reset-size4.size9,.katex .sizing.reset-size4.size9{font-size:2.16em}.katex .fontsize-ensurer.reset-size4.size10,.katex .sizing.reset-size4.size10{font-size:2.5925em}.katex .fontsize-ensurer.reset-size4.size11,.katex .sizing.reset-size4.size11{font-size:3.11em}.katex .fontsize-ensurer.reset-size5.size1,.katex .sizing.reset-size5.size1{font-size:.55555556em}.katex .fontsize-ensurer.reset-size5.size2,.katex .sizing.reset-size5.size2{font-size:.66666667em}.katex .fontsize-ensurer.reset-size5.size3,.katex .sizing.reset-size5.size3{font-size:.77777778em}.katex .fontsize-ensurer.reset-size5.size4,.katex .sizing.reset-size5.size4{font-size:.88888889em}.katex .fontsize-ensurer.reset-size5.size5,.katex .sizing.reset-size5.size5{font-size:1em}.katex .fontsize-ensurer.reset-size5.size6,.katex .sizing.reset-size5.size6{font-size:1.11111111em}.katex .fontsize-ensurer.reset-size5.size7,.katex .sizing.reset-size5.size7{font-size:1.33333333em}.katex .fontsize-ensurer.reset-size5.size8,.katex .sizing.reset-size5.size8{font-size:1.6em}.katex .fontsize-ensurer.reset-size5.size9,.katex .sizing.reset-size5.size9{font-size:1.92em}.katex .fontsize-ensurer.reset-size5.size10,.katex .sizing.reset-size5.size10{font-size:2.30444444em}.katex .fontsize-ensurer.reset-size5.size11,.katex .sizing.reset-size5.size11{font-size:2.76444444em}.katex .fontsize-ensurer.reset-size6.size1,.katex .sizing.reset-size6.size1{font-size:.5em}.katex .fontsize-ensurer.reset-size6.size2,.katex .sizing.reset-size6.size2{font-size:.6em}.katex .fontsize-ensurer.reset-size6.size3,.katex .sizing.reset-size6.size3{font-size:.7em}.katex .fontsize-ensurer.reset-size6.size4,.katex .sizing.reset-size6.size4{font-size:.8em}.katex .fontsize-ensurer.reset-size6.size5,.katex .sizing.reset-size6.size5{font-size:.9em}.katex .fontsize-ensurer.reset-size6.size6,.katex .sizing.reset-size6.size6{font-size:1em}.katex .fontsize-ensurer.reset-size6.size7,.katex .sizing.reset-size6.size7{font-size:1.2em}.katex .fontsize-ensurer.reset-size6.size8,.katex .sizing.reset-size6.size8{font-size:1.44em}.katex .fontsize-ensurer.reset-size6.size9,.katex .sizing.reset-size6.size9{font-size:1.728em}.katex .fontsize-ensurer.reset-size6.size10,.katex .sizing.reset-size6.size10{font-size:2.074em}.katex .fontsize-ensurer.reset-size6.size11,.katex .sizing.reset-size6.size11{font-size:2.488em}.katex .fontsize-ensurer.reset-size7.size1,.katex .sizing.reset-size7.size1{font-size:.41666667em}.katex .fontsize-ensurer.reset-size7.size2,.katex .sizing.reset-size7.size2{font-size:.5em}.katex .fontsize-ensurer.reset-size7.size3,.katex .sizing.reset-size7.size3{font-size:.58333333em}.katex .fontsize-ensurer.reset-size7.size4,.katex .sizing.reset-size7.size4{font-size:.66666667em}.katex .fontsize-ensurer.reset-size7.size5,.katex .sizing.reset-size7.size5{font-size:.75em}.katex .fontsize-ensurer.reset-size7.size6,.katex .sizing.reset-size7.size6{font-size:.83333333em}.katex .fontsize-ensurer.reset-size7.size7,.katex .sizing.reset-size7.size7{font-size:1em}.katex .fontsize-ensurer.reset-size7.size8,.katex .sizing.reset-size7.size8{font-size:1.2em}.katex .fontsize-ensurer.reset-size7.size9,.katex .sizing.reset-size7.size9{font-size:1.44em}.katex .fontsize-ensurer.reset-size7.size10,.katex .sizing.reset-size7.size10{font-size:1.72833333em}.katex .fontsize-ensurer.reset-size7.size11,.katex .sizing.reset-size7.size11{font-size:2.07333333em}.katex .fontsize-ensurer.reset-size8.size1,.katex .sizing.reset-size8.size1{font-size:.34722222em}.katex .fontsize-ensurer.reset-size8.size2,.katex .sizing.reset-size8.size2{font-size:.41666667em}.katex .fontsize-ensurer.reset-size8.size3,.katex .sizing.reset-size8.size3{font-size:.48611111em}.katex .fontsize-ensurer.reset-size8.size4,.katex .sizing.reset-size8.size4{font-size:.55555556em}.katex .fontsize-ensurer.reset-size8.size5,.katex .sizing.reset-size8.size5{font-size:.625em}.katex .fontsize-ensurer.reset-size8.size6,.katex .sizing.reset-size8.size6{font-size:.69444444em}.katex .fontsize-ensurer.reset-size8.size7,.katex .sizing.reset-size8.size7{font-size:.83333333em}.katex .fontsize-ensurer.reset-size8.size8,.katex .sizing.reset-size8.size8{font-size:1em}.katex .fontsize-ensurer.reset-size8.size9,.katex .sizing.reset-size8.size9{font-size:1.2em}.katex .fontsize-ensurer.reset-size8.size10,.katex .sizing.reset-size8.size10{font-size:1.44027778em}.katex .fontsize-ensurer.reset-size8.size11,.katex .sizing.reset-size8.size11{font-size:1.72777778em}.katex .fontsize-ensurer.reset-size9.size1,.katex .sizing.reset-size9.size1{font-size:.28935185em}.katex .fontsize-ensurer.reset-size9.size2,.katex .sizing.reset-size9.size2{font-size:.34722222em}.katex .fontsize-ensurer.reset-size9.size3,.katex .sizing.reset-size9.size3{font-size:.40509259em}.katex .fontsize-ensurer.reset-size9.size4,.katex .sizing.reset-size9.size4{font-size:.46296296em}.katex .fontsize-ensurer.reset-size9.size5,.katex .sizing.reset-size9.size5{font-size:.52083333em}.katex .fontsize-ensurer.reset-size9.size6,.katex .sizing.reset-size9.size6{font-size:.5787037em}.katex .fontsize-ensurer.reset-size9.size7,.katex .sizing.reset-size9.size7{font-size:.69444444em}.katex .fontsize-ensurer.reset-size9.size8,.katex .sizing.reset-size9.size8{font-size:.83333333em}.katex .fontsize-ensurer.reset-size9.size9,.katex .sizing.reset-size9.size9{font-size:1em}.katex .fontsize-ensurer.reset-size9.size10,.katex .sizing.reset-size9.size10{font-size:1.20023148em}.katex .fontsize-ensurer.reset-size9.size11,.katex .sizing.reset-size9.size11{font-size:1.43981481em}.katex .fontsize-ensurer.reset-size10.size1,.katex .sizing.reset-size10.size1{font-size:.24108004em}.katex .fontsize-ensurer.reset-size10.size2,.katex .sizing.reset-size10.size2{font-size:.28929605em}.katex .fontsize-ensurer.reset-size10.size3,.katex .sizing.reset-size10.size3{font-size:.33751205em}.katex .fontsize-ensurer.reset-size10.size4,.katex .sizing.reset-size10.size4{font-size:.38572806em}.katex .fontsize-ensurer.reset-size10.size5,.katex .sizing.reset-size10.size5{font-size:.43394407em}.katex .fontsize-ensurer.reset-size10.size6,.katex .sizing.reset-size10.size6{font-size:.48216008em}.katex .fontsize-ensurer.reset-size10.size7,.katex .sizing.reset-size10.size7{font-size:.57859209em}.katex .fontsize-ensurer.reset-size10.size8,.katex .sizing.reset-size10.size8{font-size:.69431051em}.katex .fontsize-ensurer.reset-size10.size9,.katex .sizing.reset-size10.size9{font-size:.83317261em}.katex .fontsize-ensurer.reset-size10.size10,.katex .sizing.reset-size10.size10{font-size:1em}.katex .fontsize-ensurer.reset-size10.size11,.katex .sizing.reset-size10.size11{font-size:1.19961427em}.katex .fontsize-ensurer.reset-size11.size1,.katex .sizing.reset-size11.size1{font-size:.20096463em}.katex .fontsize-ensurer.reset-size11.size2,.katex .sizing.reset-size11.size2{font-size:.24115756em}.katex .fontsize-ensurer.reset-size11.size3,.katex .sizing.reset-size11.size3{font-size:.28135048em}.katex .fontsize-ensurer.reset-size11.size4,.katex .sizing.reset-size11.size4{font-size:.32154341em}.katex .fontsize-ensurer.reset-size11.size5,.katex .sizing.reset-size11.size5{font-size:.36173633em}.katex .fontsize-ensurer.reset-size11.size6,.katex .sizing.reset-size11.size6{font-size:.40192926em}.katex .fontsize-ensurer.reset-size11.size7,.katex .sizing.reset-size11.size7{font-size:.48231511em}.katex .fontsize-ensurer.reset-size11.size8,.katex .sizing.reset-size11.size8{font-size:.57877814em}.katex .fontsize-ensurer.reset-size11.size9,.katex .sizing.reset-size11.size9{font-size:.69453376em}.katex .fontsize-ensurer.reset-size11.size10,.katex .sizing.reset-size11.size10{font-size:.83360129em}.katex .fontsize-ensurer.reset-size11.size11,.katex .sizing.reset-size11.size11{font-size:1em}.katex .delimsizing.size1{font-family:KaTeX_Size1}.katex .delimsizing.size2{font-family:KaTeX_Size2}.katex .delimsizing.size3{font-family:KaTeX_Size3}.katex .delimsizing.size4{font-family:KaTeX_Size4}.katex .delimsizing.mult .delim-size1>span{font-family:KaTeX_Size1}.katex .delimsizing.mult .delim-size4>span{font-family:KaTeX_Size4}.katex .nulldelimiter{display:inline-block;width:.12em}.katex .delimcenter,.katex .op-symbol{position:relative}.katex .op-symbol.small-op{font-family:KaTeX_Size1}.katex .op-symbol.large-op{font-family:KaTeX_Size2}.katex .accent>.vlist-t,.katex .op-limits>.vlist-t{text-align:center}.katex .accent .accent-body{position:relative}.katex .accent .accent-body:not(.accent-full){width:0}.katex .overlay{display:block}.katex .mtable .vertical-separator{display:inline-block;min-width:1px}.katex .mtable .arraycolsep{display:inline-block}.katex .mtable .col-align-c>.vlist-t{text-align:center}.katex .mtable .col-align-l>.vlist-t{text-align:left}.katex .mtable .col-align-r>.vlist-t{text-align:right}.katex .svg-align{text-align:left}.katex svg{fill:currentColor;stroke:currentColor;fill-rule:nonzero;fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1;display:block;height:inherit;position:absolute;width:100%}.katex svg path{stroke:none}.katex img{border-style:none;max-height:none;max-width:none;min-height:0;min-width:0}.katex .stretchy{display:block;overflow:hidden;position:relative;width:100%}.katex .stretchy:after,.katex .stretchy:before{content:""}.katex .hide-tail{overflow:hidden;position:relative;width:100%}.katex .halfarrow-left{left:0;overflow:hidden;position:absolute;width:50.2%}.katex .halfarrow-right{overflow:hidden;position:absolute;right:0;width:50.2%}.katex .brace-left{left:0;overflow:hidden;position:absolute;width:25.1%}.katex .brace-center{left:25%;overflow:hidden;position:absolute;width:50%}.katex .brace-right{overflow:hidden;position:absolute;right:0;width:25.1%}.katex .x-arrow-pad{padding:0 .5em}.katex .cd-arrow-pad{padding:0 .55556em 0 .27778em}.katex .mover,.katex .munder,.katex .x-arrow{text-align:center}.katex .boxpad{padding:0 .3em}.katex .fbox,.katex .fcolorbox{border:.04em solid;box-sizing:border-box}.katex .cancel-pad{padding:0 .2em}.katex .cancel-lap{margin-left:-.2em;margin-right:-.2em}.katex .sout{border-bottom-style:solid;border-bottom-width:.08em}.katex .angl{border-right:.049em solid;border-top:.049em solid;box-sizing:border-box;margin-right:.03889em}.katex .anglpad{padding:0 .03889em}.katex .eqn-num:before{content:"(" counter(katexEqnNo) ")";counter-increment:katexEqnNo}.katex .mml-eqn-num:before{content:"(" counter(mmlEqnNo) ")";counter-increment:mmlEqnNo}.katex .mtr-glue{width:50%}.katex .cd-vert-arrow{display:inline-block;position:relative}.katex .cd-label-left{display:inline-block;position:absolute;right:calc(50% + .3em);text-align:left}.katex .cd-label-right{display:inline-block;left:calc(50% + .3em);position:absolute;text-align:right}.katex-display{display:block;margin:1em 0;text-align:center}.katex-display>.katex{display:block;text-align:center;white-space:nowrap}.katex-display>.katex>.katex-html{display:block;position:relative}.katex-display>.katex>.katex-html>.tag{position:absolute;right:0}.katex-display.leqno>.katex>.katex-html>.tag{left:0;right:auto}.katex-display.fleqn>.katex{padding-left:2em;text-align:left}body{counter-reset:katexEqnNo mmlEqnNo}

</style>

</head>
<body>
    <div class="content-wrapper">
        <h1 id="marketing-agent-implementation-guide" tabindex="-1">Marketing Agent Implementation Guide</h1>
<p><strong>End-to-End Production GenAI System</strong></p>
<p>Version: 1.0<br>
Date: February 11, 2026</p>
<hr>
<h2 id="executive-summary" tabindex="-1">Executive Summary</h2>
<p>This document provides a complete, step-by-step implementation plan for building a production-grade Marketing Reasoning Agent. The agent will analyze campaign performance, competitor activity, and creative metrics to recommend specific workflow actions, replacing manual decision-making by marketing executives with AI-powered reasoning.</p>
<p><strong>Key Principles:</strong></p>
<ul>
<li>Start simple, add complexity only when proven necessary</li>
<li>Evaluation-driven development (test systematically, not trial-and-error)</li>
<li>Human-in-the-loop initially, graduated autonomy as trust builds</li>
<li>Production-grade from day one (monitoring, CI/CD, evaluation)</li>
</ul>
<hr>
<h2 id="table-of-contents" tabindex="-1">Table of Contents</h2>
<ol>
<li><a href="#1-requirements-analysis">Requirements Analysis</a></li>
<li><a href="#2-architecture-design">Architecture Design</a></li>
<li><a href="#3-technology-stack--rationale">Technology Stack &amp; Rationale</a></li>
<li><a href="#4-implementation-phases">Implementation Phases</a></li>
<li><a href="#5-data-integration-layer">Data Integration Layer</a></li>
<li><a href="#6-agent-design--prompting">Agent Design &amp; Prompting</a></li>
<li><a href="#7-evaluation-framework">Evaluation Framework</a></li>
<li><a href="#8-production-infrastructure">Production Infrastructure</a></li>
<li><a href="#9-deployment-strategy">Deployment Strategy</a></li>
<li><a href="#10-monitoring--observability">Monitoring &amp; Observability</a></li>
<li><a href="#11-cost-management">Cost Management</a></li>
<li><a href="#12-team-structure--workflows">Team Structure &amp; Workflows</a></li>
<li><a href="#13-future-roadmap--next-applications">Future Roadmap &amp; Next Applications</a></li>
</ol>
<hr>
<h2 id="1.-requirements-analysis" tabindex="-1">1. Requirements Analysis</h2>
<h3 id="1.1-current-state" tabindex="-1">1.1 Current State</h3>
<p><strong>Existing Infrastructure:</strong></p>
<ul>
<li>Multiple AI workflows that automate marketing tasks:
<ul>
<li>Ad copy generation</li>
<li>Campaign pausing</li>
<li>Creative refresh</li>
<li>Audience expansion</li>
<li>Bid adjustment</li>
</ul>
</li>
<li>Each workflow triggers notifications requiring manual approval/rejection</li>
<li>Marketing execs manually assess context to decide which workflow to trigger</li>
</ul>
<p><strong>The Problem:</strong>
Workflows execute predefined actions but lack contextual reasoning. When KPIs change (e.g., CPA increases), determining the root cause requires human analysis across multiple data sources.</p>
<h3 id="1.2-what-we're-building" tabindex="-1">1.2 What We're Building</h3>
<p><strong>Marketing Reasoning Agent</strong> - An intelligent layer that:</p>
<ol>
<li>
<p><strong>Analyzes Multi-Source Context:</strong></p>
<ul>
<li>Campaign performance metrics (CPA, CTR, conversion rates, spend)</li>
<li>Creative performance (engagement, CTR trends, frequency, age)</li>
<li>Competitor activity signals (bid changes, new entrants, market pressure)</li>
<li>Audience signals (saturation indicators, impression share)</li>
<li>Historical patterns and baseline performance</li>
</ul>
</li>
<li>
<p><strong>Reasons About Causality:</strong></p>
<ul>
<li>Correlates multiple signals to identify root causes</li>
<li>Evaluates competing hypotheses (creative fatigue vs. competitive pressure vs. audience saturation)</li>
<li>Considers interdependencies between metrics</li>
<li>Assesses confidence levels based on signal strength</li>
</ul>
</li>
<li>
<p><strong>Recommends Specific Actions:</strong></p>
<ul>
<li>Selects appropriate workflow from existing options</li>
<li>Provides detailed evidence-based reasoning</li>
<li>Predicts expected impact</li>
<li>Identifies alternative actions considered</li>
<li>Assesses risk level</li>
</ul>
</li>
</ol>
<p><strong>Example Output:</strong></p>
<pre class="hljs"><code><div>Campaign: Spring Sale 2026
Recommended Action: Bid Adjustment (Increase by 15%)

Reasoning:
CPA increased 30% over 3 days (from $45 to $58.50). Analysis indicates:
- Creative CTR stable at 2.8% (no fatigue detected)
- Audience near saturation limit (95% impression share)
- Competitor activity up 40% (3 new entrants, avg bid increase 25%)
- Historical pattern: Similar competitive surges recovered with bid adjustments

Root Cause: Increased competitive pressure in auction environment
Recommended Action: Bid adjustment, not creative refresh
Expected Impact: Restore CPA to $47-49 range within 2-3 days
Risk Level: Medium (potential for overspend if competition doesn't stabilize)
Confidence: 82%

Alternative Actions Considered:
- Creative Refresh: Low probability (creative performing well)
- Campaign Pause: Premature (issue appears temporary and addressable)
</div></code></pre>
<h3 id="1.3-success-criteria" tabindex="-1">1.3 Success Criteria</h3>
<p><strong>Quality Metrics (Primary):</strong></p>
<ul>
<li>Recommendation acceptance rate &gt;70% by month 6</li>
<li>Actual positive impact when recommendations are followed &gt;80%</li>
<li>False positive rate &lt;20%</li>
<li>Agreement with marketing team expert judgment &gt;75%</li>
</ul>
<p><strong>Operational Metrics:</strong></p>
<ul>
<li>Latency &lt;30 seconds per recommendation</li>
<li>System uptime 99.5%+</li>
<li>Cost per recommendation optimized and tracked</li>
</ul>
<p><strong>Business Impact:</strong></p>
<ul>
<li>Time saved for marketing team (hours per week)</li>
<li>Campaign management scale (campaigns managed with agent support)</li>
<li>ROI improvement on ad spend efficiency</li>
</ul>
<p><strong>Process Metrics:</strong></p>
<ul>
<li>Deployment frequency (weekly iterations)</li>
<li>Evaluation coverage (100% of recommendations evaluated)</li>
<li>Feedback loop closure time (insights → improvements &lt;1 week)</li>
</ul>
<h3 id="1.4-non-functional-requirements" tabindex="-1">1.4 Non-Functional Requirements</h3>
<p><strong>Reliability:</strong></p>
<ul>
<li>Graceful degradation (fallback to rule-based if LLM fails)</li>
<li>Retry logic with exponential backoff</li>
<li>Circuit breakers for external dependencies</li>
</ul>
<p><strong>Security:</strong></p>
<ul>
<li>Campaign data encryption at rest and in transit</li>
<li>API key management (secrets management system)</li>
<li>Audit trail for all recommendations and decisions</li>
</ul>
<p><strong>Scalability:</strong></p>
<ul>
<li>Support 100+ campaigns initially, 1000+ within 12 months</li>
<li>Handle parallel recommendation requests</li>
<li>Async workflow triggering</li>
</ul>
<p><strong>Maintainability:</strong></p>
<ul>
<li>Version-controlled prompts (Git)</li>
<li>Comprehensive logging and debugging tools</li>
<li>Clear separation of concerns (data, reasoning, orchestration)</li>
</ul>
<hr>
<h2 id="2.-architecture-design" tabindex="-1">2. Architecture Design</h2>
<h3 id="2.1-high-level-architecture" tabindex="-1">2.1 High-Level Architecture</h3>
<p>Based on Anthropic's agent patterns, we'll use a <strong>Workflow-based architecture</strong> (not fully autonomous agents) because our use case has:</p>
<ul>
<li>Well-defined problem space</li>
<li>Clear evaluation criteria</li>
<li>Need for predictable, explainable outputs</li>
<li>Human approval requirements</li>
</ul>
<pre class="hljs"><code><div>┌─────────────────────────────────────────────────────────────────────┐
│                     Marketing Dashboard (UI)                        │
│              Review &amp; Approve/Reject Recommendations                │
│                     (React + TypeScript)                            │
└────────────────────────────┬───────────────────────────────────────┘
                             │
                             │ REST API
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                      API Gateway &amp; Backend                          │
│                    (FastAPI / Python 3.11+)                         │
│                                                                     │
│  ┌──────────────────┐  ┌──────────────────┐  ┌─────────────────┐ │
│  │  Recommendation  │  │    Workflow      │  │   Evaluation    │ │
│  │   Orchestrator   │  │   Integrator     │  │     Service     │ │
│  └──────────────────┘  └──────────────────┘  └─────────────────┘ │
└────────────────────────────┬───────────────────────────────────────┘
                             │
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                  Marketing Reasoning Agent                          │
│                    (LangGraph Workflow)                             │
│                                                                     │
│  ┌────────────────────────────────────────────────────────────┐   │
│  │ 1. CONTEXT COLLECTION                                      │   │
│  │    Parallel data gathering from all sources                │   │
│  │    ├── Campaign Metrics Collector                          │   │
│  │    ├── Creative Performance Collector                      │   │
│  │    ├── Competitor Signal Collector                         │   │
│  │    ├── Audience Analytics Collector                        │   │
│  │    └── Historical Pattern Analyzer                         │   │
│  └────────────────────────────────────────────────────────────┘   │
│                             ▼                                       │
│  ┌────────────────────────────────────────────────────────────┐   │
│  │ 2. REASONING &amp; ANALYSIS                                    │   │
│  │    LLM-powered causal analysis                             │   │
│  │    ├── Signal Correlation (GPT-4)                          │   │
│  │    ├── Root Cause Identification                           │   │
│  │    ├── Hypothesis Evaluation                               │   │
│  │    └── Confidence Scoring                                  │   │
│  └────────────────────────────────────────────────────────────┘   │
│                             ▼                                       │
│  ┌────────────────────────────────────────────────────────────┐   │
│  │ 3. WORKFLOW SELECTION &amp; RECOMMENDATION                     │   │
│  │    Structured decision output                              │   │
│  │    ├── Workflow Matcher                                    │   │
│  │    ├── Impact Predictor                                    │   │
│  │    ├── Risk Assessor                                       │   │
│  │    └── Alternative Generator                               │   │
│  └────────────────────────────────────────────────────────────┘   │
│                             ▼                                       │
│  ┌────────────────────────────────────────────────────────────┐   │
│  │ 4. VALIDATION &amp; QUALITY CHECKS                             │   │
│  │    ├── Output Schema Validation                            │   │
│  │    ├── Confidence Threshold Check                          │   │
│  │    ├── Safety Guardrails                                   │   │
│  │    └── Explainability Audit                                │   │
│  └────────────────────────────────────────────────────────────┘   │
└────────────────────────────┬───────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    Data Integration Layer                           │
│                  (Connectors &amp; Adapters)                            │
│                                                                     │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐            │
│  │  Ad Platform │  │   Analytics  │  │  Competitor  │            │
│  │     APIs     │  │   Platform   │  │  Intelligence│            │
│  │              │  │              │  │     Tools    │            │
│  │ • Google Ads │  │ • GA4        │  │ • SEMrush   │            │
│  │ • Meta Ads   │  │ • Mixpanel   │  │ • SpyFu     │            │
│  │ • LinkedIn   │  │ • Amplitude  │  │ • SimilarWeb│            │
│  └──────────────┘  └──────────────┘  └──────────────┘            │
└────────────────────────────┬───────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                     Data Storage Layer                              │
│                                                                     │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐            │
│  │  PostgreSQL  │  │    Redis     │  │      S3      │            │
│  │              │  │              │  │              │            │
│  │ • Campaigns  │  │ • Cache      │  │ • Logs       │            │
│  │ • Recs       │  │ • Sessions   │  │ • Artifacts  │            │
│  │ • Decisions  │  │ • Rate Limit │  │ • Evals      │            │
│  │ • Evals      │  │              │  │              │            │
│  └──────────────┘  └──────────────┘  └──────────────┘            │
└─────────────────────────────────────────────────────────────────────┘
                             ▲
                             │
┌─────────────────────────────────────────────────────────────────────┐
│                 Observability &amp; Operations                          │
│                                                                     │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐            │
│  │  LangSmith   │  │  Prometheus  │  │    Sentry    │            │
│  │              │  │   + Grafana  │  │              │            │
│  │ • LLM Traces │  │ • Metrics    │  │ • Errors     │            │
│  │ • Evals      │  │ • Alerts     │  │ • Monitoring │            │
│  └──────────────┘  └──────────────┘  └──────────────┘            │
└─────────────────────────────────────────────────────────────────────┘
</div></code></pre>
<h3 id="2.2-agent-workflow-pattern" tabindex="-1">2.2 Agent Workflow Pattern</h3>
<p>We'll use a <strong>hybrid workflow</strong> combining:</p>
<ol>
<li><strong>Prompt Chaining</strong> - Sequential steps for data → reasoning → recommendation</li>
<li><strong>Parallelization</strong> - Concurrent data collection from multiple sources</li>
<li><strong>Evaluator-Optimizer</strong> - Self-critique loop to improve recommendation quality</li>
</ol>
<p><strong>Workflow State Machine (LangGraph):</strong></p>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> TypedDict, Annotated, <span class="hljs-type">Sequence</span>
<span class="hljs-keyword">from</span> langchain_core.messages <span class="hljs-keyword">import</span> BaseMessage
<span class="hljs-keyword">import</span> operator

<span class="hljs-keyword">class</span> <span class="hljs-title class_">AgentState</span>(<span class="hljs-title class_ inherited__">TypedDict</span>):
    <span class="hljs-string">"""State passed between nodes in the workflow"""</span>
    campaign_id: <span class="hljs-built_in">str</span>
    
    <span class="hljs-comment"># Context collection results</span>
    campaign_metrics: <span class="hljs-built_in">dict</span>
    creative_metrics: <span class="hljs-built_in">dict</span>
    competitor_signals: <span class="hljs-built_in">dict</span>
    audience_analytics: <span class="hljs-built_in">dict</span>
    historical_patterns: <span class="hljs-built_in">dict</span>
    
    <span class="hljs-comment"># Reasoning outputs</span>
    signal_analysis: <span class="hljs-built_in">str</span>
    root_cause_hypothesis: <span class="hljs-built_in">str</span>
    confidence_score: <span class="hljs-built_in">float</span>
    
    <span class="hljs-comment"># Recommendation</span>
    recommended_workflow: <span class="hljs-built_in">str</span>
    reasoning: <span class="hljs-built_in">str</span>
    expected_impact: <span class="hljs-built_in">str</span>
    risk_level: <span class="hljs-built_in">str</span>
    alternatives: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">str</span>]
    
    <span class="hljs-comment"># Quality checks</span>
    validation_passed: <span class="hljs-built_in">bool</span>
    critique_feedback: <span class="hljs-built_in">str</span> | <span class="hljs-literal">None</span>
    
    <span class="hljs-comment"># Metadata</span>
    messages: Annotated[<span class="hljs-type">Sequence</span>[BaseMessage], operator.add]
    iteration_count: <span class="hljs-built_in">int</span>

<span class="hljs-comment"># Node functions</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">collect_campaign_metrics</span>(<span class="hljs-params">state: AgentState</span>) -&gt; AgentState:
    <span class="hljs-string">"""Fetch campaign performance data"""</span>
    <span class="hljs-keyword">pass</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">collect_creative_metrics</span>(<span class="hljs-params">state: AgentState</span>) -&gt; AgentState:
    <span class="hljs-string">"""Fetch creative performance data"""</span>
    <span class="hljs-keyword">pass</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">collect_competitor_signals</span>(<span class="hljs-params">state: AgentState</span>) -&gt; AgentState:
    <span class="hljs-string">"""Fetch competitor intelligence"""</span>
    <span class="hljs-keyword">pass</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">analyze_signals</span>(<span class="hljs-params">state: AgentState</span>) -&gt; AgentState:
    <span class="hljs-string">"""LLM-powered analysis of all signals"""</span>
    <span class="hljs-keyword">pass</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_recommendation</span>(<span class="hljs-params">state: AgentState</span>) -&gt; AgentState:
    <span class="hljs-string">"""Generate structured recommendation"""</span>
    <span class="hljs-keyword">pass</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">critique_recommendation</span>(<span class="hljs-params">state: AgentState</span>) -&gt; AgentState:
    <span class="hljs-string">"""Self-critique to improve quality"""</span>
    <span class="hljs-keyword">pass</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">validate_output</span>(<span class="hljs-params">state: AgentState</span>) -&gt; AgentState:
    <span class="hljs-string">"""Validate schema and safety"""</span>
    <span class="hljs-keyword">pass</span>

<span class="hljs-comment"># Conditional edges</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">should_regenerate</span>(<span class="hljs-params">state: AgentState</span>) -&gt; <span class="hljs-built_in">str</span>:
    <span class="hljs-string">"""Decide if recommendation needs improvement"""</span>
    <span class="hljs-keyword">if</span> state[<span class="hljs-string">"iteration_count"</span>] &gt;= <span class="hljs-number">2</span>:
        <span class="hljs-keyword">return</span> <span class="hljs-string">"end"</span>
    <span class="hljs-keyword">if</span> state[<span class="hljs-string">"confidence_score"</span>] &lt; <span class="hljs-number">0.6</span>:
        <span class="hljs-keyword">return</span> <span class="hljs-string">"regenerate"</span>
    <span class="hljs-keyword">return</span> <span class="hljs-string">"end"</span>
</div></code></pre>
<h3 id="2.3-why-this-architecture%3F" tabindex="-1">2.3 Why This Architecture?</h3>
<p><strong>Workflow over Autonomous Agent:</strong></p>
<ul>
<li>Predictable execution paths (easier debugging)</li>
<li>Clear evaluation points at each stage</li>
<li>Bounded costs (no runaway token usage)</li>
<li>Explainable (can trace each decision)</li>
</ul>
<p><strong>LangGraph Benefits:</strong></p>
<ul>
<li><strong>Durable execution</strong>: Workflow can resume if interrupted</li>
<li><strong>Human-in-the-loop</strong>: Built-in approval checkpoints</li>
<li><strong>Streaming</strong>: Show progress to users in real-time</li>
<li><strong>State persistence</strong>: Debug and replay workflows</li>
</ul>
<p><strong>Best Practice Alignment:</strong></p>
<ul>
<li>Anthropic: "Start simple, add complexity only when needed"</li>
<li>LangChain: "Use workflows for well-defined tasks"</li>
<li>Our case: Well-defined workflows, clear success criteria → perfect for workflow pattern</li>
</ul>
<hr>
<h2 id="3.-technology-stack-%26-rationale" tabindex="-1">3. Technology Stack &amp; Rationale</h2>
<h3 id="3.1-core-stack" tabindex="-1">3.1 Core Stack</h3>
<table>
<thead>
<tr>
<th>Component</th>
<th>Technology</th>
<th>Rationale</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Backend</strong></td>
<td>Python 3.11+ with FastAPI</td>
<td>- Best LLM library ecosystem<br>- Async/await for parallel data collection<br>- FastAPI for auto-generated API docs<br>- Type hints for reliability</td>
</tr>
<tr>
<td><strong>Agent Framework</strong></td>
<td>LangGraph + LangChain</td>
<td>- Production-grade orchestration<br>- Durable execution &amp; HITL support<br>- Extensive integrations<br>- LangSmith for observability</td>
</tr>
<tr>
<td><strong>LLM Provider</strong></td>
<td>OpenAI GPT-4o / Anthropic Claude 3.5 Sonnet</td>
<td>- Best reasoning capabilities<br>- Strong at structured outputs<br>- Tool use reliability<br>- Consider both for flexibility</td>
</tr>
<tr>
<td><strong>Database</strong></td>
<td>PostgreSQL 15+</td>
<td>- JSONB for flexible schema<br>- Strong consistency<br>- Full-text search<br>- Time-series support</td>
</tr>
<tr>
<td><strong>Cache</strong></td>
<td>Redis 7+</td>
<td>- Response caching<br>- Rate limiting<br>- Session management<br>- Real-time features</td>
</tr>
<tr>
<td><strong>Storage</strong></td>
<td>S3-compatible (AWS S3 / MinIO)</td>
<td>- Log storage<br>- Evaluation artifacts<br>- Prompt versions<br>- Cost-effective</td>
</tr>
<tr>
<td><strong>Frontend</strong></td>
<td>React + TypeScript + TanStack Query</td>
<td>- Type safety<br>- Modern state management<br>- Excellent DX<br>- Component reusability</td>
</tr>
<tr>
<td><strong>Monitoring</strong></td>
<td>LangSmith + Prometheus + Grafana</td>
<td>- LangSmith: LLM-specific traces<br>- Prometheus: System metrics<br>- Grafana: Unified dashboards</td>
</tr>
<tr>
<td><strong>Error Tracking</strong></td>
<td>Sentry</td>
<td>- Error aggregation<br>- Release tracking<br>- Performance monitoring</td>
</tr>
<tr>
<td><strong>CI/CD</strong></td>
<td>GitHub Actions</td>
<td>- Easy setup<br>- Great for Python/Node<br>- Free for open source</td>
</tr>
<tr>
<td><strong>Orchestration</strong></td>
<td>Docker Compose (dev)<br>Kubernetes (prod)</td>
<td>- Dev/prod parity<br>- Scalability<br>- Industry standard</td>
</tr>
<tr>
<td><strong>Evaluation</strong></td>
<td>LangSmith + promptfoo</td>
<td>- LangSmith: Integration<br>- promptfoo: Advanced testing<br>- Complementary strengths</td>
</tr>
</tbody>
</table>
<h3 id="3.2-key-dependencies" tabindex="-1">3.2 Key Dependencies</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># pyproject.toml (partial)</span>
[project]
name = <span class="hljs-string">"marketing-agent"</span>
version = <span class="hljs-string">"0.1.0"</span>
requires-python = <span class="hljs-string">"&gt;=3.11"</span>

dependencies = [
    <span class="hljs-comment"># Agent framework</span>
    <span class="hljs-string">"langchain&gt;=0.3.0"</span>,
    <span class="hljs-string">"langchain-openai&gt;=0.2.0"</span>,
    <span class="hljs-string">"langchain-anthropic&gt;=0.2.0"</span>,
    <span class="hljs-string">"langgraph&gt;=0.2.0"</span>,
    <span class="hljs-string">"langsmith&gt;=0.2.0"</span>,
    
    <span class="hljs-comment"># Web framework</span>
    <span class="hljs-string">"fastapi&gt;=0.115.0"</span>,
    <span class="hljs-string">"uvicorn[standard]&gt;=0.32.0"</span>,
    <span class="hljs-string">"pydantic&gt;=2.9.0"</span>,
    <span class="hljs-string">"pydantic-settings&gt;=2.6.0"</span>,
    
    <span class="hljs-comment"># Database</span>
    <span class="hljs-string">"sqlmodel&gt;=0.0.22"</span>,
    <span class="hljs-string">"asyncpg&gt;=0.30.0"</span>,
    <span class="hljs-string">"alembic&gt;=1.13.0"</span>,
    
    <span class="hljs-comment"># Caching</span>
    <span class="hljs-string">"redis&gt;=5.2.0"</span>,
    
    <span class="hljs-comment"># HTTP</span>
    <span class="hljs-string">"httpx&gt;=0.27.0"</span>,
    <span class="hljs-string">"tenacity&gt;=9.0.0"</span>,  <span class="hljs-comment"># Retry logic</span>
    
    <span class="hljs-comment"># Observability</span>
    <span class="hljs-string">"prometheus-client&gt;=0.21.0"</span>,
    <span class="hljs-string">"sentry-sdk&gt;=2.18.0"</span>,
    
    <span class="hljs-comment"># Utilities</span>
    <span class="hljs-string">"python-dotenv&gt;=1.0.0"</span>,
    <span class="hljs-string">"structlog&gt;=24.4.0"</span>,  <span class="hljs-comment"># Structured logging</span>
    <span class="hljs-string">"pyyaml&gt;=6.0.2"</span>,
]

[project.optional-dependencies]
dev = [
    <span class="hljs-string">"pytest&gt;=8.3.0"</span>,
    <span class="hljs-string">"pytest-asyncio&gt;=0.24.0"</span>,
    <span class="hljs-string">"pytest-cov&gt;=6.0.0"</span>,
    <span class="hljs-string">"ruff&gt;=0.8.0"</span>,  <span class="hljs-comment"># Linting &amp; formatting</span>
    <span class="hljs-string">"mypy&gt;=1.13.0"</span>,  <span class="hljs-comment"># Type checking</span>
]
</div></code></pre>
<h3 id="3.3-infrastructure-as-code" tabindex="-1">3.3 Infrastructure as Code</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># docker-compose.yml (development)</span>
<span class="hljs-attr">version:</span> <span class="hljs-string">'3.9'</span>

<span class="hljs-attr">services:</span>
  <span class="hljs-attr">backend:</span>
    <span class="hljs-attr">build:</span> <span class="hljs-string">./backend</span>
    <span class="hljs-attr">ports:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">"8000:8000"</span>
    <span class="hljs-attr">environment:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">DATABASE_URL=postgresql://user:pass@postgres:5432/marketing_agent</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">REDIS_URL=redis://redis:6379/0</span>
    <span class="hljs-attr">depends_on:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">postgres</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">redis</span>
    <span class="hljs-attr">volumes:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">./backend:/app</span>
    <span class="hljs-attr">command:</span> <span class="hljs-string">uvicorn</span> <span class="hljs-string">main:app</span> <span class="hljs-string">--reload</span> <span class="hljs-string">--host</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span>

  <span class="hljs-attr">postgres:</span>
    <span class="hljs-attr">image:</span> <span class="hljs-string">postgres:15-alpine</span>
    <span class="hljs-attr">environment:</span>
      <span class="hljs-attr">POSTGRES_DB:</span> <span class="hljs-string">marketing_agent</span>
      <span class="hljs-attr">POSTGRES_USER:</span> <span class="hljs-string">user</span>
      <span class="hljs-attr">POSTGRES_PASSWORD:</span> <span class="hljs-string">pass</span>
    <span class="hljs-attr">volumes:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">postgres_data:/var/lib/postgresql/data</span>
    <span class="hljs-attr">ports:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">"5432:5432"</span>

  <span class="hljs-attr">redis:</span>
    <span class="hljs-attr">image:</span> <span class="hljs-string">redis:7-alpine</span>
    <span class="hljs-attr">ports:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">"6379:6379"</span>
    <span class="hljs-attr">volumes:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">redis_data:/data</span>

  <span class="hljs-attr">frontend:</span>
    <span class="hljs-attr">build:</span> <span class="hljs-string">./frontend</span>
    <span class="hljs-attr">ports:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">"3000:3000"</span>
    <span class="hljs-attr">volumes:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">./frontend:/app</span>
    <span class="hljs-attr">environment:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">VITE_API_URL=http://localhost:8000</span>

  <span class="hljs-attr">prometheus:</span>
    <span class="hljs-attr">image:</span> <span class="hljs-string">prom/prometheus:latest</span>
    <span class="hljs-attr">ports:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">"9090:9090"</span>
    <span class="hljs-attr">volumes:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">prometheus_data:/prometheus</span>

  <span class="hljs-attr">grafana:</span>
    <span class="hljs-attr">image:</span> <span class="hljs-string">grafana/grafana:latest</span>
    <span class="hljs-attr">ports:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">"3001:3000"</span>
    <span class="hljs-attr">volumes:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">grafana_data:/var/lib/grafana</span>
    <span class="hljs-attr">environment:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">GF_SECURITY_ADMIN_PASSWORD=admin</span>

<span class="hljs-attr">volumes:</span>
  <span class="hljs-attr">postgres_data:</span>
  <span class="hljs-attr">redis_data:</span>
  <span class="hljs-attr">prometheus_data:</span>
  <span class="hljs-attr">grafana_data:</span>
</div></code></pre>
<hr>
<h2 id="4.-implementation-phases" tabindex="-1">4. Implementation Phases</h2>
<h3 id="phase-0%3A-setup-%26-foundations-(week-1-2)" tabindex="-1">Phase 0: Setup &amp; Foundations (Week 1-2)</h3>
<p><strong>Goal:</strong> Development environment and project scaffolding</p>
<p><strong>Tasks:</strong></p>
<ul>
<li><input type="checkbox" id="checkbox0"><label for="checkbox0">Project structure setup</label></li>
<li><input type="checkbox" id="checkbox1"><label for="checkbox1">Version control (Git)</label></li>
<li><input type="checkbox" id="checkbox2"><label for="checkbox2">Development environment (Docker Compose)</label></li>
<li><input type="checkbox" id="checkbox3"><label for="checkbox3">CI/CD pipeline (GitHub Actions)</label></li>
<li><input type="checkbox" id="checkbox4"><label for="checkbox4">Secrets management setup</label></li>
<li><input type="checkbox" id="checkbox5"><label for="checkbox5">Database schema design</label></li>
<li><input type="checkbox" id="checkbox6"><label for="checkbox6">API design (OpenAPI spec)</label></li>
</ul>
<p><strong>Deliverables:</strong></p>
<ul>
<li>Working dev environment</li>
<li>Empty API endpoints with docs</li>
<li>Database migrations</li>
<li>README with setup instructions</li>
</ul>
<hr>
<h3 id="phase-1%3A-data-integration-(week-3-4)" tabindex="-1">Phase 1: Data Integration (Week 3-4)</h3>
<p><strong>Goal:</strong> Connect to all data sources</p>
<p><strong>Tasks:</strong></p>
<ul>
<li><input type="checkbox" id="checkbox7"><label for="checkbox7">Campaign metrics collector</label></li>
<li><input type="checkbox" id="checkbox8"><label for="checkbox8">Creative performance collector</label></li>
<li><input type="checkbox" id="checkbox9"><label for="checkbox9">Competitor signals collector (stub if no data initially)</label></li>
<li><input type="checkbox" id="checkbox10"><label for="checkbox10">Audience analytics collector</label></li>
<li><input type="checkbox" id="checkbox11"><label for="checkbox11">Historical pattern analyzer</label></li>
<li><input type="checkbox" id="checkbox12"><label for="checkbox12">Data model definitions (Pydantic)</label></li>
<li><input type="checkbox" id="checkbox13"><label for="checkbox13">Unit tests for each collector</label></li>
<li><input type="checkbox" id="checkbox14"><label for="checkbox14">Integration tests with real APIs (sandbox)</label></li>
</ul>
<p><strong>Acceptance Criteria:</strong></p>
<ul>
<li>Fetch data for any campaign ID</li>
<li>Handle API errors gracefully</li>
<li>Cache responses appropriately</li>
<li>&lt;5s latency for parallel collection</li>
</ul>
<p><strong>Risk Mitigation:</strong></p>
<ul>
<li>Start with stubs/mocks if API access delayed</li>
<li>Use historical exports to build test fixtures</li>
</ul>
<hr>
<h3 id="phase-2%3A-core-agent---mvp-(week-5-8)" tabindex="-1">Phase 2: Core Agent - MVP (Week 5-8)</h3>
<p><strong>Goal:</strong> First working recommendation engine</p>
<p><strong>Tasks:</strong></p>
<ul>
<li><input type="checkbox" id="checkbox15"><label for="checkbox15">Design agent workflow (LangGraph state machine)</label></li>
<li><input type="checkbox" id="checkbox16"><label for="checkbox16">Implement context builder (parallel data collection)</label></li>
<li><input type="checkbox" id="checkbox17"><label for="checkbox17">Write initial prompt for reasoning</label></li>
<li><input type="checkbox" id="checkbox18"><label for="checkbox18">Implement structured output parsing (Pydantic)</label></li>
<li><input type="checkbox" id="checkbox19"><label for="checkbox19">Basic workflow selection logic</label></li>
<li><input type="checkbox" id="checkbox20"><label for="checkbox20">End-to-end test with 5 test cases</label></li>
<li><input type="checkbox" id="checkbox21"><label for="checkbox21">CLI tool for testing recommendations</label></li>
</ul>
<p><strong>MVP Scope:</strong></p>
<ul>
<li>Analyze CPA changes only (simplest case)</li>
<li>Recommend from 2 workflows: bid adjustment vs. creative refresh</li>
<li>Manual prompt iteration based on outputs</li>
</ul>
<p><strong>Success Metrics:</strong></p>
<ul>
<li>Generate valid recommendation for test cases</li>
<li>Reasoning is explainable and accurate (human eval)</li>
<li>&lt;30s latency</li>
</ul>
<hr>
<h3 id="phase-3%3A-evaluation-framework-(week-9-12)" tabindex="-1">Phase 3: Evaluation Framework (Week 9-12)</h3>
<p><strong>Goal:</strong> Systematic quality measurement</p>
<p><strong>Tasks:</strong></p>
<ul>
<li><input type="checkbox" id="checkbox22"><label for="checkbox22">Build golden dataset (20+ historical cases)</label></li>
<li><input type="checkbox" id="checkbox23"><label for="checkbox23">Implement evaluation pipeline</label></li>
<li><input type="checkbox" id="checkbox24"><label for="checkbox24">Define evaluation metrics (accuracy, agreement)</label></li>
<li><input type="checkbox" id="checkbox25"><label for="checkbox25">LangSmith integration for LLM tracing</label></li>
<li><input type="checkbox" id="checkbox26"><label for="checkbox26">promptfoo configuration for regression testing</label></li>
<li><input type="checkbox" id="checkbox27"><label for="checkbox27">Automated eval in CI/CD</label></li>
<li><input type="checkbox" id="checkbox28"><label for="checkbox28">Evaluation dashboard</label></li>
</ul>
<p><strong>Evaluation Types:</strong></p>
<ol>
<li>
<p><strong>Golden Set Testing:</strong></p>
<ul>
<li>Historical scenarios with known outcomes</li>
<li>Compare agent decision to actual human decision</li>
<li>Measure: Agreement rate, precision, recall</li>
</ul>
</li>
<li>
<p><strong>LLM-as-Judge:</strong></p>
<ul>
<li>Use GPT-4 to evaluate reasoning quality</li>
<li>Prompts: "Is the reasoning logically sound?", "Are conclusions supported by evidence?"</li>
</ul>
</li>
<li>
<p><strong>Outcome Tracking:</strong></p>
<ul>
<li>After workflow execution, did metrics improve?</li>
<li>Compare predicted vs. actual impact</li>
</ul>
</li>
</ol>
<p><strong>Deliverables:</strong></p>
<ul>
<li>Eval runs on every PR</li>
<li>Quality regression alerts</li>
<li>Acceptance threshold (&gt;70% agreement) enforced</li>
</ul>
<hr>
<h3 id="phase-4%3A-production-api-%26-ui-(week-13-16)" tabindex="-1">Phase 4: Production API &amp; UI (Week 13-16)</h3>
<p><strong>Goal:</strong> User-facing system</p>
<p><strong>Tasks:</strong></p>
<ul>
<li><input type="checkbox" id="checkbox29"><label for="checkbox29">FastAPI endpoints (create recommendation, record decision)</label></li>
<li><input type="checkbox" id="checkbox30"><label for="checkbox30">Authentication &amp; authorization</label></li>
<li><input type="checkbox" id="checkbox31"><label for="checkbox31">Rate limiting</label></li>
<li><input type="checkbox" id="checkbox32"><label for="checkbox32">API documentation</label></li>
<li><input type="checkbox" id="checkbox33"><label for="checkbox33">Frontend: Recommendation cards UI</label></li>
<li><input type="checkbox" id="checkbox34"><label for="checkbox34">Frontend: Approve/reject flow</label></li>
<li><input type="checkbox" id="checkbox35"><label for="checkbox35">Frontend: Feedback submission</label></li>
<li><input type="checkbox" id="checkbox36"><label for="checkbox36">Notification system (email/Slack)</label></li>
</ul>
<p><strong>API Endpoints:</strong></p>
<pre class="hljs"><code><div>POST   /api/v1/recommendations/analyze
GET    /api/v1/recommendations/{id}
POST   /api/v1/recommendations/{id}/decision
GET    /api/v1/recommendations
GET    /api/v1/campaigns/{id}/history
</div></code></pre>
<p><strong>UI Views:</strong></p>
<ol>
<li><strong>Pending Recommendations</strong> - Queue of recommendations awaiting review</li>
<li><strong>Recommendation Detail</strong> - Full context, reasoning, approve/reject</li>
<li><strong>History</strong> - Past decisions and outcomes</li>
<li><strong>Analytics</strong> - Acceptance rates, impact tracking</li>
</ol>
<hr>
<h3 id="phase-5%3A-monitoring-%26-observability-(week-17-18)" tabindex="-1">Phase 5: Monitoring &amp; Observability (Week 17-18)</h3>
<p><strong>Goal:</strong> Visibility into production behavior</p>
<p><strong>Tasks:</strong></p>
<ul>
<li><input type="checkbox" id="checkbox37"><label for="checkbox37">LangSmith integration (LLM traces)</label></li>
<li><input type="checkbox" id="checkbox38"><label for="checkbox38">Prometheus metrics (business + system)</label></li>
<li><input type="checkbox" id="checkbox39"><label for="checkbox39">Grafana dashboards</label></li>
<li><input type="checkbox" id="checkbox40"><label for="checkbox40">Sentry error tracking</label></li>
<li><input type="checkbox" id="checkbox41"><label for="checkbox41">Alerting rules (PagerDuty/Slack)</label></li>
<li><input type="checkbox" id="checkbox42"><label for="checkbox42">Logging strategy (structured logs)</label></li>
<li><input type="checkbox" id="checkbox43"><label for="checkbox43">Debug tools (replay workflows)</label></li>
</ul>
<p><strong>Key Dashboards:</strong></p>
<ol>
<li>
<p><strong>Business Metrics:</strong></p>
<ul>
<li>Recommendations per day</li>
<li>Acceptance rate over time</li>
<li>Average confidence scores</li>
<li>Workflow distribution</li>
</ul>
</li>
<li>
<p><strong>Quality Metrics:</strong></p>
<ul>
<li>Latency (p50, p95, p99)</li>
<li>Error rates</li>
<li>LLM token usage/costs</li>
<li>Cache hit rates</li>
</ul>
</li>
<li>
<p><strong>Impact Metrics:</strong></p>
<ul>
<li>Campaigns with agent recommendations</li>
<li>Metric improvements when followed</li>
<li>Time saved for marketing team</li>
</ul>
</li>
</ol>
<hr>
<h3 id="phase-6%3A-advanced-features-(week-19-24)" tabindex="-1">Phase 6: Advanced Features (Week 19-24)</h3>
<p><strong>Goal:</strong> Robust, intelligent system</p>
<p><strong>Tasks:</strong></p>
<ul>
<li><input type="checkbox" id="checkbox44"><label for="checkbox44">Multi-signal reasoning (beyond just CPA)</label></li>
<li><input type="checkbox" id="checkbox45"><label for="checkbox45">Support all workflow types</label></li>
<li><input type="checkbox" id="checkbox46"><label for="checkbox46">Confidence calibration</label></li>
<li><input type="checkbox" id="checkbox47"><label for="checkbox47">Alternative recommendation ranking</label></li>
<li><input type="checkbox" id="checkbox48"><label for="checkbox48">Batch processing mode</label></li>
<li><input type="checkbox" id="checkbox49"><label for="checkbox49">Scheduled analysis (daily health checks)</label></li>
<li><input type="checkbox" id="checkbox50"><label for="checkbox50">Advanced caching strategies</label></li>
<li><input type="checkbox" id="checkbox51"><label for="checkbox51">Cost optimization (model selection)</label></li>
</ul>
<p><strong>Advanced Prompt Engineering:</strong></p>
<ul>
<li>Few-shot examples from historical cases</li>
<li>Chain-of-thought reasoning</li>
<li>Self-critique/refinement loop</li>
<li>Prompt versioning and A/B testing</li>
</ul>
<hr>
<h3 id="phase-7%3A-trust-building-%26-iteration-(month-7%2B)" tabindex="-1">Phase 7: Trust Building &amp; Iteration (Month 7+)</h3>
<p><strong>Goal:</strong> Reliable recommendations, reduced oversight</p>
<p><strong>Continuous Activities:</strong></p>
<ul>
<li>Weekly feedback sessions with marketing team</li>
<li>Bi-weekly prompt improvements based on failures</li>
<li>Monthly evaluation report (quality trends)</li>
<li>Identify patterns for graduated autonomy</li>
<li>Document learnings</li>
</ul>
<p><strong>Graduated Autonomy Criteria:</strong></p>
<ul>
<li>Scenario: "High-confidence, low-risk recommendations"</li>
<li>Requirements:
<ul>
<li>
<blockquote>
<p>85% acceptance rate over 4 weeks</p>
</blockquote>
</li>
<li>
<blockquote>
<p>90% positive impact when followed</p>
</blockquote>
</li>
<li>Confidence score &gt;0.85</li>
<li>Risk level = "low"</li>
</ul>
</li>
<li>Action: Auto-approve (with notification)</li>
</ul>
<hr>
<h2 id="5.-data-integration-layer" tabindex="-1">5. Data Integration Layer</h2>
<h3 id="5.1-collector-architecture" tabindex="-1">5.1 Collector Architecture</h3>
<p>Each data source has a dedicated collector following this interface:</p>
<pre class="hljs"><code><div><span class="hljs-comment"># src/data_collectors/base.py</span>
<span class="hljs-keyword">from</span> abc <span class="hljs-keyword">import</span> ABC, abstractmethod
<span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Generic</span>, TypeVar
<span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime

T = TypeVar(<span class="hljs-string">'T'</span>)

<span class="hljs-keyword">class</span> <span class="hljs-title class_">BaseCollector</span>(ABC, <span class="hljs-type">Generic</span>[T]):
    <span class="hljs-string">"""Base class for all data collectors"""</span>
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, cache_ttl: <span class="hljs-built_in">int</span> = <span class="hljs-number">300</span></span>):
        <span class="hljs-variable language_">self</span>.cache_ttl = cache_ttl
        <span class="hljs-variable language_">self</span>.client = <span class="hljs-literal">None</span>
    
<span class="hljs-meta">    @abstractmethod</span>
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">collect</span>(<span class="hljs-params">self, campaign_id: <span class="hljs-built_in">str</span>, **kwargs</span>) -&gt; T:
        <span class="hljs-string">"""Fetch data for a campaign"""</span>
        <span class="hljs-keyword">pass</span>
    
<span class="hljs-meta">    @abstractmethod</span>
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">health_check</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">bool</span>:
        <span class="hljs-string">"""Check if data source is accessible"""</span>
        <span class="hljs-keyword">pass</span>
    
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">collect_with_retry</span>(<span class="hljs-params">
        self, 
        campaign_id: <span class="hljs-built_in">str</span>, 
        max_retries: <span class="hljs-built_in">int</span> = <span class="hljs-number">3</span>,
        **kwargs
    </span>) -&gt; T | <span class="hljs-literal">None</span>:
        <span class="hljs-string">"""Collect with exponential backoff retry"""</span>
        <span class="hljs-keyword">from</span> tenacity <span class="hljs-keyword">import</span> retry, stop_after_attempt, wait_exponential
        
<span class="hljs-meta">        @retry(<span class="hljs-params">
            stop=stop_after_attempt(<span class="hljs-params">max_retries</span>),
            wait=wait_exponential(<span class="hljs-params">multiplier=<span class="hljs-number">1</span>, <span class="hljs-built_in">min</span>=<span class="hljs-number">2</span>, <span class="hljs-built_in">max</span>=<span class="hljs-number">10</span></span>)
        </span>)</span>
        <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">_collect</span>():
            <span class="hljs-keyword">return</span> <span class="hljs-keyword">await</span> <span class="hljs-variable language_">self</span>.collect(campaign_id, **kwargs)
        
        <span class="hljs-keyword">try</span>:
            <span class="hljs-keyword">return</span> <span class="hljs-keyword">await</span> _collect()
        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
            logger.error(<span class="hljs-string">f"Failed to collect data after <span class="hljs-subst">{max_retries}</span> retries"</span>, 
                        error=<span class="hljs-built_in">str</span>(e), campaign_id=campaign_id)
            <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span>
</div></code></pre>
<h3 id="5.2-campaign-metrics-collector" tabindex="-1">5.2 Campaign Metrics Collector</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># src/data_collectors/campaign_collector.py</span>
<span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime, timedelta
<span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel
<span class="hljs-keyword">import</span> httpx

<span class="hljs-keyword">class</span> <span class="hljs-title class_">CampaignMetrics</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):
    <span class="hljs-string">"""Campaign performance metrics"""</span>
    campaign_id: <span class="hljs-built_in">str</span>
    campaign_name: <span class="hljs-built_in">str</span>
    
    <span class="hljs-comment"># Core metrics</span>
    spend: <span class="hljs-built_in">float</span>
    impressions: <span class="hljs-built_in">int</span>
    clicks: <span class="hljs-built_in">int</span>
    conversions: <span class="hljs-built_in">int</span>
    cpa: <span class="hljs-built_in">float</span>
    ctr: <span class="hljs-built_in">float</span>
    conversion_rate: <span class="hljs-built_in">float</span>
    
    <span class="hljs-comment"># Trends (vs. previous period)</span>
    cpa_change_pct: <span class="hljs-built_in">float</span>
    cpa_trend_days: <span class="hljs-built_in">int</span>  <span class="hljs-comment"># Days CPA has been trending</span>
    spend_change_pct: <span class="hljs-built_in">float</span>
    
    <span class="hljs-comment"># Context</span>
    daily_budget: <span class="hljs-built_in">float</span>
    budget_utilization: <span class="hljs-built_in">float</span>
    impression_share: <span class="hljs-built_in">float</span>
    
    <span class="hljs-comment"># Time range</span>
    period_start: datetime
    period_end: datetime
    comparison_period_start: datetime
    comparison_period_end: datetime

<span class="hljs-keyword">class</span> <span class="hljs-title class_">CampaignMetricsCollector</span>(BaseCollector[CampaignMetrics]):
    <span class="hljs-string">"""Collect campaign performance data from ad platforms"""</span>
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, api_key: <span class="hljs-built_in">str</span>, cache_ttl: <span class="hljs-built_in">int</span> = <span class="hljs-number">300</span></span>):
        <span class="hljs-built_in">super</span>().__init__(cache_ttl)
        <span class="hljs-variable language_">self</span>.api_key = api_key
        <span class="hljs-variable language_">self</span>.client = httpx.AsyncClient(
            base_url=<span class="hljs-string">"https://ads-api.example.com"</span>,
            headers={<span class="hljs-string">"Authorization"</span>: <span class="hljs-string">f"Bearer <span class="hljs-subst">{api_key}</span>"</span>}
        )
    
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">collect</span>(<span class="hljs-params">
        self, 
        campaign_id: <span class="hljs-built_in">str</span>,
        lookback_days: <span class="hljs-built_in">int</span> = <span class="hljs-number">7</span>
    </span>) -&gt; CampaignMetrics:
        <span class="hljs-string">"""
        Fetch campaign metrics for recent period + comparison period
        
        Args:
            campaign_id: Campaign identifier
            lookback_days: Days of data to analyze
        
        Returns:
            CampaignMetrics with current and comparison data
        """</span>
        end_date = datetime.utcnow()
        start_date = end_date - timedelta(days=lookback_days)
        comparison_end = start_date
        comparison_start = comparison_end - timedelta(days=lookback_days)
        
        <span class="hljs-comment"># Fetch current period</span>
        current_data = <span class="hljs-keyword">await</span> <span class="hljs-variable language_">self</span>._fetch_metrics(
            campaign_id, start_date, end_date
        )
        
        <span class="hljs-comment"># Fetch comparison period</span>
        comparison_data = <span class="hljs-keyword">await</span> <span class="hljs-variable language_">self</span>._fetch_metrics(
            campaign_id, comparison_start, comparison_end
        )
        
        <span class="hljs-comment"># Calculate changes</span>
        cpa_change_pct = (
            (current_data[<span class="hljs-string">'cpa'</span>] - comparison_data[<span class="hljs-string">'cpa'</span>]) 
            / comparison_data[<span class="hljs-string">'cpa'</span>] * <span class="hljs-number">100</span>
        ) <span class="hljs-keyword">if</span> comparison_data[<span class="hljs-string">'cpa'</span>] &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>
        
        spend_change_pct = (
            (current_data[<span class="hljs-string">'spend'</span>] - comparison_data[<span class="hljs-string">'spend'</span>])
            / comparison_data[<span class="hljs-string">'spend'</span>] * <span class="hljs-number">100</span>
        ) <span class="hljs-keyword">if</span> comparison_data[<span class="hljs-string">'spend'</span>] &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>
        
        <span class="hljs-comment"># Detect trend duration</span>
        cpa_trend_days = <span class="hljs-keyword">await</span> <span class="hljs-variable language_">self</span>._calculate_trend_duration(
            campaign_id, <span class="hljs-string">'cpa'</span>, direction=<span class="hljs-string">'increasing'</span>
        )
        
        <span class="hljs-keyword">return</span> CampaignMetrics(
            campaign_id=campaign_id,
            campaign_name=current_data[<span class="hljs-string">'name'</span>],
            spend=current_data[<span class="hljs-string">'spend'</span>],
            impressions=current_data[<span class="hljs-string">'impressions'</span>],
            clicks=current_data[<span class="hljs-string">'clicks'</span>],
            conversions=current_data[<span class="hljs-string">'conversions'</span>],
            cpa=current_data[<span class="hljs-string">'cpa'</span>],
            ctr=current_data[<span class="hljs-string">'ctr'</span>],
            conversion_rate=current_data[<span class="hljs-string">'conversion_rate'</span>],
            cpa_change_pct=cpa_change_pct,
            cpa_trend_days=cpa_trend_days,
            spend_change_pct=spend_change_pct,
            daily_budget=current_data[<span class="hljs-string">'daily_budget'</span>],
            budget_utilization=current_data[<span class="hljs-string">'budget_utilization'</span>],
            impression_share=current_data[<span class="hljs-string">'impression_share'</span>],
            period_start=start_date,
            period_end=end_date,
            comparison_period_start=comparison_start,
            comparison_period_end=comparison_end
        )
    
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">_fetch_metrics</span>(<span class="hljs-params">
        self, 
        campaign_id: <span class="hljs-built_in">str</span>,
        start_date: datetime,
        end_date: datetime
    </span>) -&gt; <span class="hljs-built_in">dict</span>:
        <span class="hljs-string">"""Internal: Fetch raw metrics from API"""</span>
        response = <span class="hljs-keyword">await</span> <span class="hljs-variable language_">self</span>.client.get(
            <span class="hljs-string">f"/campaigns/<span class="hljs-subst">{campaign_id}</span>/metrics"</span>,
            params={
                <span class="hljs-string">"start_date"</span>: start_date.isoformat(),
                <span class="hljs-string">"end_date"</span>: end_date.isoformat()
            }
        )
        response.raise_for_status()
        <span class="hljs-keyword">return</span> response.json()
    
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">_calculate_trend_duration</span>(<span class="hljs-params">
        self,
        campaign_id: <span class="hljs-built_in">str</span>,
        metric: <span class="hljs-built_in">str</span>,
        direction: <span class="hljs-built_in">str</span>
    </span>) -&gt; <span class="hljs-built_in">int</span>:
        <span class="hljs-string">"""Calculate how many consecutive days metric has been trending"""</span>
        <span class="hljs-comment"># Fetch daily data for last 30 days</span>
        daily_data = <span class="hljs-keyword">await</span> <span class="hljs-variable language_">self</span>._fetch_daily_metrics(campaign_id, days=<span class="hljs-number">30</span>)
        
        trend_days = <span class="hljs-number">0</span>
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(daily_data) - <span class="hljs-number">1</span>):
            current = daily_data[i][metric]
            previous = daily_data[i + <span class="hljs-number">1</span>][metric]
            
            <span class="hljs-keyword">if</span> direction == <span class="hljs-string">'increasing'</span> <span class="hljs-keyword">and</span> current &gt; previous:
                trend_days += <span class="hljs-number">1</span>
            <span class="hljs-keyword">elif</span> direction == <span class="hljs-string">'decreasing'</span> <span class="hljs-keyword">and</span> current &lt; previous:
                trend_days += <span class="hljs-number">1</span>
            <span class="hljs-keyword">else</span>:
                <span class="hljs-keyword">break</span>
        
        <span class="hljs-keyword">return</span> trend_days
    
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">health_check</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">bool</span>:
        <span class="hljs-string">"""Check if API is accessible"""</span>
        <span class="hljs-keyword">try</span>:
            response = <span class="hljs-keyword">await</span> <span class="hljs-variable language_">self</span>.client.get(<span class="hljs-string">"/health"</span>)
            <span class="hljs-keyword">return</span> response.status_code == <span class="hljs-number">200</span>
        <span class="hljs-keyword">except</span> Exception:
            <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span>
</div></code></pre>
<h3 id="5.3-creative-performance-collector" tabindex="-1">5.3 Creative Performance Collector</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># src/data_collectors/creative_collector.py</span>
<span class="hljs-keyword">from</span> enum <span class="hljs-keyword">import</span> Enum

<span class="hljs-keyword">class</span> <span class="hljs-title class_">CreativeTrend</span>(<span class="hljs-built_in">str</span>, Enum):
    IMPROVING = <span class="hljs-string">"improving"</span>
    STABLE = <span class="hljs-string">"stable"</span>
    DECLINING = <span class="hljs-string">"declining"</span>

<span class="hljs-keyword">class</span> <span class="hljs-title class_">CreativeMetrics</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):
    <span class="hljs-string">"""Creative performance and fatigue indicators"""</span>
    campaign_id: <span class="hljs-built_in">str</span>
    creative_id: <span class="hljs-built_in">str</span>
    creative_name: <span class="hljs-built_in">str</span>
    
    <span class="hljs-comment"># Performance</span>
    ctr: <span class="hljs-built_in">float</span>
    engagement_rate: <span class="hljs-built_in">float</span>
    video_completion_rate: <span class="hljs-built_in">float</span> | <span class="hljs-literal">None</span>
    
    <span class="hljs-comment"># Trends</span>
    ctr_trend: CreativeTrend
    ctr_change_pct: <span class="hljs-built_in">float</span>
    
    <span class="hljs-comment"># Fatigue indicators</span>
    creative_age_days: <span class="hljs-built_in">int</span>
    average_frequency: <span class="hljs-built_in">float</span>  <span class="hljs-comment"># Impressions per unique user</span>
    frequency_trend: <span class="hljs-built_in">str</span>  <span class="hljs-comment"># "increasing", "stable", "decreasing"</span>
    
    <span class="hljs-comment"># Context</span>
    total_impressions: <span class="hljs-built_in">int</span>
    unique_reach: <span class="hljs-built_in">int</span>
    
    <span class="hljs-comment"># Freshness</span>
    last_updated: datetime

<span class="hljs-keyword">class</span> <span class="hljs-title class_">CreativeMetricsCollector</span>(BaseCollector[CreativeMetrics]):
    <span class="hljs-string">"""Collect creative performance and fatigue signals"""</span>
    
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">collect</span>(<span class="hljs-params">self, campaign_id: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">list</span>[CreativeMetrics]:
        <span class="hljs-string">"""
        Fetch all creative metrics for a campaign
        
        Returns list (one per creative)
        """</span>
        <span class="hljs-comment"># Implementation similar to CampaignMetricsCollector</span>
        <span class="hljs-keyword">pass</span>
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">analyze_fatigue</span>(<span class="hljs-params">self, metrics: CreativeMetrics</span>) -&gt; <span class="hljs-built_in">dict</span>:
        <span class="hljs-string">"""
        Analyze if creative is showing fatigue
        
        Returns:
            {
                "is_fatigued": bool,
                "confidence": float,
                "signals": list[str]
            }
        """</span>
        signals = []
        fatigue_score = <span class="hljs-number">0</span>
        
        <span class="hljs-comment"># Check age</span>
        <span class="hljs-keyword">if</span> metrics.creative_age_days &gt; <span class="hljs-number">30</span>:
            signals.append(<span class="hljs-string">f"Creative is <span class="hljs-subst">{metrics.creative_age_days}</span> days old"</span>)
            fatigue_score += <span class="hljs-number">0.3</span>
        
        <span class="hljs-comment"># Check CTR decline</span>
        <span class="hljs-keyword">if</span> metrics.ctr_trend == CreativeTrend.DECLINING:
            signals.append(<span class="hljs-string">f"CTR declining: <span class="hljs-subst">{metrics.ctr_change_pct:<span class="hljs-number">.1</span>f}</span>% drop"</span>)
            fatigue_score += <span class="hljs-number">0.4</span>
        
        <span class="hljs-comment"># Check frequency</span>
        <span class="hljs-keyword">if</span> metrics.average_frequency &gt; <span class="hljs-number">5.0</span>:
            signals.append(<span class="hljs-string">f"High frequency: <span class="hljs-subst">{metrics.average_frequency:<span class="hljs-number">.1</span>f}</span>"</span>)
            fatigue_score += <span class="hljs-number">0.3</span>
        
        <span class="hljs-keyword">return</span> {
            <span class="hljs-string">"is_fatigued"</span>: fatigue_score &gt; <span class="hljs-number">0.5</span>,
            <span class="hljs-string">"confidence"</span>: fatigue_score,
            <span class="hljs-string">"signals"</span>: signals
        }
</div></code></pre>
<h3 id="5.4-competitor-signals-collector" tabindex="-1">5.4 Competitor Signals Collector</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># src/data_collectors/competitor_collector.py</span>

<span class="hljs-keyword">class</span> <span class="hljs-title class_">CompetitorSignals</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):
    <span class="hljs-string">"""Competitor activity indicators"""</span>
    industry: <span class="hljs-built_in">str</span>
    keywords: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">str</span>]
    
    <span class="hljs-comment"># Activity metrics</span>
    active_competitors_count: <span class="hljs-built_in">int</span>
    new_competitors_count: <span class="hljs-built_in">int</span>  <span class="hljs-comment"># Last 7 days</span>
    activity_change_pct: <span class="hljs-built_in">float</span>  <span class="hljs-comment"># Overall market activity</span>
    
    <span class="hljs-comment"># Bidding indicators</span>
    avg_bid_increase_pct: <span class="hljs-built_in">float</span>
    top_competitor_bids: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">dict</span>]
    
    <span class="hljs-comment"># Ad creative activity</span>
    new_ads_count: <span class="hljs-built_in">int</span>
    creative_refreshes: <span class="hljs-built_in">int</span>
    
    <span class="hljs-comment"># Context</span>
    analysis_period_days: <span class="hljs-built_in">int</span>
    last_updated: datetime

<span class="hljs-keyword">class</span> <span class="hljs-title class_">CompetitorSignalsCollector</span>(BaseCollector[CompetitorSignals]):
    <span class="hljs-string">"""
    Collect competitor intelligence from tools like:
    - SEMrush API
    - SpyFu API
    - Google Ads Auction Insights
    - Meta Ad Library
    """</span>
    
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">collect</span>(<span class="hljs-params">
        self,
        campaign_id: <span class="hljs-built_in">str</span>,
        industry: <span class="hljs-built_in">str</span>,
        keywords: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">str</span>]
    </span>) -&gt; CompetitorSignals:
        <span class="hljs-string">"""Aggregate competitor signals from multiple sources"""</span>
        
        <span class="hljs-comment"># Example: Fetch from multiple sources in parallel</span>
        results = <span class="hljs-keyword">await</span> asyncio.gather(
            <span class="hljs-variable language_">self</span>._fetch_semrush_data(keywords),
            <span class="hljs-variable language_">self</span>._fetch_auction_insights(campaign_id),
            <span class="hljs-variable language_">self</span>._fetch_ad_library_trends(industry),
            return_exceptions=<span class="hljs-literal">True</span>
        )
        
        <span class="hljs-comment"># Aggregate and normalize</span>
        <span class="hljs-comment"># ...</span>
        
        <span class="hljs-keyword">return</span> CompetitorSignals(...)
</div></code></pre>
<h3 id="5.5-parallel-context-collection" tabindex="-1">5.5 Parallel Context Collection</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># src/agent/context_builder.py</span>
<span class="hljs-keyword">import</span> asyncio
<span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> TypedDict

<span class="hljs-keyword">class</span> <span class="hljs-title class_">CampaignContext</span>(<span class="hljs-title class_ inherited__">TypedDict</span>):
    <span class="hljs-string">"""Complete context for a campaign analysis"""</span>
    campaign_id: <span class="hljs-built_in">str</span>
    campaign_metrics: CampaignMetrics
    creative_metrics: <span class="hljs-built_in">list</span>[CreativeMetrics]
    competitor_signals: CompetitorSignals
    audience_analytics: AudienceAnalytics
    historical_patterns: HistoricalPatterns

<span class="hljs-keyword">class</span> <span class="hljs-title class_">ContextBuilder</span>:
    <span class="hljs-string">"""Orchestrate parallel data collection from all sources"""</span>
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">
        self,
        campaign_collector: CampaignMetricsCollector,
        creative_collector: CreativeMetricsCollector,
        competitor_collector: CompetitorSignalsCollector,
        audience_collector: AudienceAnalyticsCollector,
        historical_analyzer: HistoricalPatternAnalyzer
    </span>):
        <span class="hljs-variable language_">self</span>.campaign_collector = campaign_collector
        <span class="hljs-variable language_">self</span>.creative_collector = creative_collector
        <span class="hljs-variable language_">self</span>.competitor_collector = competitor_collector
        <span class="hljs-variable language_">self</span>.audience_collector = audience_collector
        <span class="hljs-variable language_">self</span>.historical_analyzer = historical_analyzer
    
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">build_context</span>(<span class="hljs-params">
        self, 
        campaign_id: <span class="hljs-built_in">str</span>
    </span>) -&gt; CampaignContext:
        <span class="hljs-string">"""
        Collect all context data in parallel
        
        Handles failures gracefully - partial context is OK
        """</span>
        <span class="hljs-comment"># Execute all collectors in parallel</span>
        results = <span class="hljs-keyword">await</span> asyncio.gather(
            <span class="hljs-variable language_">self</span>.campaign_collector.collect_with_retry(campaign_id),
            <span class="hljs-variable language_">self</span>.creative_collector.collect_with_retry(campaign_id),
            <span class="hljs-variable language_">self</span>._collect_competitor_data(campaign_id),
            <span class="hljs-variable language_">self</span>.audience_collector.collect_with_retry(campaign_id),
            <span class="hljs-variable language_">self</span>.historical_analyzer.analyze(campaign_id),
            return_exceptions=<span class="hljs-literal">True</span>  <span class="hljs-comment"># Don't fail if one collector fails</span>
        )
        
        <span class="hljs-comment"># Unpack results (handle None from failures)</span>
        campaign_metrics, creative_metrics, competitor_signals, \
            audience_analytics, historical_patterns = results
        
        <span class="hljs-comment"># Log any failures but continue</span>
        <span class="hljs-keyword">for</span> i, result <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(results):
            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(result, Exception):
                logger.warning(
                    <span class="hljs-string">f"Collector <span class="hljs-subst">{i}</span> failed"</span>,
                    error=<span class="hljs-built_in">str</span>(result),
                    campaign_id=campaign_id
                )
        
        <span class="hljs-keyword">return</span> CampaignContext(
            campaign_id=campaign_id,
            campaign_metrics=campaign_metrics,
            creative_metrics=creative_metrics <span class="hljs-keyword">or</span> [],
            competitor_signals=competitor_signals,
            audience_analytics=audience_analytics,
            historical_patterns=historical_patterns
        )
    
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">_collect_competitor_data</span>(<span class="hljs-params">self, campaign_id: <span class="hljs-built_in">str</span></span>):
        <span class="hljs-string">"""Helper to get industry/keywords from campaign first"""</span>
        <span class="hljs-comment"># Fetch campaign details to get industry and keywords</span>
        campaign_info = <span class="hljs-keyword">await</span> <span class="hljs-variable language_">self</span>._get_campaign_info(campaign_id)
        
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">await</span> <span class="hljs-variable language_">self</span>.competitor_collector.collect_with_retry(
            campaign_id=campaign_id,
            industry=campaign_info[<span class="hljs-string">'industry'</span>],
            keywords=campaign_info[<span class="hljs-string">'keywords'</span>]
        )
</div></code></pre>
<p><strong>Performance Expectations:</strong></p>
<ul>
<li>Parallel collection: ~5-10s total (vs. 20-30s sequential)</li>
<li>Graceful degradation: Agent can reason with partial context</li>
<li>Caching: Similar campaigns share competitor/historical data</li>
</ul>
<hr>
<h2 id="6.-agent-design-%26-prompting" tabindex="-1">6. Agent Design &amp; Prompting</h2>
<h3 id="6.1-langgraph-workflow" tabindex="-1">6.1 LangGraph Workflow</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># src/agent/workflow.py</span>
<span class="hljs-keyword">from</span> langgraph.graph <span class="hljs-keyword">import</span> StateGraph, END
<span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Literal</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">create_marketing_agent</span>() -&gt; StateGraph:
    <span class="hljs-string">"""Create the marketing reasoning agent workflow"""</span>
    
    <span class="hljs-comment"># Initialize workflow</span>
    workflow = StateGraph(AgentState)
    
    <span class="hljs-comment"># Add nodes</span>
    workflow.add_node(<span class="hljs-string">"collect_context"</span>, collect_context_node)
    workflow.add_node(<span class="hljs-string">"analyze_signals"</span>, analyze_signals_node)
    workflow.add_node(<span class="hljs-string">"generate_recommendation"</span>, generate_recommendation_node)
    workflow.add_node(<span class="hljs-string">"critique"</span>, critique_recommendation_node)
    workflow.add_node(<span class="hljs-string">"validate"</span>, validate_output_node)
    
    <span class="hljs-comment"># Define edges</span>
    workflow.set_entry_point(<span class="hljs-string">"collect_context"</span>)
    workflow.add_edge(<span class="hljs-string">"collect_context"</span>, <span class="hljs-string">"analyze_signals"</span>)
    workflow.add_edge(<span class="hljs-string">"analyze_signals"</span>, <span class="hljs-string">"generate_recommendation"</span>)
    workflow.add_edge(<span class="hljs-string">"generate_recommendation"</span>, <span class="hljs-string">"critique"</span>)
    
    <span class="hljs-comment"># Conditional edge: Regenerate if needed</span>
    workflow.add_conditional_edges(
        <span class="hljs-string">"critique"</span>,
        should_regenerate,
        {
            <span class="hljs-string">"regenerate"</span>: <span class="hljs-string">"analyze_signals"</span>,
            <span class="hljs-string">"validate"</span>: <span class="hljs-string">"validate"</span>
        }
    )
    
    workflow.add_edge(<span class="hljs-string">"validate"</span>, END)
    
    <span class="hljs-keyword">return</span> workflow.<span class="hljs-built_in">compile</span>()

<span class="hljs-comment"># Node implementations</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">collect_context_node</span>(<span class="hljs-params">state: AgentState</span>) -&gt; AgentState:
    <span class="hljs-string">"""Collect all campaign context in parallel"""</span>
    context_builder = ContextBuilder(...)  <span class="hljs-comment"># Inject dependencies</span>
    context = <span class="hljs-keyword">await</span> context_builder.build_context(state[<span class="hljs-string">"campaign_id"</span>])
    
    <span class="hljs-keyword">return</span> {
        **state,
        <span class="hljs-string">"campaign_metrics"</span>: context[<span class="hljs-string">"campaign_metrics"</span>],
        <span class="hljs-string">"creative_metrics"</span>: context[<span class="hljs-string">"creative_metrics"</span>],
        <span class="hljs-string">"competitor_signals"</span>: context[<span class="hljs-string">"competitor_signals"</span>],
        <span class="hljs-string">"audience_analytics"</span>: context[<span class="hljs-string">"audience_analytics"</span>],
        <span class="hljs-string">"historical_patterns"</span>: context[<span class="hljs-string">"historical_patterns"</span>]
    }

<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">analyze_signals_node</span>(<span class="hljs-params">state: AgentState</span>) -&gt; AgentState:
    <span class="hljs-string">"""LLM-powered signal analysis"""</span>
    <span class="hljs-keyword">from</span> langchain_openai <span class="hljs-keyword">import</span> ChatOpenAI
    <span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> ChatPromptTemplate
    
    llm = ChatOpenAI(model=<span class="hljs-string">"gpt-4o"</span>, temperature=<span class="hljs-number">0.1</span>)
    
    prompt = ChatPromptTemplate.from_messages([
        (<span class="hljs-string">"system"</span>, SIGNAL_ANALYSIS_PROMPT),
        (<span class="hljs-string">"user"</span>, format_context_for_llm(state))
    ])
    
    response = <span class="hljs-keyword">await</span> llm.ainvoke(prompt.format_messages())
    
    <span class="hljs-comment"># Parse structured response</span>
    analysis = parse_signal_analysis(response.content)
    
    <span class="hljs-keyword">return</span> {
        **state,
        <span class="hljs-string">"signal_analysis"</span>: analysis[<span class="hljs-string">"analysis"</span>],
        <span class="hljs-string">"root_cause_hypothesis"</span>: analysis[<span class="hljs-string">"root_cause"</span>],
        <span class="hljs-string">"confidence_score"</span>: analysis[<span class="hljs-string">"confidence"</span>]
    }

<span class="hljs-keyword">def</span> <span class="hljs-title function_">should_regenerate</span>(<span class="hljs-params">state: AgentState</span>) -&gt; <span class="hljs-type">Literal</span>[<span class="hljs-string">"regenerate"</span>, <span class="hljs-string">"validate"</span>]:
    <span class="hljs-string">"""Decide if recommendation needs regeneration"""</span>
    iteration_count = state.get(<span class="hljs-string">"iteration_count"</span>, <span class="hljs-number">0</span>)
    confidence = state.get(<span class="hljs-string">"confidence_score"</span>, <span class="hljs-number">0</span>)
    critique_feedback = state.get(<span class="hljs-string">"critique_feedback"</span>)
    
    <span class="hljs-comment"># Max 2 iterations</span>
    <span class="hljs-keyword">if</span> iteration_count &gt;= <span class="hljs-number">2</span>:
        <span class="hljs-keyword">return</span> <span class="hljs-string">"validate"</span>
    
    <span class="hljs-comment"># Regenerate if low confidence or critical issues</span>
    <span class="hljs-keyword">if</span> confidence &lt; <span class="hljs-number">0.6</span> <span class="hljs-keyword">or</span> (critique_feedback <span class="hljs-keyword">and</span> <span class="hljs-string">"CRITICAL"</span> <span class="hljs-keyword">in</span> critique_feedback):
        <span class="hljs-keyword">return</span> <span class="hljs-string">"regenerate"</span>
    
    <span class="hljs-keyword">return</span> <span class="hljs-string">"validate"</span>
</div></code></pre>
<h3 id="6.2-core-system-prompt" tabindex="-1">6.2 Core System Prompt</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># src/agent/prompts.py</span>

SIGNAL_ANALYSIS_PROMPT = <span class="hljs-string">"""You are an expert marketing performance analyst specializing in paid advertising campaigns.

Your task is to analyze campaign performance data and identify the root cause of any performance changes.

## Available Workflows

You can recommend one of the following actions:
1. **Creative Refresh** - Replace or update ad creatives
2. **Audience Expansion** - Broaden targeting to reach new users
3. **Bid Adjustment** - Increase or decrease bidding strategy
4. **Campaign Pause** - Stop campaign temporarily
5. **Budget Reallocation** - Shift budget to better-performing segments
6. **Continue Monitoring** - No action needed, continue observing

## Analysis Framework

Consider these factors in your analysis:

### 1. Metric Changes
- Magnitude: How significant is the change? (&gt;10% = significant, &gt;30% = critical)
- Duration: How many days has the trend persisted? (3+ days = established trend)
- Velocity: Is the change accelerating or stabilizing?

### 2. Signal Correlation
- Do multiple metrics point to the same issue?
- Are there contradictory signals that need reconciliation?
- What's the most parsimonious explanation?

### 3. Root Cause Hypotheses

**Creative Fatigue:**
- Declining CTR despite stable audience metrics
- Increasing frequency (&gt;5 impressions per user)
- Creative older than 30 days
- Engagement rates declining

**Audience Saturation:**
- High impression share (&gt;90%)
- Declining reach despite consistent budget
- Frequency increasing
- CPM increasing while CTR stable

**Competitive Pressure:**
- CPA/CPM increasing while creative performance stable
- Competitor activity up significantly (&gt;20%)
- Impression share declining
- Auction dynamics shifting

**Seasonal/External Factors:**
- Industry-wide trends
- Market events
- Historical patterns (e.g., day of week, time of year)

### 4. Historical Context
- How has this campaign performed previously?
- What actions worked in similar situations?
- Are there recurring patterns?

## Output Requirements

Provide your analysis in the following structured format:

```json
{
  "signal_analysis": "Detailed narrative of key signals and their relationships",
  "root_cause": "Primary hypothesis for performance change",
  "supporting_evidence": [
    "Evidence point 1",
    "Evidence point 2"
  ],
  "contradictory_evidence": [
    "Counter-signal 1 (if any)"
  ],
  "confidence": 0.85,
  "confidence_reasoning": "Why this confidence level"
}
</span></div></code></pre>
<h2 id="guidelines" tabindex="-1">Guidelines</h2>
<ol>
<li><strong>Be data-driven</strong>: Base conclusions on evidence, not assumptions</li>
<li><strong>Consider alternatives</strong>: What else could explain the data?</li>
<li><strong>Assess confidence honestly</strong>: Don't overstate certainty</li>
<li><strong>Think causally</strong>: Correlation ≠ causation</li>
<li><strong>Be specific</strong>: Vague reasoning helps no one</li>
</ol>
<h2 id="example" tabindex="-1">Example</h2>
<p><strong>Input:</strong></p>
<ul>
<li>CPA increased 30% (from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>45</mn><mi>t</mi><mi>o</mi></mrow><annotation encoding="application/x-tex">45 to </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">45</span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span></span></span></span>58.50) over 3 days</li>
<li>Creative CTR stable at 2.8%</li>
<li>Impression share 95%</li>
<li>Competitor activity up 40%</li>
<li>Frequency at 4.2 (not fatigued)</li>
</ul>
<p><strong>Good Analysis:</strong></p>
<pre class="hljs"><code><div><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">"signal_analysis"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"CPA spike coincides with increased competitive activity rather than creative fatigue. Creative CTR remains stable at 2.8%, indicating ads still resonate. Audience is near saturation (95% impression share), limiting expansion options. Frequency at 4.2 is within healthy range. Competitor analysis shows 3 new entrants and 25% avg bid increase in past week. This suggests auction environment has become more competitive, driving up costs without internal performance degradation."</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"root_cause"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Increased competitive pressure in auction environment"</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"supporting_evidence"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
    <span class="hljs-string">"Competitor activity +40% (3 new entrants)"</span><span class="hljs-punctuation">,</span>
    <span class="hljs-string">"CPA increase timing aligns with competitive surge"</span><span class="hljs-punctuation">,</span>
    <span class="hljs-string">"No creative fatigue signals (stable CTR, healthy frequency)"</span><span class="hljs-punctuation">,</span>
    <span class="hljs-string">"Audience near limit (95% IS) - saturation not the issue"</span>
  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"contradictory_evidence"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"confidence"</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.82</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"confidence_reasoning"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Strong signal correlation and clear timing alignment. Only uncertainty is whether competitive pressure will persist or is temporary."</span>
<span class="hljs-punctuation">}</span>
</div></code></pre>
<p>Now analyze the provided campaign data."""</p>
<p>RECOMMENDATION_GENERATION_PROMPT = """Based on your signal analysis, generate a specific, actionable recommendation.</p>
<h2 id="input" tabindex="-1">Input</h2>
<p>You will receive:</p>
<ul>
<li>Your signal analysis and root cause hypothesis</li>
<li>Campaign context and constraints</li>
<li>Historical effectiveness of different actions</li>
</ul>
<h2 id="output-format" tabindex="-1">Output Format</h2>
<pre class="hljs"><code><div><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">"recommended_workflow"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Bid Adjustment"</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"specific_action"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Increase bid by 15% from current $2.50 to $2.88"</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"reasoning"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Detailed explanation linking analysis to recommendation"</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"expected_impact"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Restore CPA to $47-49 range within 2-3 days"</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"risk_level"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"medium"</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"risk_factors"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
    <span class="hljs-string">"If competition doesn't stabilize, may need further increases"</span><span class="hljs-punctuation">,</span>
    <span class="hljs-string">"Potential for temporary overspend if competitors drop out suddenly"</span>
  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"alternative_actions"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
    <span class="hljs-punctuation">{</span>
      <span class="hljs-attr">"workflow"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Continue Monitoring"</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">"why_not_recommended"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Delaying action risks further CPA degradation"</span>
    <span class="hljs-punctuation">}</span><span class="hljs-punctuation">,</span>
    <span class="hljs-punctuation">{</span>
      <span class="hljs-attr">"workflow"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Creative Refresh"</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">"why_not_recommended"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Creative showing no fatigue signals; wouldn't address competitive pressure"</span>
    <span class="hljs-punctuation">}</span>
  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"success_metrics"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
    <span class="hljs-string">"CPA returns to &lt;$50 within 3 days"</span><span class="hljs-punctuation">,</span>
    <span class="hljs-string">"Impression share maintained above 90%"</span><span class="hljs-punctuation">,</span>
    <span class="hljs-string">"CTR remains stable or improves"</span>
  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"confidence"</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.82</span>
<span class="hljs-punctuation">}</span>
</div></code></pre>
<h2 id="recommendation-guidelines" tabindex="-1">Recommendation Guidelines</h2>
<ol>
<li><strong>Be specific</strong>: Don't just say "adjust bids" - say how much</li>
<li><strong>Explain the logic</strong>: Connect dots from analysis to action</li>
<li><strong>Set expectations</strong>: What should happen if this works?</li>
<li><strong>Acknowledge risks</strong>: What could go wrong?</li>
<li><strong>Provide alternatives</strong>: What else could we do?</li>
<li><strong>Define success</strong>: How will we know if it worked?</li>
</ol>
<h2 id="action-suitability-matrix" tabindex="-1">Action Suitability Matrix</h2>
<table>
<thead>
<tr>
<th>Root Cause</th>
<th>Best Action</th>
<th>Why</th>
</tr>
</thead>
<tbody>
<tr>
<td>Creative fatigue</td>
<td>Creative Refresh</td>
<td>Directly addresses ad staleness</td>
</tr>
<tr>
<td>Audience saturation</td>
<td>Audience Expansion</td>
<td>Reaches new users</td>
</tr>
<tr>
<td>Competitive pressure</td>
<td>Bid Adjustment</td>
<td>Competes in auction</td>
</tr>
<tr>
<td>Poor targeting</td>
<td>Audience Refinement</td>
<td>Improves relevance</td>
</tr>
<tr>
<td>Fundamental issue</td>
<td>Campaign Pause</td>
<td>Prevents waste</td>
</tr>
<tr>
<td>Normal variance</td>
<td>Continue Monitoring</td>
<td>Avoids overreaction</td>
</tr>
</tbody>
</table>
<p>Now generate your recommendation."""</p>
<p>CRITIQUE_PROMPT = """You are a quality assurance analyst reviewing a marketing recommendation.</p>
<h2 id="your-task" tabindex="-1">Your Task</h2>
<p>Evaluate the recommendation for:</p>
<ol>
<li><strong>Logical consistency</strong>: Does the recommendation follow from the analysis?</li>
<li><strong>Specificity</strong>: Is the action concrete and actionable?</li>
<li><strong>Risk assessment</strong>: Are risks properly identified and weighted?</li>
<li><strong>Alternative consideration</strong>: Were other options fairly evaluated?</li>
<li><strong>Success criteria</strong>: Can we measure if this worked?</li>
</ol>
<h2 id="output" tabindex="-1">Output</h2>
<pre class="hljs"><code><div><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">"is_satisfactory"</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"issues"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
    <span class="hljs-punctuation">{</span>
      <span class="hljs-attr">"severity"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"minor"</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">"issue"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Expected impact timeframe is vague"</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">"suggestion"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Specify exact number of days"</span>
    <span class="hljs-punctuation">}</span>
  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"strengths"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
    <span class="hljs-string">"Clear connection between competitive pressure and bid adjustment"</span><span class="hljs-punctuation">,</span>
    <span class="hljs-string">"Specific bid increase percentage provided"</span>
  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"overall_assessment"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Strong recommendation with minor improvements possible"</span>
<span class="hljs-punctuation">}</span>
</div></code></pre>
<p>Severity levels:</p>
<ul>
<li><strong>CRITICAL</strong>: Logical flaw, unsafe recommendation, or missing key info</li>
<li><strong>major</strong>: Significant improvement needed</li>
<li><strong>minor</strong>: Small refinement would help</li>
</ul>
<p>If any CRITICAL issues are found, the recommendation should be regenerated.</p>
<p>Now critique the recommendation."""</p>
<pre class="hljs"><code><div>
### 6.3 Structured Output Models

```python
# src/agent/models.py
from pydantic import BaseModel, Field
from enum import Enum

class WorkflowType(str, Enum):
    CREATIVE_REFRESH = "Creative Refresh"
    AUDIENCE_EXPANSION = "Audience Expansion"
    BID_ADJUSTMENT = "Bid Adjustment"
    CAMPAIGN_PAUSE = "Campaign Pause"
    BUDGET_REALLOCATION = "Budget Reallocation"
    CONTINUE_MONITORING = "Continue Monitoring"

class RiskLevel(str, Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"

class AlternativeAction(BaseModel):
    workflow: WorkflowType
    why_not_recommended: str

class Recommendation(BaseModel):
    """Structured recommendation output"""
    
    # Core recommendation
    recommended_workflow: WorkflowType
    specific_action: str = Field(
        description="Concrete, actionable instruction (e.g., 'Increase bid by 15% to $2.88')"
    )
    
    # Reasoning
    reasoning: str = Field(
        description="Detailed explanation connecting analysis to recommendation"
    )
    signal_analysis: str = Field(
        description="Summary of key performance signals analyzed"
    )
    root_cause: str = Field(
        description="Primary hypothesis for performance change"
    )
    
    # Impact &amp; Risk
    expected_impact: str = Field(
        description="Predicted outcome if recommendation is followed"
    )
    risk_level: RiskLevel
    risk_factors: list[str] = Field(
        description="Potential risks or complications"
    )
    
    # Alternatives
    alternative_actions: list[AlternativeAction] = Field(
        description="Other options considered and why not chosen"
    )
    
    # Success criteria
    success_metrics: list[str] = Field(
        description="How to measure if recommendation worked"
    )
    
    # Confidence
    confidence: float = Field(
        ge=0.0, le=1.0,
        description="Confidence score (0-1)"
    )
    confidence_reasoning: str = Field(
        description="Explanation of confidence level"
    )
    
    # Metadata
    campaign_id: str
    generated_at: datetime
    model_version: str

# Use with LangChain structured output
from langchain.output_parsers import PydanticOutputParser

parser = PydanticOutputParser(pydantic_object=Recommendation)
</div></code></pre>
<h3 id="6.4-prompt-versioning-strategy" tabindex="-1">6.4 Prompt Versioning Strategy</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># src/agent/prompt_registry.py</span>
<span class="hljs-keyword">import</span> yaml
<span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path

<span class="hljs-keyword">class</span> <span class="hljs-title class_">PromptRegistry</span>:
    <span class="hljs-string">"""Version-controlled prompt management"""</span>
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, prompts_dir: Path</span>):
        <span class="hljs-variable language_">self</span>.prompts_dir = prompts_dir
        <span class="hljs-variable language_">self</span>._cache = {}
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_prompt</span>(<span class="hljs-params">
        self, 
        name: <span class="hljs-built_in">str</span>, 
        version: <span class="hljs-built_in">str</span> = <span class="hljs-string">"latest"</span>
    </span>) -&gt; <span class="hljs-built_in">str</span>:
        <span class="hljs-string">"""
        Load prompt from versioned YAML files
        
        prompts/
          signal_analysis/
            v1.yaml
            v2.yaml
            latest.yaml (symlink)
        """</span>
        cache_key = <span class="hljs-string">f"<span class="hljs-subst">{name}</span>:<span class="hljs-subst">{version}</span>"</span>
        
        <span class="hljs-keyword">if</span> cache_key <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>._cache:
            <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>._cache[cache_key]
        
        prompt_path = <span class="hljs-variable language_">self</span>.prompts_dir / name / <span class="hljs-string">f"<span class="hljs-subst">{version}</span>.yaml"</span>
        
        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(prompt_path) <span class="hljs-keyword">as</span> f:
            prompt_config = yaml.safe_load(f)
        
        prompt_text = prompt_config[<span class="hljs-string">'prompt'</span>]
        <span class="hljs-variable language_">self</span>._cache[cache_key] = prompt_text
        
        <span class="hljs-keyword">return</span> prompt_text
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">list_versions</span>(<span class="hljs-params">self, name: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">str</span>]:
        <span class="hljs-string">"""List all versions of a prompt"""</span>
        prompt_dir = <span class="hljs-variable language_">self</span>.prompts_dir / name
        <span class="hljs-keyword">return</span> [
            p.stem <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> prompt_dir.glob(<span class="hljs-string">"*.yaml"</span>)
            <span class="hljs-keyword">if</span> p.stem != <span class="hljs-string">"latest"</span>
        ]
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compare_versions</span>(<span class="hljs-params">
        self, 
        name: <span class="hljs-built_in">str</span>,
        v1: <span class="hljs-built_in">str</span>,
        v2: <span class="hljs-built_in">str</span>
    </span>) -&gt; <span class="hljs-built_in">dict</span>:
        <span class="hljs-string">"""
        Compare two prompt versions on golden dataset
        Used for A/B testing prompts
        """</span>
        <span class="hljs-comment"># Run eval on both versions</span>
        results_v1 = run_evaluation(name, v1)
        results_v2 = run_evaluation(name, v2)
        
        <span class="hljs-keyword">return</span> {
            <span class="hljs-string">"v1"</span>: results_v1,
            <span class="hljs-string">"v2"</span>: results_v2,
            <span class="hljs-string">"winner"</span>: results_v2 <span class="hljs-keyword">if</span> results_v2.score &gt; results_v1.score <span class="hljs-keyword">else</span> results_v1
        }
</div></code></pre>
<p><strong>Prompt Version Control in Git:</strong></p>
<pre class="hljs"><code><div><span class="hljs-comment"># prompts/signal_analysis/v1.yaml</span>
<span class="hljs-attr">version:</span> <span class="hljs-string">"1.0"</span>
<span class="hljs-attr">created:</span> <span class="hljs-string">"2026-02-11"</span>
<span class="hljs-attr">author:</span> <span class="hljs-string">"sudip"</span>
<span class="hljs-attr">description:</span> <span class="hljs-string">"Initial signal analysis prompt"</span>
<span class="hljs-attr">changelog:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-string">"First version based on requirements"</span>

<span class="hljs-attr">prompt:</span> <span class="hljs-string">|
  You are an expert marketing performance analyst...
  [full prompt text]
</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">model:</span> <span class="hljs-string">"gpt-4o"</span>
  <span class="hljs-attr">temperature:</span> <span class="hljs-number">0.1</span>
  <span class="hljs-attr">max_tokens:</span> <span class="hljs-number">2000</span>
</div></code></pre>
<hr>
<h2 id="7.-evaluation-framework" tabindex="-1">7. Evaluation Framework</h2>
<h3 id="7.1-evaluation-strategy" tabindex="-1">7.1 Evaluation Strategy</h3>
<p><strong>Multi-Layered Evaluation:</strong></p>
<ol>
<li><strong>Unit Tests</strong> - Individual components work correctly</li>
<li><strong>Golden Set Tests</strong> - Agent matches human decisions on historical cases</li>
<li><strong>LLM-as-Judge</strong> - Reasoning quality assessment</li>
<li><strong>Outcome Tracking</strong> - Real-world impact measurement</li>
<li><strong>Regression Tests</strong> - Prevent quality degradation over time</li>
</ol>
<h3 id="7.2-golden-dataset-creation" tabindex="-1">7.2 Golden Dataset Creation</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># src/evaluation/golden_dataset.py</span>
<span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel

<span class="hljs-keyword">class</span> <span class="hljs-title class_">GoldenExample</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):
    <span class="hljs-string">"""A test case with known correct answer"""</span>
    example_id: <span class="hljs-built_in">str</span>
    campaign_id: <span class="hljs-built_in">str</span>
    campaign_name: <span class="hljs-built_in">str</span>
    
    <span class="hljs-comment"># Input: Campaign context at decision time</span>
    context: CampaignContext
    
    <span class="hljs-comment"># Expected output: What human decided</span>
    human_decision: WorkflowType
    human_reasoning: <span class="hljs-built_in">str</span>
    confidence: <span class="hljs-built_in">float</span>  <span class="hljs-comment"># How clear-cut was decision</span>
    
    <span class="hljs-comment"># Actual outcome: What happened after action</span>
    outcome: <span class="hljs-built_in">dict</span>  <span class="hljs-comment"># {"cpa_change_pct": -15, "success": True}</span>
    
    <span class="hljs-comment"># Metadata</span>
    decision_date: datetime
    decided_by: <span class="hljs-built_in">str</span>  <span class="hljs-comment"># Marketing exec who made call</span>
    tags: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">str</span>]  <span class="hljs-comment"># ["competitive_pressure", "bid_adjustment"]</span>

<span class="hljs-keyword">class</span> <span class="hljs-title class_">GoldenDatasetBuilder</span>:
    <span class="hljs-string">"""Build golden dataset from historical decisions"""</span>
    
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">create_from_historical_data</span>(<span class="hljs-params">
        self,
        start_date: datetime,
        end_date: datetime
    </span>) -&gt; <span class="hljs-built_in">list</span>[GoldenExample]:
        <span class="hljs-string">"""
        Extract historical scenarios where:
        1. Marketing exec made a decision
        2. We have context snapshot
        3. We can measure outcome
        """</span>
        <span class="hljs-comment"># Query database for historical recommendations</span>
        historical_recs = <span class="hljs-keyword">await</span> db.query(
            <span class="hljs-string">"""
            SELECT 
                r.id,
                r.campaign_id,
                r.context,
                r.human_decision,
                r.human_reasoning,
                r.decision_date,
                r.decided_by,
                o.outcome_metrics
            FROM recommendations r
            JOIN outcomes o ON r.id = o.recommendation_id
            WHERE r.decision_date BETWEEN :start AND :end
              AND r.human_decision IS NOT NULL
              AND o.outcome_metrics IS NOT NULL
            """</span>,
            start=start_date,
            end=end_date
        )
        
        golden_examples = []
        <span class="hljs-keyword">for</span> rec <span class="hljs-keyword">in</span> historical_recs:
            <span class="hljs-comment"># Tag example for categorization</span>
            tags = <span class="hljs-variable language_">self</span>._categorize_scenario(rec)
            
            <span class="hljs-comment"># Calculate decision confidence based on outcome</span>
            confidence = <span class="hljs-variable language_">self</span>._assess_decision_confidence(rec)
            
            example = GoldenExample(
                example_id=rec[<span class="hljs-string">'id'</span>],
                campaign_id=rec[<span class="hljs-string">'campaign_id'</span>],
                context=rec[<span class="hljs-string">'context'</span>],
                human_decision=rec[<span class="hljs-string">'human_decision'</span>],
                human_reasoning=rec[<span class="hljs-string">'human_reasoning'</span>],
                confidence=confidence,
                outcome=rec[<span class="hljs-string">'outcome_metrics'</span>],
                decision_date=rec[<span class="hljs-string">'decision_date'</span>],
                decided_by=rec[<span class="hljs-string">'decided_by'</span>],
                tags=tags
            )
            
            golden_examples.append(example)
        
        <span class="hljs-keyword">return</span> golden_examples
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_categorize_scenario</span>(<span class="hljs-params">self, rec: <span class="hljs-built_in">dict</span></span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">str</span>]:
        <span class="hljs-string">"""Tag scenario with relevant categories"""</span>
        tags = []
        
        context = rec[<span class="hljs-string">'context'</span>]
        
        <span class="hljs-comment"># Root cause tags</span>
        <span class="hljs-keyword">if</span> context[<span class="hljs-string">'campaign_metrics'</span>][<span class="hljs-string">'cpa_change_pct'</span>] &gt; <span class="hljs-number">20</span>:
            tags.append(<span class="hljs-string">"high_cpa_increase"</span>)
        
        <span class="hljs-keyword">if</span> context[<span class="hljs-string">'competitor_signals'</span>][<span class="hljs-string">'activity_change_pct'</span>] &gt; <span class="hljs-number">30</span>:
            tags.append(<span class="hljs-string">"competitive_pressure"</span>)
        
        creative_fatigued = <span class="hljs-built_in">any</span>(
            c.get(<span class="hljs-string">'is_fatigued'</span>) <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> context.get(<span class="hljs-string">'creative_metrics'</span>, [])
        )
        <span class="hljs-keyword">if</span> creative_fatigued:
            tags.append(<span class="hljs-string">"creative_fatigue"</span>)
        
        <span class="hljs-comment"># Action tags</span>
        tags.append(<span class="hljs-string">f"action_<span class="hljs-subst">{rec[<span class="hljs-string">'human_decision'</span>].lower().replace(<span class="hljs-string">' '</span>, <span class="hljs-string">'_'</span>)}</span>"</span>)
        
        <span class="hljs-keyword">return</span> tags
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_assess_decision_confidence</span>(<span class="hljs-params">self, rec: <span class="hljs-built_in">dict</span></span>) -&gt; <span class="hljs-built_in">float</span>:
        <span class="hljs-string">"""
        Estimate how clear-cut the decision was
        Based on outcome and alternative viability
        """</span>
        outcome = rec[<span class="hljs-string">'outcome_metrics'</span>]
        
        <span class="hljs-comment"># If action led to significant improvement → high confidence</span>
        <span class="hljs-keyword">if</span> outcome.get(<span class="hljs-string">'success'</span>) <span class="hljs-keyword">and</span> outcome.get(<span class="hljs-string">'improvement_pct'</span>, <span class="hljs-number">0</span>) &gt; <span class="hljs-number">15</span>:
            <span class="hljs-keyword">return</span> <span class="hljs-number">0.9</span>
        
        <span class="hljs-comment"># If marginal improvement → medium confidence</span>
        <span class="hljs-keyword">if</span> outcome.get(<span class="hljs-string">'success'</span>) <span class="hljs-keyword">and</span> outcome.get(<span class="hljs-string">'improvement_pct'</span>, <span class="hljs-number">0</span>) &gt; <span class="hljs-number">5</span>:
            <span class="hljs-keyword">return</span> <span class="hljs-number">0.7</span>
        
        <span class="hljs-comment"># If no improvement → decision was less obvious or wrong</span>
        <span class="hljs-keyword">return</span> <span class="hljs-number">0.5</span>
</div></code></pre>
<h3 id="7.3-evaluation-metrics" tabindex="-1">7.3 Evaluation Metrics</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># src/evaluation/metrics.py</span>
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> precision_score, recall_score, f1_score
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-keyword">class</span> <span class="hljs-title class_">EvaluationMetrics</span>:
    <span class="hljs-string">"""Calculate evaluation metrics for recommendations"""</span>
    
<span class="hljs-meta">    @staticmethod</span>
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_agreement_rate</span>(<span class="hljs-params">
        agent_decisions: <span class="hljs-built_in">list</span>[WorkflowType],
        human_decisions: <span class="hljs-built_in">list</span>[WorkflowType]
    </span>) -&gt; <span class="hljs-built_in">float</span>:
        <span class="hljs-string">"""
        What % of time does agent match human decision?
        Primary quality metric
        """</span>
        matches = <span class="hljs-built_in">sum</span>(
            <span class="hljs-number">1</span> <span class="hljs-keyword">for</span> a, h <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(agent_decisions, human_decisions)
            <span class="hljs-keyword">if</span> a == h
        )
        <span class="hljs-keyword">return</span> matches / <span class="hljs-built_in">len</span>(agent_decisions)
    
<span class="hljs-meta">    @staticmethod</span>
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_precision_by_workflow</span>(<span class="hljs-params">
        agent_decisions: <span class="hljs-built_in">list</span>[WorkflowType],
        human_decisions: <span class="hljs-built_in">list</span>[WorkflowType]
    </span>) -&gt; <span class="hljs-built_in">dict</span>[WorkflowType, <span class="hljs-built_in">float</span>]:
        <span class="hljs-string">"""
        For each workflow type, calculate precision:
        Of recommendations agent made, how many did humans agree with?
        """</span>
        workflows = <span class="hljs-built_in">list</span>(WorkflowType)
        
        <span class="hljs-comment"># Convert to binary labels for sklearn</span>
        results = {}
        <span class="hljs-keyword">for</span> workflow <span class="hljs-keyword">in</span> workflows:
            y_true = [<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> h == workflow <span class="hljs-keyword">else</span> <span class="hljs-number">0</span> <span class="hljs-keyword">for</span> h <span class="hljs-keyword">in</span> human_decisions]
            y_pred = [<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> a == workflow <span class="hljs-keyword">else</span> <span class="hljs-number">0</span> <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> agent_decisions]
            
            <span class="hljs-keyword">if</span> <span class="hljs-built_in">sum</span>(y_pred) &gt; <span class="hljs-number">0</span>:  <span class="hljs-comment"># Avoid division by zero</span>
                precision = precision_score(y_true, y_pred, zero_division=<span class="hljs-number">0</span>)
                results[workflow] = precision
            <span class="hljs-keyword">else</span>:
                results[workflow] = <span class="hljs-literal">None</span>
        
        <span class="hljs-keyword">return</span> results
    
<span class="hljs-meta">    @staticmethod</span>
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_confidence_calibration</span>(<span class="hljs-params">
        confidences: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">float</span>],
        correct: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">bool</span>]
    </span>) -&gt; <span class="hljs-built_in">dict</span>:
        <span class="hljs-string">"""
        How well-calibrated are confidence scores?
        
        If agent says 80% confident, are they right 80% of the time?
        """</span>
        <span class="hljs-comment"># Bin confidences</span>
        bins = np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">11</span>)  <span class="hljs-comment"># 0-10%, 10-20%, ..., 90-100%</span>
        
        calibration = {}
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(bins) - <span class="hljs-number">1</span>):
            bin_low, bin_high = bins[i], bins[i+<span class="hljs-number">1</span>]
            
            <span class="hljs-comment"># Find predictions in this confidence range</span>
            in_bin = [
                correct[j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(confidences))
                <span class="hljs-keyword">if</span> bin_low &lt;= confidences[j] &lt; bin_high
            ]
            
            <span class="hljs-keyword">if</span> in_bin:
                actual_accuracy = <span class="hljs-built_in">sum</span>(in_bin) / <span class="hljs-built_in">len</span>(in_bin)
                expected_confidence = (bin_low + bin_high) / <span class="hljs-number">2</span>
                
                calibration[<span class="hljs-string">f"<span class="hljs-subst">{<span class="hljs-built_in">int</span>(bin_low*<span class="hljs-number">100</span>)}</span>-<span class="hljs-subst">{<span class="hljs-built_in">int</span>(bin_high*<span class="hljs-number">100</span>)}</span>%"</span>] = {
                    <span class="hljs-string">"expected"</span>: expected_confidence,
                    <span class="hljs-string">"actual"</span>: actual_accuracy,
                    <span class="hljs-string">"count"</span>: <span class="hljs-built_in">len</span>(in_bin),
                    <span class="hljs-string">"calibration_error"</span>: <span class="hljs-built_in">abs</span>(actual_accuracy - expected_confidence)
                }
        
        <span class="hljs-keyword">return</span> calibration
    
<span class="hljs-meta">    @staticmethod</span>
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_outcome_metrics</span>(<span class="hljs-params">
        recommendations: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">dict</span>]
    </span>) -&gt; <span class="hljs-built_in">dict</span>:
        <span class="hljs-string">"""
        Track real-world impact of recommendations
        
        Args:
            recommendations: List of dicts with {
                "recommended_workflow": str,
                "was_accepted": bool,
                "outcome": dict  # If accepted and executed
            }
        """</span>
        accepted = [r <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> recommendations <span class="hljs-keyword">if</span> r[<span class="hljs-string">'was_accepted'</span>]]
        
        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> accepted:
            <span class="hljs-keyword">return</span> {<span class="hljs-string">"error"</span>: <span class="hljs-string">"No accepted recommendations to evaluate"</span>}
        
        with_outcomes = [
            r <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> accepted 
            <span class="hljs-keyword">if</span> r.get(<span class="hljs-string">'outcome'</span>) <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>
        ]
        
        <span class="hljs-keyword">return</span> {
            <span class="hljs-string">"total_recommendations"</span>: <span class="hljs-built_in">len</span>(recommendations),
            <span class="hljs-string">"acceptance_rate"</span>: <span class="hljs-built_in">len</span>(accepted) / <span class="hljs-built_in">len</span>(recommendations),
            <span class="hljs-string">"positive_impact_rate"</span>: <span class="hljs-built_in">sum</span>(
                <span class="hljs-number">1</span> <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> with_outcomes 
                <span class="hljs-keyword">if</span> r[<span class="hljs-string">'outcome'</span>].get(<span class="hljs-string">'improvement_pct'</span>, <span class="hljs-number">0</span>) &gt; <span class="hljs-number">0</span>
            ) / <span class="hljs-built_in">len</span>(with_outcomes) <span class="hljs-keyword">if</span> with_outcomes <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>,
            <span class="hljs-string">"avg_improvement_pct"</span>: np.mean([
                r[<span class="hljs-string">'outcome'</span>].get(<span class="hljs-string">'improvement_pct'</span>, <span class="hljs-number">0</span>)
                <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> with_outcomes
            ]) <span class="hljs-keyword">if</span> with_outcomes <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>,
            <span class="hljs-string">"samples_with_outcomes"</span>: <span class="hljs-built_in">len</span>(with_outcomes)
        }
</div></code></pre>
<h3 id="7.4-llm-as-judge-evaluation" tabindex="-1">7.4 LLM-as-Judge Evaluation</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># src/evaluation/llm_judge.py</span>
<span class="hljs-keyword">from</span> langchain_openai <span class="hljs-keyword">import</span> ChatOpenAI
<span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> ChatPromptTemplate

<span class="hljs-keyword">class</span> <span class="hljs-title class_">LLMJudge</span>:
    <span class="hljs-string">"""Use GPT-4 to evaluate reasoning quality"""</span>
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):
        <span class="hljs-variable language_">self</span>.llm = ChatOpenAI(model=<span class="hljs-string">"gpt-4o"</span>, temperature=<span class="hljs-number">0</span>)
    
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_reasoning</span>(<span class="hljs-params">
        self,
        recommendation: Recommendation,
        context: CampaignContext
    </span>) -&gt; <span class="hljs-built_in">dict</span>:
        <span class="hljs-string">"""
        Evaluate quality of reasoning independent of correctness
        
        Measures:
        - Logical consistency
        - Evidence support
        - Consideration of alternatives
        - Clarity of explanation
        """</span>
        prompt = ChatPromptTemplate.from_messages([
            (<span class="hljs-string">"system"</span>, <span class="hljs-variable language_">self</span>._get_judge_prompt()),
            (<span class="hljs-string">"user"</span>, <span class="hljs-variable language_">self</span>._format_eval_input(recommendation, context))
        ])
        
        response = <span class="hljs-keyword">await</span> <span class="hljs-variable language_">self</span>.llm.ainvoke(prompt.format_messages())
        
        <span class="hljs-comment"># Parse structured evaluation</span>
        evaluation = parse_judge_response(response.content)
        
        <span class="hljs-keyword">return</span> evaluation
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_get_judge_prompt</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">str</span>:
        <span class="hljs-keyword">return</span> <span class="hljs-string">"""You are evaluating the quality of a marketing recommendation.

Rate on scale 1-5 for each criterion:

1. **Logical Consistency** (1-5)
   - Does the recommendation follow logically from the analysis?
   - Are there gaps or leaps in reasoning?
   - Score: 5 = flawless logic, 1 = major logical issues

2. **Evidence Support** (1-5)
   - Is each claim backed by evidence from the data?
   - Are numbers and metrics used appropriately?
   - Score: 5 = well-evidenced, 1 = unsupported claims

3. **Alternative Consideration** (1-5)
   - Were reasonable alternatives considered?
   - Is the explanation for rejecting alternatives sound?
   - Score: 5 = thorough, 1 = ignored alternatives

4. **Clarity** (1-5)
   - Is the reasoning clear and easy to follow?
   - Could a non-expert understand it?
   - Score: 5 = very clear, 1 = confusing

Output format:
```json
{
  "logical_consistency": 4,
  "evidence_support": 5,
  "alternative_consideration": 3,
  "clarity": 4,
  "overall_score": 4.0,
  "strengths": ["List of specific strengths"],
  "weaknesses": ["List of specific weaknesses"],
  "explanation": "Brief overall assessment"
}
</span></div></code></pre>
<p>"""</p>
<h3 id="7.5-promptfoo-integration" tabindex="-1">7.5 promptfoo Integration</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># promptfoo-config.yaml</span>
<span class="hljs-attr">prompts:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-string">file://prompts/signal_analysis/v1.yaml</span>
  <span class="hljs-bullet">-</span> <span class="hljs-string">file://prompts/signal_analysis/v2.yaml</span>

<span class="hljs-attr">providers:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">id:</span> <span class="hljs-string">openai:gpt-4o</span>
    <span class="hljs-attr">config:</span>
      <span class="hljs-attr">temperature:</span> <span class="hljs-number">0.1</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">id:</span> <span class="hljs-string">anthropic:claude-sonnet-4-5-20250929</span>
    <span class="hljs-attr">config:</span>
      <span class="hljs-attr">temperature:</span> <span class="hljs-number">0.1</span>

<span class="hljs-attr">tests:</span>
  <span class="hljs-comment"># Golden dataset test cases</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">vars:</span>
      <span class="hljs-attr">campaign_id:</span> <span class="hljs-string">"campaign_001"</span>
      <span class="hljs-attr">context:</span> <span class="hljs-string">file://test_data/competitive_pressure_case.json</span>
    <span class="hljs-attr">assert:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">type:</span> <span class="hljs-string">is-json</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">type:</span> <span class="hljs-string">python</span>
        <span class="hljs-attr">value:</span> <span class="hljs-string">file://evaluators/check_workflow_match.py</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">type:</span> <span class="hljs-string">llm-rubric</span>
        <span class="hljs-attr">value:</span> <span class="hljs-string">|
          The recommendation should identify competitive pressure as root cause
          and suggest bid adjustment as the solution.
</span>      <span class="hljs-bullet">-</span> <span class="hljs-attr">type:</span> <span class="hljs-string">similar</span>
        <span class="hljs-attr">value:</span> <span class="hljs-string">"Competitor activity increased significantly"</span>
        <span class="hljs-attr">threshold:</span> <span class="hljs-number">0.8</span>

  <span class="hljs-bullet">-</span> <span class="hljs-attr">vars:</span>
      <span class="hljs-attr">campaign_id:</span> <span class="hljs-string">"campaign_002"</span>
      <span class="hljs-attr">context:</span> <span class="hljs-string">file://test_data/creative_fatigue_case.json</span>
    <span class="hljs-attr">assert:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">type:</span> <span class="hljs-string">python</span>
        <span class="hljs-attr">value:</span> <span class="hljs-string">file://evaluators/check_workflow_match.py</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">type:</span> <span class="hljs-string">contains</span>
        <span class="hljs-attr">value:</span> <span class="hljs-string">"creative refresh"</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">type:</span> <span class="hljs-string">llm-rubric</span>
        <span class="hljs-attr">value:</span> <span class="hljs-string">|
          Should identify declining CTR and high frequency as creative fatigue signals.
</span>
<span class="hljs-comment"># Custom evaluator</span>
<span class="hljs-comment"># evaluators/check_workflow_match.py</span>
<span class="hljs-string">def</span> <span class="hljs-string">evaluate(output,</span> <span class="hljs-attr">context):</span>
    <span class="hljs-string">""</span><span class="hljs-string">"Check if agent recommendation matches expected workflow"</span><span class="hljs-string">""</span>
    <span class="hljs-string">import</span> <span class="hljs-string">json</span>
    
    <span class="hljs-attr">try:</span>
        <span class="hljs-string">recommendation</span> <span class="hljs-string">=</span> <span class="hljs-string">json.loads(output)</span>
        <span class="hljs-string">expected_workflow</span> <span class="hljs-string">=</span> <span class="hljs-string">context['vars']['expected_workflow']</span>
        
        <span class="hljs-string">if</span> <span class="hljs-string">recommendation['recommended_workflow']</span> <span class="hljs-string">==</span> <span class="hljs-attr">expected_workflow:</span>
            <span class="hljs-string">return</span> {
                <span class="hljs-attr">'pass':</span> <span class="hljs-literal">True</span>,
                <span class="hljs-attr">'score':</span> <span class="hljs-number">1.0</span>,
                <span class="hljs-attr">'reason':</span> <span class="hljs-string">'Workflow matches expected decision'</span>
            }
        <span class="hljs-attr">else:</span>
            <span class="hljs-string">return</span> {
                <span class="hljs-attr">'pass':</span> <span class="hljs-literal">False</span>,
                <span class="hljs-attr">'score':</span> <span class="hljs-number">0.0</span>,
                <span class="hljs-attr">'reason':</span> <span class="hljs-string">f"Expected</span> {<span class="hljs-string">expected_workflow</span>}, <span class="hljs-string">got</span> {<span class="hljs-string">recommendation</span>[<span class="hljs-string">'recommended_workflow'</span>]}<span class="hljs-string">"
            }
    except Exception as e:
        return {
            'pass': False,
            'score': 0.0,
            'reason': f'Parse error: {str(e)}'
        }
</span></div></code></pre>
<p><strong>Run Evaluation:</strong></p>
<pre class="hljs"><code><div><span class="hljs-comment"># Run all tests</span>
promptfoo <span class="hljs-built_in">eval</span>

<span class="hljs-comment"># Compare prompts</span>
promptfoo <span class="hljs-built_in">eval</span> --prompts prompts/signal_analysis/v*.yaml

<span class="hljs-comment"># Run specific test</span>
promptfoo <span class="hljs-built_in">eval</span> --filter <span class="hljs-string">"competitive_pressure"</span>

<span class="hljs-comment"># View results in UI</span>
promptfoo view
</div></code></pre>
<h3 id="7.6-continuous-evaluation-in-ci" tabindex="-1">7.6 Continuous Evaluation in CI</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># .github/workflows/eval.yml</span>
<span class="hljs-attr">name:</span> <span class="hljs-string">Continuous</span> <span class="hljs-string">Evaluation</span>

<span class="hljs-attr">on:</span>
  <span class="hljs-attr">pull_request:</span>
    <span class="hljs-attr">paths:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">'prompts/**'</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">'src/agent/**'</span>

<span class="hljs-attr">jobs:</span>
  <span class="hljs-attr">evaluate:</span>
    <span class="hljs-attr">runs-on:</span> <span class="hljs-string">ubuntu-latest</span>
    <span class="hljs-attr">steps:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/checkout@v3</span>
      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Set</span> <span class="hljs-string">up</span> <span class="hljs-string">Python</span>
        <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/setup-python@v4</span>
        <span class="hljs-attr">with:</span>
          <span class="hljs-attr">python-version:</span> <span class="hljs-string">'3.11'</span>
      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Install</span> <span class="hljs-string">dependencies</span>
        <span class="hljs-attr">run:</span> <span class="hljs-string">|
          pip install -r requirements.txt
          npm install -g promptfoo
</span>      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Run</span> <span class="hljs-string">golden</span> <span class="hljs-string">set</span> <span class="hljs-string">evaluation</span>
        <span class="hljs-attr">env:</span>
          <span class="hljs-attr">OPENAI_API_KEY:</span> <span class="hljs-string">${{</span> <span class="hljs-string">secrets.OPENAI_API_KEY</span> <span class="hljs-string">}}</span>
        <span class="hljs-attr">run:</span> <span class="hljs-string">|
          python -m evaluation.run_golden_set
</span>      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Run</span> <span class="hljs-string">promptfoo</span> <span class="hljs-string">tests</span>
        <span class="hljs-attr">env:</span>
          <span class="hljs-attr">OPENAI_API_KEY:</span> <span class="hljs-string">${{</span> <span class="hljs-string">secrets.OPENAI_API_KEY</span> <span class="hljs-string">}}</span>
        <span class="hljs-attr">run:</span> <span class="hljs-string">|
          promptfoo eval
</span>      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Check</span> <span class="hljs-string">quality</span> <span class="hljs-string">threshold</span>
        <span class="hljs-attr">run:</span> <span class="hljs-string">|
          python -m evaluation.check_threshold
</span>      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Post</span> <span class="hljs-string">results</span> <span class="hljs-string">to</span> <span class="hljs-string">PR</span>
        <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/github-script@v6</span>
        <span class="hljs-attr">with:</span>
          <span class="hljs-attr">script:</span> <span class="hljs-string">|
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('eval_results.json'));
</span>            
            <span class="hljs-string">github.rest.issues.createComment({</span>
              <span class="hljs-attr">issue_number:</span> <span class="hljs-string">context.issue.number,</span>
              <span class="hljs-attr">owner:</span> <span class="hljs-string">context.repo.owner,</span>
              <span class="hljs-attr">repo:</span> <span class="hljs-string">context.repo.repo,</span>
              <span class="hljs-attr">body:</span> <span class="hljs-string">`##</span> <span class="hljs-string">Evaluation</span> <span class="hljs-string">Results\n\n`</span> <span class="hljs-string">+</span>
                    <span class="hljs-string">`Agreement</span> <span class="hljs-attr">Rate:</span> <span class="hljs-string">${results.agreement_rate}%\n`</span> <span class="hljs-string">+</span>
                    <span class="hljs-string">`Threshold:</span> <span class="hljs-number">70</span><span class="hljs-string">%</span> <span class="hljs-string">✓\n\n`</span> <span class="hljs-string">+</span>
                    <span class="hljs-string">`Passed:</span> <span class="hljs-string">${results.passed_count}/${results.total_count}`</span>
            <span class="hljs-string">});</span>
      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Fail</span> <span class="hljs-string">if</span> <span class="hljs-string">below</span> <span class="hljs-string">threshold</span>
        <span class="hljs-attr">run:</span> <span class="hljs-string">|
          python -c "
          import json
          with open('eval_results.json') as f:
              results = json.load(f)
          if results['agreement_rate'] &lt; 70:
              print(f'❌ Agreement rate {results[\"agreement_rate\"]}% below 70% threshold')
              exit(1)
          print(f'✓ Agreement rate {results[\"agreement_rate\"]}% meets threshold')
          "
</span></div></code></pre>
<hr>
<h2 id="8.-production-infrastructure" tabindex="-1">8. Production Infrastructure</h2>
<h3 id="8.1-database-schema" tabindex="-1">8.1 Database Schema</h3>
<pre class="hljs"><code><div><span class="hljs-comment">-- PostgreSQL schema</span>
<span class="hljs-keyword">CREATE</span> EXTENSION IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> "uuid-ossp";

<span class="hljs-comment">-- Campaigns table</span>
<span class="hljs-keyword">CREATE TABLE</span> campaigns (
    id UUID <span class="hljs-keyword">PRIMARY KEY</span> <span class="hljs-keyword">DEFAULT</span> uuid_generate_v4(),
    campaign_id <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">255</span>) <span class="hljs-keyword">UNIQUE</span> <span class="hljs-keyword">NOT NULL</span>,
    campaign_name <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">500</span>) <span class="hljs-keyword">NOT NULL</span>,
    platform <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">50</span>) <span class="hljs-keyword">NOT NULL</span>,  <span class="hljs-comment">-- 'google_ads', 'meta_ads', etc.</span>
    industry <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">100</span>),
    keywords TEXT[],
    created_at <span class="hljs-type">TIMESTAMP</span> <span class="hljs-keyword">DEFAULT</span> NOW(),
    updated_at <span class="hljs-type">TIMESTAMP</span> <span class="hljs-keyword">DEFAULT</span> NOW()
);

<span class="hljs-comment">-- Recommendations table</span>
<span class="hljs-keyword">CREATE TABLE</span> recommendations (
    id UUID <span class="hljs-keyword">PRIMARY KEY</span> <span class="hljs-keyword">DEFAULT</span> uuid_generate_v4(),
    campaign_id <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">255</span>) <span class="hljs-keyword">NOT NULL</span> <span class="hljs-keyword">REFERENCES</span> campaigns(campaign_id),
    
    <span class="hljs-comment">-- Context (JSONB for flexibility)</span>
    context JSONB <span class="hljs-keyword">NOT NULL</span>,
    
    <span class="hljs-comment">-- Recommendation</span>
    recommended_workflow <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">100</span>) <span class="hljs-keyword">NOT NULL</span>,
    specific_action TEXT <span class="hljs-keyword">NOT NULL</span>,
    reasoning TEXT <span class="hljs-keyword">NOT NULL</span>,
    signal_analysis TEXT <span class="hljs-keyword">NOT NULL</span>,
    root_cause TEXT <span class="hljs-keyword">NOT NULL</span>,
    expected_impact TEXT,
    risk_level <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">20</span>),
    risk_factors JSONB,
    alternative_actions JSONB,
    success_metrics JSONB,
    confidence <span class="hljs-type">FLOAT</span> <span class="hljs-keyword">CHECK</span> (confidence <span class="hljs-operator">&gt;=</span> <span class="hljs-number">0</span> <span class="hljs-keyword">AND</span> confidence <span class="hljs-operator">&lt;=</span> <span class="hljs-number">1</span>),
    confidence_reasoning TEXT,
    
    <span class="hljs-comment">-- Decision tracking</span>
    human_decision <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">100</span>),  <span class="hljs-comment">-- NULL if pending, 'approved' or 'rejected'</span>
    decided_by <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">255</span>),
    decided_at <span class="hljs-type">TIMESTAMP</span>,
    decision_feedback TEXT,
    
    <span class="hljs-comment">-- Outcome tracking</span>
    outcome_metrics JSONB,
    outcome_recorded_at <span class="hljs-type">TIMESTAMP</span>,
    
    <span class="hljs-comment">-- Metadata</span>
    model_version <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">50</span>),
    prompt_version <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">50</span>),
    generated_at <span class="hljs-type">TIMESTAMP</span> <span class="hljs-keyword">DEFAULT</span> NOW(),
    
    <span class="hljs-comment">-- Indexes</span>
    created_at <span class="hljs-type">TIMESTAMP</span> <span class="hljs-keyword">DEFAULT</span> NOW()
);

<span class="hljs-keyword">CREATE</span> INDEX idx_recommendations_campaign <span class="hljs-keyword">ON</span> recommendations(campaign_id);
<span class="hljs-keyword">CREATE</span> INDEX idx_recommendations_decision <span class="hljs-keyword">ON</span> recommendations(human_decision);
<span class="hljs-keyword">CREATE</span> INDEX idx_recommendations_created <span class="hljs-keyword">ON</span> recommendations(created_at);
<span class="hljs-keyword">CREATE</span> INDEX idx_recommendations_context_gin <span class="hljs-keyword">ON</span> recommendations <span class="hljs-keyword">USING</span> gin(context);

<span class="hljs-comment">-- Evaluation results</span>
<span class="hljs-keyword">CREATE TABLE</span> evaluation_runs (
    id UUID <span class="hljs-keyword">PRIMARY KEY</span> <span class="hljs-keyword">DEFAULT</span> uuid_generate_v4(),
    run_type <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">50</span>) <span class="hljs-keyword">NOT NULL</span>,  <span class="hljs-comment">-- 'golden_set', 'llm_judge', 'outcome'</span>
    dataset_version <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">50</span>),
    prompt_version <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">50</span>),
    model_version <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">50</span>),
    
    <span class="hljs-comment">-- Results</span>
    total_examples <span class="hljs-type">INT</span> <span class="hljs-keyword">NOT NULL</span>,
    passed_examples <span class="hljs-type">INT</span> <span class="hljs-keyword">NOT NULL</span>,
    metrics JSONB <span class="hljs-keyword">NOT NULL</span>,
    
    <span class="hljs-comment">-- Metadata</span>
    triggered_by <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">100</span>),  <span class="hljs-comment">-- 'ci', 'manual', 'scheduled'</span>
    git_commit <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">40</span>),
    run_at <span class="hljs-type">TIMESTAMP</span> <span class="hljs-keyword">DEFAULT</span> NOW()
);

<span class="hljs-comment">-- Agent execution logs (for debugging)</span>
<span class="hljs-keyword">CREATE TABLE</span> agent_executions (
    id UUID <span class="hljs-keyword">PRIMARY KEY</span> <span class="hljs-keyword">DEFAULT</span> uuid_generate_v4(),
    recommendation_id UUID <span class="hljs-keyword">REFERENCES</span> recommendations(id),
    
    <span class="hljs-comment">-- Execution trace</span>
    workflow_state JSONB <span class="hljs-keyword">NOT NULL</span>,
    execution_path TEXT[],
    node_outputs JSONB,
    
    <span class="hljs-comment">-- Performance</span>
    total_duration_ms <span class="hljs-type">INT</span>,
    llm_calls_count <span class="hljs-type">INT</span>,
    total_tokens <span class="hljs-type">INT</span>,
    total_cost_usd <span class="hljs-type">DECIMAL</span>(<span class="hljs-number">10</span>, <span class="hljs-number">6</span>),
    
    <span class="hljs-comment">-- Status</span>
    status <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">20</span>) <span class="hljs-keyword">NOT NULL</span>,  <span class="hljs-comment">-- 'success', 'error', 'timeout'</span>
    error_message TEXT,
    
    executed_at <span class="hljs-type">TIMESTAMP</span> <span class="hljs-keyword">DEFAULT</span> NOW()
);

<span class="hljs-comment">-- Data collector health</span>
<span class="hljs-keyword">CREATE TABLE</span> collector_health (
    id UUID <span class="hljs-keyword">PRIMARY KEY</span> <span class="hljs-keyword">DEFAULT</span> uuid_generate_v4(),
    collector_name <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">100</span>) <span class="hljs-keyword">NOT NULL</span>,
    status <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">20</span>) <span class="hljs-keyword">NOT NULL</span>,  <span class="hljs-comment">-- 'healthy', 'degraded', 'down'</span>
    last_check <span class="hljs-type">TIMESTAMP</span> <span class="hljs-keyword">DEFAULT</span> NOW(),
    error_message TEXT,
    response_time_ms <span class="hljs-type">INT</span>
);
</div></code></pre>
<h3 id="8.2-api-implementation" tabindex="-1">8.2 API Implementation</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># src/api/main.py</span>
<span class="hljs-keyword">from</span> fastapi <span class="hljs-keyword">import</span> FastAPI, HTTPException, Depends, BackgroundTasks
<span class="hljs-keyword">from</span> fastapi.middleware.cors <span class="hljs-keyword">import</span> CORSMiddleware
<span class="hljs-keyword">from</span> slowapi <span class="hljs-keyword">import</span> Limiter, _rate_limit_exceeded_handler
<span class="hljs-keyword">from</span> slowapi.util <span class="hljs-keyword">import</span> get_remote_address
<span class="hljs-keyword">from</span> slowapi.errors <span class="hljs-keyword">import</span> RateLimitExceeded
<span class="hljs-keyword">import</span> structlog

<span class="hljs-keyword">from</span> .routers <span class="hljs-keyword">import</span> recommendations, campaigns, evaluations
<span class="hljs-keyword">from</span> .dependencies <span class="hljs-keyword">import</span> get_current_user, get_db
<span class="hljs-keyword">from</span> .monitoring <span class="hljs-keyword">import</span> setup_prometheus

logger = structlog.get_logger()

<span class="hljs-comment"># Initialize app</span>
app = FastAPI(
    title=<span class="hljs-string">"Marketing Agent API"</span>,
    version=<span class="hljs-string">"0.1.0"</span>,
    docs_url=<span class="hljs-string">"/api/docs"</span>
)

<span class="hljs-comment"># Rate limiting</span>
limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

<span class="hljs-comment"># CORS</span>
app.add_middleware(
    CORSMiddleware,
    allow_origins=[<span class="hljs-string">"http://localhost:3000"</span>],  <span class="hljs-comment"># Frontend URL</span>
    allow_credentials=<span class="hljs-literal">True</span>,
    allow_methods=[<span class="hljs-string">"*"</span>],
    allow_headers=[<span class="hljs-string">"*"</span>],
)

<span class="hljs-comment"># Monitoring</span>
setup_prometheus(app)

<span class="hljs-comment"># Routers</span>
app.include_router(recommendations.router, prefix=<span class="hljs-string">"/api/v1"</span>)
app.include_router(campaigns.router, prefix=<span class="hljs-string">"/api/v1"</span>)
app.include_router(evaluations.router, prefix=<span class="hljs-string">"/api/v1"</span>)

<span class="hljs-meta">@app.get(<span class="hljs-params"><span class="hljs-string">"/health"</span></span>)</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">health_check</span>():
    <span class="hljs-string">"""Health check endpoint"""</span>
    <span class="hljs-keyword">return</span> {<span class="hljs-string">"status"</span>: <span class="hljs-string">"healthy"</span>, <span class="hljs-string">"version"</span>: <span class="hljs-string">"0.1.0"</span>}

<span class="hljs-comment"># src/api/routers/recommendations.py</span>
<span class="hljs-keyword">from</span> fastapi <span class="hljs-keyword">import</span> APIRouter, HTTPException, BackgroundTasks
<span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel
<span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Optional</span>

router = APIRouter(prefix=<span class="hljs-string">"/recommendations"</span>, tags=[<span class="hljs-string">"recommendations"</span>])

<span class="hljs-keyword">class</span> <span class="hljs-title class_">AnalyzeRequest</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):
    campaign_id: <span class="hljs-built_in">str</span>
    force_refresh: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>  <span class="hljs-comment"># Skip cache</span>

<span class="hljs-keyword">class</span> <span class="hljs-title class_">AnalyzeResponse</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):
    recommendation_id: <span class="hljs-built_in">str</span>
    recommendation: Recommendation
    status: <span class="hljs-built_in">str</span>

<span class="hljs-keyword">class</span> <span class="hljs-title class_">DecisionRequest</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):
    decision: <span class="hljs-built_in">str</span>  <span class="hljs-comment"># 'approved' or 'rejected'</span>
    feedback: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-literal">None</span>

<span class="hljs-meta">@router.post(<span class="hljs-params"><span class="hljs-string">"/analyze"</span>, response_model=AnalyzeResponse</span>)</span>
<span class="hljs-meta">@limiter.limit(<span class="hljs-params"><span class="hljs-string">"10/minute"</span></span>)  </span><span class="hljs-comment"># Rate limit</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">analyze_campaign</span>(<span class="hljs-params">
    request: AnalyzeRequest,
    background_tasks: BackgroundTasks,
    current_user = Depends(<span class="hljs-params">get_current_user</span>),
    db = Depends(<span class="hljs-params">get_db</span>)
</span>):
    <span class="hljs-string">"""
    Generate recommendation for a campaign
    
    Rate limited to 10 requests/minute per user
    """</span>
    <span class="hljs-keyword">try</span>:
        logger.info(
            <span class="hljs-string">"analyze_campaign_requested"</span>,
            campaign_id=request.campaign_id,
            user=current_user.email
        )
        
        <span class="hljs-comment"># Check if recent recommendation exists (unless force_refresh)</span>
        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> request.force_refresh:
            recent_rec = <span class="hljs-keyword">await</span> db.get_recent_recommendation(
                request.campaign_id,
                hours=<span class="hljs-number">24</span>
            )
            <span class="hljs-keyword">if</span> recent_rec <span class="hljs-keyword">and</span> recent_rec.human_decision <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
                logger.info(<span class="hljs-string">"returning_cached_recommendation"</span>)
                <span class="hljs-keyword">return</span> AnalyzeResponse(
                    recommendation_id=recent_rec.<span class="hljs-built_in">id</span>,
                    recommendation=recent_rec,
                    status=<span class="hljs-string">"cached"</span>
                )
        
        <span class="hljs-comment"># Run agent workflow</span>
        agent = create_marketing_agent()
        result = <span class="hljs-keyword">await</span> agent.ainvoke({
            <span class="hljs-string">"campaign_id"</span>: request.campaign_id
        })
        
        <span class="hljs-comment"># Extract recommendation from workflow state</span>
        recommendation = result[<span class="hljs-string">"recommendation"</span>]
        
        <span class="hljs-comment"># Store in database</span>
        rec_id = <span class="hljs-keyword">await</span> db.store_recommendation(recommendation)
        
        <span class="hljs-comment"># Send notification (async)</span>
        background_tasks.add_task(
            notify_marketing_team,
            recommendation_id=rec_id,
            campaign_id=request.campaign_id
        )
        
        <span class="hljs-comment"># Log for monitoring</span>
        recommendations_total.labels(
            workflow_type=recommendation.recommended_workflow,
            confidence_band=get_confidence_band(recommendation.confidence)
        ).inc()
        
        <span class="hljs-keyword">return</span> AnalyzeResponse(
            recommendation_id=rec_id,
            recommendation=recommendation,
            status=<span class="hljs-string">"generated"</span>
        )
        
    <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
        logger.error(
            <span class="hljs-string">"analyze_campaign_failed"</span>,
            campaign_id=request.campaign_id,
            error=<span class="hljs-built_in">str</span>(e)
        )
        <span class="hljs-keyword">raise</span> HTTPException(status_code=<span class="hljs-number">500</span>, detail=<span class="hljs-built_in">str</span>(e))

<span class="hljs-meta">@router.get(<span class="hljs-params"><span class="hljs-string">"/{recommendation_id}"</span></span>)</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_recommendation</span>(<span class="hljs-params">
    recommendation_id: <span class="hljs-built_in">str</span>,
    current_user = Depends(<span class="hljs-params">get_current_user</span>),
    db = Depends(<span class="hljs-params">get_db</span>)
</span>):
    <span class="hljs-string">"""Retrieve a specific recommendation"""</span>
    rec = <span class="hljs-keyword">await</span> db.get_recommendation(recommendation_id)
    
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> rec:
        <span class="hljs-keyword">raise</span> HTTPException(status_code=<span class="hljs-number">404</span>, detail=<span class="hljs-string">"Recommendation not found"</span>)
    
    <span class="hljs-keyword">return</span> rec

<span class="hljs-meta">@router.post(<span class="hljs-params"><span class="hljs-string">"/{recommendation_id}/decision"</span></span>)</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">record_decision</span>(<span class="hljs-params">
    recommendation_id: <span class="hljs-built_in">str</span>,
    decision: DecisionRequest,
    background_tasks: BackgroundTasks,
    current_user = Depends(<span class="hljs-params">get_current_user</span>),
    db = Depends(<span class="hljs-params">get_db</span>)
</span>):
    <span class="hljs-string">"""
    Record human approval/rejection of recommendation
    """</span>
    <span class="hljs-keyword">if</span> decision.decision <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">'approved'</span>, <span class="hljs-string">'rejected'</span>]:
        <span class="hljs-keyword">raise</span> HTTPException(
            status_code=<span class="hljs-number">400</span>,
            detail=<span class="hljs-string">"Decision must be 'approved' or 'rejected'"</span>
        )
    
    <span class="hljs-comment"># Update database</span>
    <span class="hljs-keyword">await</span> db.update_recommendation(
        recommendation_id=recommendation_id,
        human_decision=decision.decision,
        decided_by=current_user.email,
        decision_feedback=decision.feedback
    )
    
    <span class="hljs-comment"># Metrics</span>
    recommendation_acceptance.labels(
        action =<span class="hljs-string">'approved'</span> <span class="hljs-keyword">if</span> decision.decision == <span class="hljs-string">'approved'</span> <span class="hljs-keyword">else</span> <span class="hljs-string">'rejected'</span>
    ).inc()
    
    <span class="hljs-comment"># If approved, trigger workflow execution</span>
    <span class="hljs-keyword">if</span> decision.decision == <span class="hljs-string">'approved'</span>:
        background_tasks.add_task(
            trigger_workflow_execution,
            recommendation_id=recommendation_id
        )
    
    logger.info(
        <span class="hljs-string">"decision_recorded"</span>,
        recommendation_id=recommendation_id,
        decision=decision.decision,
        decided_by=current_user.email
    )
    
    <span class="hljs-keyword">return</span> {<span class="hljs-string">"status"</span>: <span class="hljs-string">"recorded"</span>}

<span class="hljs-meta">@router.get(<span class="hljs-params"><span class="hljs-string">"/"</span></span>)</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">list_recommendations</span>(<span class="hljs-params">
    status: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-literal">None</span>,  <span class="hljs-comment"># 'pending', 'approved', 'rejected'</span>
    campaign_id: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-literal">None</span>,
    limit: <span class="hljs-built_in">int</span> = <span class="hljs-number">50</span>,
    offset: <span class="hljs-built_in">int</span> = <span class="hljs-number">0</span>,
    current_user = Depends(<span class="hljs-params">get_current_user</span>),
    db = Depends(<span class="hljs-params">get_db</span>)
</span>):
    <span class="hljs-string">"""List recommendations with filtering"""</span>
    recommendations = <span class="hljs-keyword">await</span> db.list_recommendations(
        status=status,
        campaign_id=campaign_id,
        limit=limit,
        offset=offset
    )
    
    <span class="hljs-keyword">return</span> {
        <span class="hljs-string">"recommendations"</span>: recommendations,
        <span class="hljs-string">"limit"</span>: limit,
        <span class="hljs-string">"offset"</span>: offset
    }
</div></code></pre>
<h3 id="8.3-async-workflow-execution" tabindex="-1">8.3 Async Workflow Execution</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># src/workflows/executor.py</span>
<span class="hljs-keyword">from</span> celery <span class="hljs-keyword">import</span> Celery
<span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Dict</span>, <span class="hljs-type">Any</span>

<span class="hljs-comment"># Initialize Celery (for background tasks)</span>
celery_app = Celery(
    <span class="hljs-string">'marketing_agent'</span>,
    broker=<span class="hljs-string">'redis://localhost:6379/0'</span>,
    backend=<span class="hljs-string">'redis://localhost:6379/0'</span>
)

<span class="hljs-meta">@celery_app.task</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">trigger_workflow_execution</span>(<span class="hljs-params">recommendation_id: <span class="hljs-built_in">str</span></span>):
    <span class="hljs-string">"""
    Execute the recommended workflow on external systems
    
    This is where we integrate with existing marketing workflows
    """</span>
    <span class="hljs-comment"># Fetch recommendation</span>
    rec = <span class="hljs-keyword">await</span> db.get_recommendation(recommendation_id)
    
    workflow_handlers = {
        WorkflowType.BID_ADJUSTMENT: execute_bid_adjustment,
        WorkflowType.CREATIVE_REFRESH: execute_creative_refresh,
        WorkflowType.AUDIENCE_EXPANSION: execute_audience_expansion,
        WorkflowType.CAMPAIGN_PAUSE: execute_campaign_pause,
        WorkflowType.BUDGET_REALLOCATION: execute_budget_reallocation,
    }
    
    handler = workflow_handlers.get(rec.recommended_workflow)
    
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> handler:
        logger.error(<span class="hljs-string">f"No handler for workflow: <span class="hljs-subst">{rec.recommended_workflow}</span>"</span>)
        <span class="hljs-keyword">return</span>
    
    <span class="hljs-keyword">try</span>:
        <span class="hljs-comment"># Execute</span>
        result = <span class="hljs-keyword">await</span> handler(rec)
        
        <span class="hljs-comment"># Log execution</span>
        <span class="hljs-keyword">await</span> db.log_workflow_execution(
            recommendation_id=recommendation_id,
            status=<span class="hljs-string">'success'</span>,
            result=result
        )
        
        <span class="hljs-comment"># Schedule outcome tracking (check results in 3 days)</span>
        schedule_outcome_tracking.apply_async(
            args=[recommendation_id],
            countdown=<span class="hljs-number">3</span> * <span class="hljs-number">24</span> * <span class="hljs-number">60</span> * <span class="hljs-number">60</span>  <span class="hljs-comment"># 3 days</span>
        )
        
    <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
        logger.error(
            <span class="hljs-string">"workflow_execution_failed"</span>,
            recommendation_id=recommendation_id,
            error=<span class="hljs-built_in">str</span>(e)
        )
        <span class="hljs-keyword">await</span> db.log_workflow_execution(
            recommendation_id=recommendation_id,
            status=<span class="hljs-string">'error'</span>,
            error=<span class="hljs-built_in">str</span>(e)
        )

<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">execute_bid_adjustment</span>(<span class="hljs-params">rec: Recommendation</span>) -&gt; <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Any</span>]:
    <span class="hljs-string">"""Execute bid adjustment via ad platform API"""</span>
    <span class="hljs-comment"># Parse specific action (e.g., "Increase bid by 15% to $2.88")</span>
    <span class="hljs-keyword">import</span> re
    <span class="hljs-keyword">match</span> = re.search(<span class="hljs-string">r'(\d+)%.*\$(\d+\.\d+)'</span>, rec.specific_action)
    
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">match</span>:
        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">f"Could not parse bid adjustment: <span class="hljs-subst">{rec.specific_action}</span>"</span>)
    
    increase_pct = <span class="hljs-built_in">int</span>(<span class="hljs-keyword">match</span>.group(<span class="hljs-number">1</span>))
    target_bid = <span class="hljs-built_in">float</span>(<span class="hljs-keyword">match</span>.group(<span class="hljs-number">2</span>))
    
    <span class="hljs-comment"># Call ad platform API</span>
    platform_client = get_ad_platform_client(rec.campaign_id)
    result = <span class="hljs-keyword">await</span> platform_client.update_bid(
        campaign_id=rec.campaign_id,
        new_bid=target_bid
    )
    
    <span class="hljs-keyword">return</span> {
        <span class="hljs-string">"action"</span>: <span class="hljs-string">"bid_adjustment"</span>,
        <span class="hljs-string">"previous_bid"</span>: result[<span class="hljs-string">'previous_bid'</span>],
        <span class="hljs-string">"new_bid"</span>: target_bid,
        <span class="hljs-string">"increase_pct"</span>: increase_pct,
        <span class="hljs-string">"executed_at"</span>: datetime.utcnow().isoformat()
    }

<span class="hljs-meta">@celery_app.task</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">schedule_outcome_tracking</span>(<span class="hljs-params">recommendation_id: <span class="hljs-built_in">str</span></span>):
    <span class="hljs-string">"""
    Check campaign performance after recommendation execution
    Track whether expected impact materialized
    """</span>
    rec = <span class="hljs-keyword">await</span> db.get_recommendation(recommendation_id)
    
    <span class="hljs-comment"># Fetch current metrics</span>
    context_builder = ContextBuilder(...)
    current_context = <span class="hljs-keyword">await</span> context_builder.build_context(rec.campaign_id)
    
    <span class="hljs-comment"># Compare to context at recommendation time</span>
    original_context = rec.context
    
    <span class="hljs-comment"># Calculate changes</span>
    cpa_before = original_context[<span class="hljs-string">'campaign_metrics'</span>][<span class="hljs-string">'cpa'</span>]
    cpa_after = current_context[<span class="hljs-string">'campaign_metrics'</span>][<span class="hljs-string">'cpa'</span>]
    cpa_change_pct = ((cpa_after - cpa_before) / cpa_before) * <span class="hljs-number">100</span>
    
    <span class="hljs-comment"># Determine success based on expected impact</span>
    success = evaluate_outcome_success(rec, cpa_change_pct)
    
    <span class="hljs-comment"># Store outcome</span>
    <span class="hljs-keyword">await</span> db.store_outcome(
        recommendation_id=recommendation_id,
        outcome_metrics={
            <span class="hljs-string">"cpa_before"</span>: cpa_before,
            <span class="hljs-string">"cpa_after"</span>: cpa_after,
            <span class="hljs-string">"cpa_change_pct"</span>: cpa_change_pct,
            <span class="hljs-string">"success"</span>: success,
            <span class="hljs-string">"improvement_pct"</span>: -cpa_change_pct <span class="hljs-keyword">if</span> cpa_change_pct &lt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>
        }
    )
    
    <span class="hljs-comment"># Update evaluation dataset</span>
    <span class="hljs-keyword">await</span> add_to_golden_dataset(recommendation_id)
    
    logger.info(
        <span class="hljs-string">"outcome_tracked"</span>,
        recommendation_id=recommendation_id,
        success=success,
        cpa_change_pct=cpa_change_pct
    )
</div></code></pre>
<hr>
<h2 id="9.-deployment-strategy" tabindex="-1">9. Deployment Strategy</h2>
<h3 id="9.1-environment-structure" tabindex="-1">9.1 Environment Structure</h3>
<p><strong>Three Environments:</strong></p>
<ol>
<li>
<p><strong>Development</strong> (<code>dev</code>):</p>
<ul>
<li>Local Docker Compose</li>
<li>Stub data collectors</li>
<li>Mock LLM responses (for fast iteration)</li>
<li>No rate limits</li>
</ul>
</li>
<li>
<p><strong>Staging</strong> (<code>staging</code>):</p>
<ul>
<li>Kubernetes cluster</li>
<li>Real data collectors (sandbox APIs)</li>
<li>Real LLM calls</li>
<li>Human-in-the-loop testing</li>
<li>Production-like config</li>
</ul>
</li>
<li>
<p><strong>Production</strong> (<code>prod</code>):</p>
<ul>
<li>Kubernetes cluster</li>
<li>Real data, real LLMs</li>
<li>High availability (2+ replicas)</li>
<li>Monitoring and alerts</li>
<li>Graduated rollout</li>
</ul>
</li>
</ol>
<h3 id="9.2-deployment-process" tabindex="-1">9.2 Deployment Process</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># .github/workflows/deploy.yml</span>
<span class="hljs-attr">name:</span> <span class="hljs-string">Deploy</span> <span class="hljs-string">Marketing</span> <span class="hljs-string">Agent</span>

<span class="hljs-attr">on:</span>
  <span class="hljs-attr">push:</span>
    <span class="hljs-attr">branches:</span> [<span class="hljs-string">main</span>]
  <span class="hljs-attr">workflow_dispatch:</span>
    <span class="hljs-attr">inputs:</span>
      <span class="hljs-attr">environment:</span>
        <span class="hljs-attr">description:</span> <span class="hljs-string">'Environment to deploy to'</span>
        <span class="hljs-attr">required:</span> <span class="hljs-literal">true</span>
        <span class="hljs-attr">type:</span> <span class="hljs-string">choice</span>
        <span class="hljs-attr">options:</span>
          <span class="hljs-bullet">-</span> <span class="hljs-string">staging</span>
          <span class="hljs-bullet">-</span> <span class="hljs-string">production</span>

<span class="hljs-attr">jobs:</span>
  <span class="hljs-attr">test:</span>
    <span class="hljs-attr">runs-on:</span> <span class="hljs-string">ubuntu-latest</span>
    <span class="hljs-attr">steps:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/checkout@v3</span>
      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Run</span> <span class="hljs-string">unit</span> <span class="hljs-string">tests</span>
        <span class="hljs-attr">run:</span> <span class="hljs-string">pytest</span> <span class="hljs-string">tests/unit</span>
      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Run</span> <span class="hljs-string">integration</span> <span class="hljs-string">tests</span>
        <span class="hljs-attr">run:</span> <span class="hljs-string">pytest</span> <span class="hljs-string">tests/integration</span>
  
  <span class="hljs-attr">evaluate:</span>
    <span class="hljs-attr">needs:</span> <span class="hljs-string">test</span>
    <span class="hljs-attr">runs-on:</span> <span class="hljs-string">ubuntu-latest</span>
    <span class="hljs-attr">steps:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/checkout@v3</span>
      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Run</span> <span class="hljs-string">golden</span> <span class="hljs-string">set</span> <span class="hljs-string">evaluation</span>
        <span class="hljs-attr">env:</span>
          <span class="hljs-attr">OPENAI_API_KEY:</span> <span class="hljs-string">${{</span> <span class="hljs-string">secrets.OPENAI_API_KEY</span> <span class="hljs-string">}}</span>
        <span class="hljs-attr">run:</span> <span class="hljs-string">python</span> <span class="hljs-string">-m</span> <span class="hljs-string">evaluation.run_golden_set</span>
      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Check</span> <span class="hljs-string">quality</span> <span class="hljs-string">threshold</span>
        <span class="hljs-attr">run:</span> <span class="hljs-string">|
          python -m evaluation.check_deployment_criteria
</span>  
  <span class="hljs-attr">deploy-staging:</span>
    <span class="hljs-attr">needs:</span> <span class="hljs-string">evaluate</span>
    <span class="hljs-attr">runs-on:</span> <span class="hljs-string">ubuntu-latest</span>
    <span class="hljs-attr">environment:</span> <span class="hljs-string">staging</span>
    <span class="hljs-attr">steps:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/checkout@v3</span>
      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Configure</span> <span class="hljs-string">kubectl</span>
        <span class="hljs-attr">uses:</span> <span class="hljs-string">azure/k8s-set-context@v1</span>
        <span class="hljs-attr">with:</span>
          <span class="hljs-attr">method:</span> <span class="hljs-string">kubeconfig</span>
          <span class="hljs-attr">kubeconfig:</span> <span class="hljs-string">${{</span> <span class="hljs-string">secrets.KUBE_CONFIG_STAGING</span> <span class="hljs-string">}}</span>
      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Deploy</span> <span class="hljs-string">to</span> <span class="hljs-string">staging</span>
        <span class="hljs-attr">run:</span> <span class="hljs-string">|
          kubectl apply -f k8s/staging/
          kubectl rollout status deployment/marketing-agent
</span>      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Run</span> <span class="hljs-string">smoke</span> <span class="hljs-string">tests</span>
        <span class="hljs-attr">run:</span> <span class="hljs-string">python</span> <span class="hljs-string">-m</span> <span class="hljs-string">tests.smoke_tests</span> <span class="hljs-string">--env</span> <span class="hljs-string">staging</span>
  
  <span class="hljs-attr">deploy-production:</span>
    <span class="hljs-attr">needs:</span> <span class="hljs-string">deploy-staging</span>
    <span class="hljs-attr">runs-on:</span> <span class="hljs-string">ubuntu-latest</span>
    <span class="hljs-attr">environment:</span> <span class="hljs-string">production</span>
    <span class="hljs-attr">if:</span> <span class="hljs-string">github.event_name</span> <span class="hljs-string">==</span> <span class="hljs-string">'workflow_dispatch'</span> <span class="hljs-string">&amp;&amp;</span> <span class="hljs-string">github.event.inputs.environment</span> <span class="hljs-string">==</span> <span class="hljs-string">'production'</span>
    <span class="hljs-attr">steps:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/checkout@v3</span>
      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Configure</span> <span class="hljs-string">kubectl</span>
        <span class="hljs-attr">uses:</span> <span class="hljs-string">azure/k8s-set-context@v1</span>
        <span class="hljs-attr">with:</span>
          <span class="hljs-attr">method:</span> <span class="hljs-string">kubeconfig</span>
          <span class="hljs-attr">kubeconfig:</span> <span class="hljs-string">${{</span> <span class="hljs-string">secrets.KUBE_CONFIG_PROD</span> <span class="hljs-string">}}</span>
      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Deploy</span> <span class="hljs-string">with</span> <span class="hljs-string">canary</span> <span class="hljs-string">rollout</span>
        <span class="hljs-attr">run:</span> <span class="hljs-string">|
          # Deploy canary (10% traffic)
          kubectl apply -f k8s/production/canary/
</span>          
          <span class="hljs-comment"># Wait and monitor</span>
          <span class="hljs-string">sleep</span> <span class="hljs-number">300</span>  <span class="hljs-comment"># 5 minutes</span>
          
          <span class="hljs-comment"># Check canary metrics</span>
          <span class="hljs-string">python</span> <span class="hljs-string">-m</span> <span class="hljs-string">deployment.check_canary_health</span>
          
          <span class="hljs-comment"># If healthy, proceed with full rollout</span>
          <span class="hljs-string">kubectl</span> <span class="hljs-string">apply</span> <span class="hljs-string">-f</span> <span class="hljs-string">k8s/production/</span>
          <span class="hljs-string">kubectl</span> <span class="hljs-string">rollout</span> <span class="hljs-string">status</span> <span class="hljs-string">deployment/marketing-agent</span>
      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Notify</span> <span class="hljs-string">team</span>
        <span class="hljs-attr">uses:</span> <span class="hljs-string">8398a7/action-slack@v3</span>
        <span class="hljs-attr">with:</span>
          <span class="hljs-attr">status:</span> <span class="hljs-string">${{</span> <span class="hljs-string">job.status</span> <span class="hljs-string">}}</span>
          <span class="hljs-attr">text:</span> <span class="hljs-string">'Marketing Agent deployed to production'</span>
          <span class="hljs-attr">webhook_url:</span> <span class="hljs-string">${{</span> <span class="hljs-string">secrets.SLACK_WEBHOOK</span> <span class="hljs-string">}}</span>
</div></code></pre>
<h3 id="9.3-kubernetes-configuration" tabindex="-1">9.3 Kubernetes Configuration</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># k8s/production/deployment.yaml</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">marketing-agent</span>
  <span class="hljs-attr">namespace:</span> <span class="hljs-string">production</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">replicas:</span> <span class="hljs-number">3</span>
  <span class="hljs-attr">strategy:</span>
    <span class="hljs-attr">type:</span> <span class="hljs-string">RollingUpdate</span>
    <span class="hljs-attr">rollingUpdate:</span>
      <span class="hljs-attr">maxSurge:</span> <span class="hljs-number">1</span>
      <span class="hljs-attr">maxUnavailable:</span> <span class="hljs-number">0</span>
  <span class="hljs-attr">selector:</span>
    <span class="hljs-attr">matchLabels:</span>
      <span class="hljs-attr">app:</span> <span class="hljs-string">marketing-agent</span>
  <span class="hljs-attr">template:</span>
    <span class="hljs-attr">metadata:</span>
      <span class="hljs-attr">labels:</span>
        <span class="hljs-attr">app:</span> <span class="hljs-string">marketing-agent</span>
        <span class="hljs-attr">version:</span> <span class="hljs-string">v1</span>
    <span class="hljs-attr">spec:</span>
      <span class="hljs-attr">containers:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">backend</span>
        <span class="hljs-attr">image:</span> <span class="hljs-string">marketing-agent:latest</span>
        <span class="hljs-attr">ports:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">8000</span>
        <span class="hljs-attr">env:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">DATABASE_URL</span>
          <span class="hljs-attr">valueFrom:</span>
            <span class="hljs-attr">secretKeyRef:</span>
              <span class="hljs-attr">name:</span> <span class="hljs-string">marketing-agent-secrets</span>
              <span class="hljs-attr">key:</span> <span class="hljs-string">database-url</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">OPENAI_API_KEY</span>
          <span class="hljs-attr">valueFrom:</span>
            <span class="hljs-attr">secretKeyRef:</span>
              <span class="hljs-attr">name:</span> <span class="hljs-string">marketing-agent-secrets</span>
              <span class="hljs-attr">key:</span> <span class="hljs-string">openai-api-key</span>
        <span class="hljs-attr">resources:</span>
          <span class="hljs-attr">requests:</span>
            <span class="hljs-attr">memory:</span> <span class="hljs-string">"512Mi"</span>
            <span class="hljs-attr">cpu:</span> <span class="hljs-string">"500m"</span>
          <span class="hljs-attr">limits:</span>
            <span class="hljs-attr">memory:</span> <span class="hljs-string">"2Gi"</span>
            <span class="hljs-attr">cpu:</span> <span class="hljs-string">"2000m"</span>
        <span class="hljs-attr">livenessProbe:</span>
          <span class="hljs-attr">httpGet:</span>
            <span class="hljs-attr">path:</span> <span class="hljs-string">/health</span>
            <span class="hljs-attr">port:</span> <span class="hljs-number">8000</span>
          <span class="hljs-attr">initialDelaySeconds:</span> <span class="hljs-number">30</span>
          <span class="hljs-attr">periodSeconds:</span> <span class="hljs-number">10</span>
        <span class="hljs-attr">readinessProbe:</span>
          <span class="hljs-attr">httpGet:</span>
            <span class="hljs-attr">path:</span> <span class="hljs-string">/health</span>
            <span class="hljs-attr">port:</span> <span class="hljs-number">8000</span>
          <span class="hljs-attr">initialDelaySeconds:</span> <span class="hljs-number">5</span>
          <span class="hljs-attr">periodSeconds:</span> <span class="hljs-number">5</span>
      
      <span class="hljs-comment"># Sidecar: Prometheus exporter</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">metrics-exporter</span>
        <span class="hljs-attr">image:</span> <span class="hljs-string">prom/prometheus:latest</span>
        <span class="hljs-attr">ports:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">9090</span>

<span class="hljs-meta">---</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">marketing-agent-service</span>
  <span class="hljs-attr">namespace:</span> <span class="hljs-string">production</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">selector:</span>
    <span class="hljs-attr">app:</span> <span class="hljs-string">marketing-agent</span>
  <span class="hljs-attr">ports:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span>
    <span class="hljs-attr">port:</span> <span class="hljs-number">80</span>
    <span class="hljs-attr">targetPort:</span> <span class="hljs-number">8000</span>
  <span class="hljs-attr">type:</span> <span class="hljs-string">LoadBalancer</span>

<span class="hljs-meta">---</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">autoscaling/v2</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">HorizontalPodAutoscaler</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">marketing-agent-hpa</span>
  <span class="hljs-attr">namespace:</span> <span class="hljs-string">production</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">scaleTargetRef:</span>
    <span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span>
    <span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span>
    <span class="hljs-attr">name:</span> <span class="hljs-string">marketing-agent</span>
  <span class="hljs-attr">minReplicas:</span> <span class="hljs-number">3</span>
  <span class="hljs-attr">maxReplicas:</span> <span class="hljs-number">10</span>
  <span class="hljs-attr">metrics:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">type:</span> <span class="hljs-string">Resource</span>
    <span class="hljs-attr">resource:</span>
      <span class="hljs-attr">name:</span> <span class="hljs-string">cpu</span>
      <span class="hljs-attr">target:</span>
        <span class="hljs-attr">type:</span> <span class="hljs-string">Utilization</span>
        <span class="hljs-attr">averageUtilization:</span> <span class="hljs-number">70</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">type:</span> <span class="hljs-string">Resource</span>
    <span class="hljs-attr">resource:</span>
      <span class="hljs-attr">name:</span> <span class="hljs-string">memory</span>
      <span class="hljs-attr">target:</span>
        <span class="hljs-attr">type:</span> <span class="hljs-string">Utilization</span>
        <span class="hljs-attr">averageUtilization:</span> <span class="hljs-number">80</span>
</div></code></pre>
<h3 id="9.4-rollout-strategy" tabindex="-1">9.4 Rollout Strategy</h3>
<p><strong>Week 1-2: Shadow Mode</strong></p>
<ul>
<li>Agent runs in background</li>
<li>Generates recommendations</li>
<li>No UI, no notifications</li>
<li>Compare to what humans actually decide</li>
<li>Goal: Baseline agreement rate</li>
</ul>
<p><strong>Week 3-4: Internal Beta</strong></p>
<ul>
<li>Show to 2-3 marketing team members</li>
<li>Feedback collection focus</li>
<li>Iteration on prompts and reasoning</li>
<li>Goal: Refine to &gt;60% acceptance</li>
</ul>
<p><strong>Week 5-8: Limited Production</strong></p>
<ul>
<li>Roll out to 25% of campaigns</li>
<li>Full human approval required</li>
<li>Weekly feedback sessions</li>
<li>Goal: Achieve 70% acceptance rate</li>
</ul>
<p><strong>Week 9+: Full Production</strong></p>
<ul>
<li>All campaigns eligible</li>
<li>Auto-notifications</li>
<li>Graduated autonomy for high-confidence cases</li>
<li>Goal: Scale and optimize</li>
</ul>
<hr>
<h2 id="10.-monitoring-%26-observability" tabindex="-1">10. Monitoring &amp; Observability</h2>
<h3 id="10.1-metrics-dashboard" tabindex="-1">10.1 Metrics Dashboard</h3>
<p><strong>Business Metrics:</strong></p>
<pre class="hljs"><code><div><span class="hljs-comment"># src/monitoring/metrics.py</span>
<span class="hljs-keyword">from</span> prometheus_client <span class="hljs-keyword">import</span> Counter, Histogram, Gauge

<span class="hljs-comment"># Recommendation tracking</span>
recommendations_total = Counter(
    <span class="hljs-string">'recommendations_total'</span>,
    <span class="hljs-string">'Total recommendations generated'</span>,
    [<span class="hljs-string">'workflow_type'</span>, <span class="hljs-string">'confidence_band'</span>]
)

recommendation_acceptance = Counter(
    <span class="hljs-string">'recommendation_acceptance_total'</span>,
    <span class="hljs-string">'Recommendations accepted by humans'</span>,
    [<span class="hljs-string">'workflow_type'</span>]
)

recommendation_latency = Histogram(
    <span class="hljs-string">'recommendation_latency_seconds'</span>,
    <span class="hljs-string">'Time to generate recommendation'</span>,
    buckets=[<span class="hljs-number">5</span>, <span class="hljs-number">10</span>, <span class="hljs-number">15</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>, <span class="hljs-number">45</span>, <span class="hljs-number">60</span>]
)

<span class="hljs-comment"># Quality metrics</span>
confidence_score_distribution = Histogram(
    <span class="hljs-string">'confidence_score'</span>,
    <span class="hljs-string">'Distribution of confidence scores'</span>,
    buckets=[<span class="hljs-number">0.0</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.7</span>, <span class="hljs-number">0.8</span>, <span class="hljs-number">0.9</span>, <span class="hljs-number">1.0</span>]
)

agreement_rate_daily = Gauge(
    <span class="hljs-string">'agreement_rate_daily'</span>,
    <span class="hljs-string">'Daily agreement rate with human decisions'</span>
)

<span class="hljs-comment"># LLM metrics</span>
llm_tokens_used = Counter(
    <span class="hljs-string">'llm_tokens_total'</span>,
    <span class="hljs-string">'Total LLM tokens consumed'</span>,
    [<span class="hljs-string">'model'</span>, <span class="hljs-string">'operation'</span>]
)

llm_cost_usd = Counter(
    <span class="hljs-string">'llm_cost_usd_total'</span>,
    <span class="hljs-string">'Total LLM API costs in USD'</span>
)

llm_api_errors = Counter(
    <span class="hljs-string">'llm_api_errors_total'</span>,
    <span class="hljs-string">'LLM API error count'</span>,
    [<span class="hljs-string">'model'</span>, <span class="hljs-string">'error_type'</span>]
)

<span class="hljs-comment"># Workflow execution</span>
workflow_execution_total = Counter(
    <span class="hljs-string">'workflow_execution_total'</span>,
    <span class="hljs-string">'Workflows executed in external systems'</span>,
    [<span class="hljs-string">'workflow_type'</span>, <span class="hljs-string">'status'</span>]
)

workflow_execution_duration = Histogram(
    <span class="hljs-string">'workflow_execution_duration_seconds'</span>,
    <span class="hljs-string">'Time to execute workflow'</span>,
    [<span class="hljs-string">'workflow_type'</span>]
)

<span class="hljs-comment"># Outcome tracking</span>
recommendation_impact = Gauge(
    <span class="hljs-string">'recommendation_impact_pct'</span>,
    <span class="hljs-string">'Average metric improvement when recommendation followed'</span>,
    [<span class="hljs-string">'workflow_type'</span>]
)
</div></code></pre>
<p><strong>Grafana Dashboard (JSON):</strong></p>
<pre class="hljs"><code><div><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">"title"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Marketing Agent - Overview"</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"panels"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
    <span class="hljs-punctuation">{</span>
      <span class="hljs-attr">"title"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Recommendations per Day"</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">"targets"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
        <span class="hljs-punctuation">{</span>
          <span class="hljs-attr">"expr"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"rate(recommendations_total[1d])"</span>
        <span class="hljs-punctuation">}</span>
      <span class="hljs-punctuation">]</span>
    <span class="hljs-punctuation">}</span><span class="hljs-punctuation">,</span>
    <span class="hljs-punctuation">{</span>
      <span class="hljs-attr">"title"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Acceptance Rate"</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">"targets"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
        <span class="hljs-punctuation">{</span>
          <span class="hljs-attr">"expr"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"rate(recommendation_acceptance_total[1d]) / rate(recommendations_total[1d]) * 100"</span>
        <span class="hljs-punctuation">}</span>
      <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">"alert"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
        <span class="hljs-attr">"conditions"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
          <span class="hljs-punctuation">{</span>
            <span class="hljs-attr">"evaluator"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
              <span class="hljs-attr">"params"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-number">70</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
              <span class="hljs-attr">"type"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"lt"</span>
            <span class="hljs-punctuation">}</span><span class="hljs-punctuation">,</span>
            <span class="hljs-attr">"query"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
              <span class="hljs-attr">"expr"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"acceptance_rate"</span>
            <span class="hljs-punctuation">}</span>
          <span class="hljs-punctuation">}</span>
        <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">"message"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Acceptance rate dropped below 70%"</span>
      <span class="hljs-punctuation">}</span>
    <span class="hljs-punctuation">}</span><span class="hljs-punctuation">,</span>
    <span class="hljs-punctuation">{</span>
      <span class="hljs-attr">"title"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"p95 Latency"</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">"targets"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
        <span class="hljs-punctuation">{</span>
          <span class="hljs-attr">"expr"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"histogram_quantile(0.95, rate(recommendation_latency_seconds_bucket[5m]))"</span>
        <span class="hljs-punctuation">}</span>
      <span class="hljs-punctuation">]</span>
    <span class="hljs-punctuation">}</span><span class="hljs-punctuation">,</span>
    <span class="hljs-punctuation">{</span>
      <span class="hljs-attr">"title"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"LLM Cost per Day"</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">"targets"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
        <span class="hljs-punctuation">{</span>
          <span class="hljs-attr">"expr"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"increase(llm_cost_usd_total[1d])"</span>
        <span class="hljs-punctuation">}</span>
      <span class="hljs-punctuation">]</span>
    <span class="hljs-punctuation">}</span>
  <span class="hljs-punctuation">]</span>
<span class="hljs-punctuation">}</span>
</div></code></pre>
<h3 id="10.2-langsmith-integration" tabindex="-1">10.2 LangSmith Integration</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># src/agent/workflow.py</span>
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">from</span> langsmith <span class="hljs-keyword">import</span> Client
<span class="hljs-keyword">from</span> langsmith.run_helpers <span class="hljs-keyword">import</span> traceable

<span class="hljs-comment"># Initialize LangSmith</span>
os.environ[<span class="hljs-string">"LANGCHAIN_TRACING_V2"</span>] = <span class="hljs-string">"true"</span>
os.environ[<span class="hljs-string">"LANGCHAIN_PROJECT"</span>] = <span class="hljs-string">"marketing-agent-prod"</span>

<span class="hljs-meta">@traceable(<span class="hljs-params">run_type=<span class="hljs-string">"chain"</span>, name=<span class="hljs-string">"marketing_agent"</span></span>)</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">run_marketing_agent</span>(<span class="hljs-params">campaign_id: <span class="hljs-built_in">str</span></span>):
    <span class="hljs-string">"""
    Traced agent execution - all LLM calls, latencies, 
    and intermediate states visible in LangSmith
    """</span>
    workflow = create_marketing_agent()
    result = <span class="hljs-keyword">await</span> workflow.ainvoke({<span class="hljs-string">"campaign_id"</span>: campaign_id})
    <span class="hljs-keyword">return</span> result
</div></code></pre>
<p><strong>LangSmith Benefits:</strong></p>
<ul>
<li>Trace every LLM call with inputs/outputs</li>
<li>Visualize workflow execution paths</li>
<li>Debug failures with full context</li>
<li>Compare prompt versions</li>
<li>Production query: "Find all recommendations with confidence &lt; 0.6"</li>
</ul>
<h3 id="10.3-alerting-rules" tabindex="-1">10.3 Alerting Rules</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># monitoring/alerting_rules.yml</span>
<span class="hljs-attr">groups:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">marketing_agent_alerts</span>
    <span class="hljs-attr">interval:</span> <span class="hljs-string">1m</span>
    <span class="hljs-attr">rules:</span>
      <span class="hljs-comment"># Quality alerts</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">alert:</span> <span class="hljs-string">AcceptanceRateLow</span>
        <span class="hljs-attr">expr:</span> <span class="hljs-string">acceptance_rate_daily</span> <span class="hljs-string">&lt;</span> <span class="hljs-number">0.70</span>
        <span class="hljs-attr">for:</span> <span class="hljs-string">1h</span>
        <span class="hljs-attr">labels:</span>
          <span class="hljs-attr">severity:</span> <span class="hljs-string">warning</span>
        <span class="hljs-attr">annotations:</span>
          <span class="hljs-attr">summary:</span> <span class="hljs-string">"Acceptance rate dropped below 70%"</span>
          <span class="hljs-attr">description:</span> <span class="hljs-string">"Current rate: <span class="hljs-template-variable">{{ $value }}</span>%"</span>
      
      <span class="hljs-bullet">-</span> <span class="hljs-attr">alert:</span> <span class="hljs-string">HighErrorRate</span>
        <span class="hljs-attr">expr:</span> <span class="hljs-string">rate(llm_api_errors_total[5m])</span> <span class="hljs-string">&gt;</span> <span class="hljs-number">0.1</span>
        <span class="hljs-attr">for:</span> <span class="hljs-string">5m</span>
        <span class="hljs-attr">labels:</span>
          <span class="hljs-attr">severity:</span> <span class="hljs-string">critical</span>
        <span class="hljs-attr">annotations:</span>
          <span class="hljs-attr">summary:</span> <span class="hljs-string">"LLM API error rate elevated"</span>
      
      <span class="hljs-comment"># Performance alerts</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">alert:</span> <span class="hljs-string">HighLatency</span>
        <span class="hljs-attr">expr:</span> <span class="hljs-string">histogram_quantile(0.95,</span> <span class="hljs-string">rate(recommendation_latency_seconds_bucket[5m]))</span> <span class="hljs-string">&gt;</span> <span class="hljs-number">30</span>
        <span class="hljs-attr">for:</span> <span class="hljs-string">10m</span>
        <span class="hljs-attr">labels:</span>
          <span class="hljs-attr">severity:</span> <span class="hljs-string">warning</span>
        <span class="hljs-attr">annotations:</span>
          <span class="hljs-attr">summary:</span> <span class="hljs-string">"p95 latency &gt; 30 seconds"</span>
      
      <span class="hljs-comment"># Cost alerts</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">alert:</span> <span class="hljs-string">DailyCostExceeded</span>
        <span class="hljs-attr">expr:</span> <span class="hljs-string">increase(llm_cost_usd_total[1d])</span> <span class="hljs-string">&gt;</span> <span class="hljs-number">100</span>
        <span class="hljs-attr">labels:</span>
          <span class="hljs-attr">severity:</span> <span class="hljs-string">warning</span>
        <span class="hljs-attr">annotations:</span>
          <span class="hljs-attr">summary:</span> <span class="hljs-string">"Daily LLM costs exceeded $100"</span>
      
      <span class="hljs-comment"># Business alerts</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">alert:</span> <span class="hljs-string">NoRecommendations</span>
        <span class="hljs-attr">expr:</span> <span class="hljs-string">rate(recommendations_total[1h])</span> <span class="hljs-string">==</span> <span class="hljs-number">0</span>
        <span class="hljs-attr">for:</span> <span class="hljs-string">2h</span>
        <span class="hljs-attr">labels:</span>
          <span class="hljs-attr">severity:</span> <span class="hljs-string">critical</span>
        <span class="hljs-attr">annotations:</span>
          <span class="hljs-attr">summary:</span> <span class="hljs-string">"No recommendations generated in 2 hours"</span>
</div></code></pre>
<h3 id="10.4-log-aggregation" tabindex="-1">10.4 Log Aggregation</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># src/monitoring/logging.py</span>
<span class="hljs-keyword">import</span> structlog
<span class="hljs-keyword">import</span> logging
<span class="hljs-keyword">from</span> pythonjsonlogger <span class="hljs-keyword">import</span> jsonlogger

<span class="hljs-keyword">def</span> <span class="hljs-title function_">setup_logging</span>():
    <span class="hljs-string">"""Configure structured logging"""</span>
    
    <span class="hljs-comment"># JSON formatter for machine parsing</span>
    logHandler = logging.StreamHandler()
    formatter = jsonlogger.JsonFormatter(
        <span class="hljs-string">'%(timestamp)s %(level)s %(name)s %(message)s'</span>
    )
    logHandler.setFormatter(formatter)
    
    <span class="hljs-comment"># Configure structlog</span>
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.TimeStamper(fmt=<span class="hljs-string">"iso"</span>),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.processors.JSONRenderer()
        ],
        context_class=<span class="hljs-built_in">dict</span>,
        logger_factory=structlog.stdlib.LoggerFactory(),
        cache_logger_on_first_use=<span class="hljs-literal">True</span>,
    )
    
    logging.basicConfig(
        <span class="hljs-built_in">format</span>=<span class="hljs-string">"%(message)s"</span>,
        stream=sys.stdout,
        level=logging.INFO,
        handlers=[logHandler]
    )

<span class="hljs-comment"># Usage</span>
logger = structlog.get_logger()

logger.info(
    <span class="hljs-string">"recommendation_generated"</span>,
    campaign_id=<span class="hljs-string">"camp_123"</span>,
    workflow=<span class="hljs-string">"Bid Adjustment"</span>,
    confidence=<span class="hljs-number">0.85</span>,
    user_id=<span class="hljs-string">"user_456"</span>
)
</div></code></pre>
<p><strong>Logs Example:</strong></p>
<pre class="hljs"><code><div><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">"timestamp"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"2026-02-11T10:30:45.123Z"</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"level"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"info"</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"name"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"marketing_agent"</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"event"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"recommendation_generated"</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"campaign_id"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"camp_123"</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"workflow"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Bid Adjustment"</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"confidence"</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.85</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"user_id"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"user_456"</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"duration_ms"</span><span class="hljs-punctuation">:</span> <span class="hljs-number">12450</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">"llm_tokens"</span><span class="hljs-punctuation">:</span> <span class="hljs-number">3200</span>
<span class="hljs-punctuation">}</span>
</div></code></pre>
<hr>
<h2 id="11.-cost-management" tabindex="-1">11. Cost Management</h2>
<h3 id="11.1-cost-breakdown-projection" tabindex="-1">11.1 Cost Breakdown Projection</h3>
<p><strong>Assumptions:</strong></p>
<ul>
<li>100 campaigns monitored</li>
<li>1 recommendation per campaign per week</li>
<li>Average context: 5,000 input tokens</li>
<li>Average output: 1,500 tokens</li>
</ul>
<p><strong>Monthly Costs (OpenAI GPT-4o):</strong></p>
<table>
<thead>
<tr>
<th>Component</th>
<th>Usage</th>
<th>Cost per Unit</th>
<th>Monthly Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Context Collection</strong></td>
<td>400 requests × 5k tokens</td>
<td>$0.15/1M token</td>
<td>$3.00</td>
</tr>
<tr>
<td><strong>Signal Analysis</strong></td>
<td>400 requests × 7k tokens</td>
<td>$0.15/1M token</td>
<td>$4.20</td>
</tr>
<tr>
<td><strong>Recommendation Gen</strong></td>
<td>400 requests × 1.5k tokens</td>
<td>$0.60/1M token</td>
<td>$3.60</td>
</tr>
<tr>
<td><strong>Critique Loop</strong></td>
<td>200 requests × 3k tokens</td>
<td>$0.15/1M token</td>
<td>$0.90</td>
</tr>
<tr>
<td><strong>LLM-as-Judge Eval</strong></td>
<td>100 requests × 5k tokens</td>
<td>$0.15/1M token</td>
<td>$0.75</td>
</tr>
<tr>
<td><strong>Infrastructure</strong></td>
<td>AWS/Kubernetes</td>
<td>-</td>
<td>$200</td>
</tr>
<tr>
<td><strong>Total</strong></td>
<td></td>
<td></td>
<td><strong>~$212/month</strong></td>
</tr>
</tbody>
</table>
<h3 id="11.2-cost-optimization-strategies" tabindex="-1">11.2 Cost Optimization Strategies</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># src/agent/cost_optimizer.py</span>

<span class="hljs-keyword">class</span> <span class="hljs-title class_">CostOptimizer</span>:
    <span class="hljs-string">"""Optimize LLM usage to reduce costs"""</span>
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):
        <span class="hljs-variable language_">self</span>.cache = RedisCache(ttl=<span class="hljs-number">3600</span>)
    
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_cached_analysis</span>(<span class="hljs-params">
        self, 
        context_hash: <span class="hljs-built_in">str</span>
    </span>) -&gt; <span class="hljs-type">Optional</span>[<span class="hljs-built_in">dict</span>]:
        <span class="hljs-string">"""
        Cache analysis results for similar contexts
        
        If two campaigns have nearly identical metrics,
        reuse analysis with minor adjustments
        """</span>
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">await</span> <span class="hljs-variable language_">self</span>.cache.get(<span class="hljs-string">f"analysis:<span class="hljs-subst">{context_hash}</span>"</span>)
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">select_model_by_complexity</span>(<span class="hljs-params">
        self,
        context: CampaignContext
    </span>) -&gt; <span class="hljs-built_in">str</span>:
        <span class="hljs-string">"""
        Use cheaper models for simple cases
        
        - GPT-4o: Complex reasoning, edge cases
        - GPT-4o-mini: Straightforward cases
        """</span>
        <span class="hljs-comment"># Calculate complexity score</span>
        complexity = <span class="hljs-number">0</span>
        
        <span class="hljs-comment"># Many metrics changed significantly</span>
        <span class="hljs-keyword">if</span> context[<span class="hljs-string">'campaign_metrics'</span>][<span class="hljs-string">'cpa_change_pct'</span>] &gt; <span class="hljs-number">50</span>:
            complexity += <span class="hljs-number">2</span>
        
        <span class="hljs-comment"># Conflicting signals</span>
        <span class="hljs-keyword">if</span> has_conflicting_signals(context):
            complexity += <span class="hljs-number">3</span>
        
        <span class="hljs-comment"># Novel scenario</span>
        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> has_similar_historical_case(context):
            complexity += <span class="hljs-number">2</span>
        
        <span class="hljs-comment"># Select model</span>
        <span class="hljs-keyword">if</span> complexity &gt;= <span class="hljs-number">5</span>:
            <span class="hljs-keyword">return</span> <span class="hljs-string">"gpt-4o"</span>  <span class="hljs-comment"># $0.15/$0.60 per 1M tokens</span>
        <span class="hljs-keyword">else</span>:
            <span class="hljs-keyword">return</span> <span class="hljs-string">"gpt-4o-mini"</span>  <span class="hljs-comment"># $0.03/$0.12 per 1M tokens</span>
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compress_context</span>(<span class="hljs-params">
        self,
        context: CampaignContext
    </span>) -&gt; <span class="hljs-built_in">dict</span>:
        <span class="hljs-string">"""
        Reduce token count by removing redundant info
        
        - Round numbers to 2 decimals
        - Remove null/empty fields
        - Summarize historical data
        """</span>
        compressed = {}
        
        <span class="hljs-comment"># Only include metrics with significant changes</span>
        metrics = context[<span class="hljs-string">'campaign_metrics'</span>]
        compressed[<span class="hljs-string">'metrics'</span>] = {
            k: <span class="hljs-built_in">round</span>(v, <span class="hljs-number">2</span>) <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(v, <span class="hljs-built_in">float</span>) <span class="hljs-keyword">else</span> v
            <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> metrics.items()
            <span class="hljs-keyword">if</span> k.endswith(<span class="hljs-string">'_change_pct'</span>) <span class="hljs-keyword">and</span> <span class="hljs-built_in">abs</span>(v) &gt; <span class="hljs-number">5</span>  <span class="hljs-comment"># &gt;5% change</span>
        }
        
        <span class="hljs-comment"># Summarize instead of full detail</span>
        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(context.get(<span class="hljs-string">'historical_patterns'</span>, [])) &gt; <span class="hljs-number">5</span>:
            compressed[<span class="hljs-string">'historical_summary'</span>] = summarize_patterns(
                context[<span class="hljs-string">'historical_patterns'</span>]
            )
        
        <span class="hljs-keyword">return</span> compressed

<span class="hljs-comment"># Apply optimization</span>
optimizer = CostOptimizer()

model = optimizer.select_model_by_complexity(context)
cached_result = <span class="hljs-keyword">await</span> optimizer.get_cached_analysis(context_hash)

<span class="hljs-keyword">if</span> cached_result:
    logger.info(<span class="hljs-string">"Using cached analysis"</span>, savings_usd=<span class="hljs-number">0.05</span>)
    <span class="hljs-keyword">return</span> cached_result
</div></code></pre>
<h3 id="11.3-cost-tracking" tabindex="-1">11.3 Cost Tracking</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># src/monitoring/cost_tracker.py</span>
<span class="hljs-keyword">from</span> dataclasses <span class="hljs-keyword">import</span> dataclass

<span class="hljs-meta">@dataclass</span>
<span class="hljs-keyword">class</span> <span class="hljs-title class_">LLMUsage</span>:
    model: <span class="hljs-built_in">str</span>
    input_tokens: <span class="hljs-built_in">int</span>
    output_tokens: <span class="hljs-built_in">int</span>
    timestamp: datetime

<span class="hljs-keyword">class</span> <span class="hljs-title class_">CostTracker</span>:
    <span class="hljs-string">"""Track and report LLM costs"""</span>
    
    PRICING = {
        <span class="hljs-string">"gpt-4o"</span>: {<span class="hljs-string">"input"</span>: <span class="hljs-number">0.15</span> / <span class="hljs-number">1_000_000</span>, <span class="hljs-string">"output"</span>: <span class="hljs-number">0.60</span> / <span class="hljs-number">1_000_000</span>},
        <span class="hljs-string">"gpt-4o-mini"</span>: {<span class="hljs-string">"input"</span>: <span class="hljs-number">0.03</span> / <span class="hljs-number">1_000_000</span>, <span class="hljs-string">"output"</span>: <span class="hljs-number">0.12</span> / <span class="hljs-number">1_000_000</span>},
        <span class="hljs-string">"claude-3-5-sonnet"</span>: {<span class="hljs-string">"input"</span>: <span class="hljs-number">0.15</span> / <span class="hljs-number">1_000_000</span>, <span class="hljs-string">"output"</span>: <span class="hljs-number">0.60</span> / <span class="hljs-number">1_000_000</span>},
    }
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_cost</span>(<span class="hljs-params">self, usage: LLMUsage</span>) -&gt; <span class="hljs-built_in">float</span>:
        <span class="hljs-string">"""Calculate cost for a single LLM call"""</span>
        pricing = <span class="hljs-variable language_">self</span>.PRICING.get(usage.model, <span class="hljs-variable language_">self</span>.PRICING[<span class="hljs-string">"gpt-4o"</span>])
        
        input_cost = usage.input_tokens * pricing[<span class="hljs-string">"input"</span>]
        output_cost = usage.output_tokens * pricing[<span class="hljs-string">"output"</span>]
        
        <span class="hljs-keyword">return</span> input_cost + output_cost
    
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_cost_report</span>(<span class="hljs-params">
        self,
        start_date: datetime,
        end_date: datetime
    </span>) -&gt; <span class="hljs-built_in">dict</span>:
        <span class="hljs-string">"""Generate cost report for period"""</span>
        usages = <span class="hljs-keyword">await</span> db.get_llm_usages(start_date, end_date)
        
        total_cost = <span class="hljs-built_in">sum</span>(<span class="hljs-variable language_">self</span>.calculate_cost(u) <span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> usages)
        
        <span class="hljs-comment"># Breakdown by operation</span>
        by_operation = {}
        <span class="hljs-keyword">for</span> usage <span class="hljs-keyword">in</span> usages:
            op = usage.operation
            <span class="hljs-keyword">if</span> op <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> by_operation:
                by_operation[op] = {<span class="hljs-string">"cost"</span>: <span class="hljs-number">0</span>, <span class="hljs-string">"calls"</span>: <span class="hljs-number">0</span>, <span class="hljs-string">"tokens"</span>: <span class="hljs-number">0</span>}
            
            by_operation[op][<span class="hljs-string">"cost"</span>] += <span class="hljs-variable language_">self</span>.calculate_cost(usage)
            by_operation[op][<span class="hljs-string">"calls"</span>] += <span class="hljs-number">1</span>
            by_operation[op][<span class="hljs-string">"tokens"</span>] += usage.input_tokens + usage.output_tokens
        
        <span class="hljs-keyword">return</span> {
            <span class="hljs-string">"period"</span>: {<span class="hljs-string">"start"</span>: start_date, <span class="hljs-string">"end"</span>: end_date},
            <span class="hljs-string">"total_cost"</span>: total_cost,
            <span class="hljs-string">"total_calls"</span>: <span class="hljs-built_in">len</span>(usages),
            <span class="hljs-string">"by_operation"</span>: by_operation,
            <span class="hljs-string">"avg_cost_per_call"</span>: total_cost / <span class="hljs-built_in">len</span>(usages) <span class="hljs-keyword">if</span> usages <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>
        }

<span class="hljs-comment"># Usage in monitoring</span>
cost_tracker = CostTracker()

<span class="hljs-comment"># After each LLM call</span>
llm_cost_usd.inc(cost_tracker.calculate_cost(usage))
</div></code></pre>
<hr>
<h2 id="12.-team-structure-%26-workflows" tabindex="-1">12. Team Structure &amp; Workflows</h2>
<h3 id="12.1-recommended-team" tabindex="-1">12.1 Recommended Team</h3>
<p><strong>Phase 1-3 (Months 1-4): Foundation</strong></p>
<ul>
<li>
<p><strong>1 GenAI Engineer</strong> (You) - Full-time</p>
<ul>
<li>Agent development</li>
<li>Prompt engineering</li>
<li>Evaluation framework</li>
<li>Infrastructure setup</li>
</ul>
</li>
<li>
<p><strong>0.5 Backend Engineer</strong> (Part-time support)</p>
<ul>
<li>API development</li>
<li>Data integration</li>
<li>Database design</li>
</ul>
</li>
<li>
<p><strong>0.25 Marketing Subject Matter Expert</strong> (Consultation)</p>
<ul>
<li>Requirements validation</li>
<li>Test case creation</li>
<li>Feedback on recommendations</li>
</ul>
</li>
</ul>
<p><strong>Phase 4-6 (Months 5-8): Production Launch</strong></p>
<ul>
<li><strong>1 GenAI Engineer</strong> - Full-time</li>
<li><strong>1 Backend Engineer</strong> - Full-time (API, integrations, scale)</li>
<li><strong>0.5 Frontend Engineer</strong> - Build review UI</li>
<li><strong>0.5 DevOps Engineer</strong> - Kubernetes, monitoring, CI/CD</li>
<li><strong>Marketing Team</strong> - Weekly feedback sessions</li>
</ul>
<p><strong>Phase 7+ (Months 9+): Optimization &amp; Scale</strong></p>
<ul>
<li><strong>1 GenAI Engineer</strong> - Improve reasoning, add features</li>
<li><strong>0.5 Backend Engineer</strong> - Maintenance, new integrations</li>
<li><strong>Marketing Team</strong> - Ongoing feedback loop</li>
</ul>
<h3 id="12.2-weekly-workflow" tabindex="-1">12.2 Weekly Workflow</h3>
<p><strong>Monday:</strong></p>
<ul>
<li>Review weekend metrics (acceptance rate, outcomes)</li>
<li>Triage any critical issues</li>
<li>Plan week's improvements</li>
</ul>
<p><strong>Tuesday-Thursday:</strong></p>
<ul>
<li>Development work</li>
<li>Prompt iteration based on feedback</li>
<li>Evaluation runs on every PR</li>
</ul>
<p><strong>Friday:</strong></p>
<ul>
<li>Marketing team feedback session (30-60 min)</li>
<li>Review flagged recommendations</li>
<li>Discuss failure cases</li>
<li>Identify patterns for improvement</li>
</ul>
<p><strong>Continuous:</strong></p>
<ul>
<li>Monitor dashboards</li>
<li>Respond to alerts</li>
<li>Document learnings</li>
</ul>
<h3 id="12.3-feedback-loop-process" tabindex="-1">12.3 Feedback Loop Process</h3>
<div class="mermaid">graph LR
    A[Agent Generates Recommendation] --&gt; B[Marketing Exec Reviews]
    B --&gt;|Approved| C[Execute Workflow]
    B --&gt;|Rejected| D[Record Feedback]
    C --&gt; E[Track Outcome]
    D --&gt; F[Analyze Disagreement]
    E --&gt; F
    F --&gt; G[Update Prompts/Logic]
    G --&gt; H[Re-evaluate on Golden Set]
    H --&gt;|Quality Improved| I[Deploy]
    H --&gt;|Not Better| J[Iterate]
    I --&gt; A
    J --&gt; G</div><p><strong>Feedback Categories:</strong></p>
<ol>
<li><strong>Correct Decision, Good Reasoning</strong> - Reinforcement learning</li>
<li><strong>Correct Decision, Poor Reasoning</strong> - Improve explanation clarity</li>
<li><strong>Wrong Decision, Understandable Why</strong> - Edge case, add to training</li>
<li><strong>Wrong Decision, Unclear Why</strong> - Investigate failure mode</li>
</ol>
<h3 id="12.4-cross-team-collaboration%3A-data-science-%26-mlops" tabindex="-1">12.4 Cross-Team Collaboration: Data Science &amp; MLOps</h3>
<p><strong>Context:</strong>
The data science team is building MLOps infrastructure for traditional ML models (predictive models, recommendation systems, etc.). As you establish GenAI patterns, there's significant overlap in operational concerns but also critical differences.</p>
<p><strong>Areas of Alignment (Leverage Shared Infrastructure):</strong></p>
<table>
<thead>
<tr>
<th>Component</th>
<th>Traditional ML</th>
<th>GenAI</th>
<th>Shared Approach</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Monitoring</strong></td>
<td>Prometheus, Grafana</td>
<td>Same + LangSmith</td>
<td>Share Prometheus/Grafana infrastructure, add GenAI-specific dashboards</td>
</tr>
<tr>
<td><strong>CI/CD</strong></td>
<td>GitHub Actions, testing</td>
<td>Same + LLM evaluation</td>
<td>Extend existing pipelines with evaluation gates</td>
</tr>
<tr>
<td><strong>Feature Stores</strong></td>
<td>Feast, Tecton</td>
<td>Context stores</td>
<td>Potentially share feature store for numerical features (CPA, CTR)</td>
</tr>
<tr>
<td><strong>Experiment Tracking</strong></td>
<td>MLflow</td>
<td>LangSmith + MLflow</td>
<td>Use MLflow for cost tracking, LangSmith for traces</td>
</tr>
<tr>
<td><strong>Data Quality</strong></td>
<td>Great Expectations</td>
<td>Same + prompt validation</td>
<td>Share data quality checks for campaign metrics</td>
</tr>
<tr>
<td><strong>Infrastructure</strong></td>
<td>Kubernetes, Docker</td>
<td>Same</td>
<td>Share K8s clusters with proper resource isolation</td>
</tr>
</tbody>
</table>
<p><strong>Areas of Divergence (GenAI-Specific Patterns):</strong></p>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>Traditional ML</th>
<th>GenAI</th>
<th>Why Different</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Evaluation</strong></td>
<td>Numeric metrics (RMSE, AUC)</td>
<td>LLM-as-judge, human feedback</td>
<td>GenAI outputs are natural language, require semantic evaluation</td>
</tr>
<tr>
<td><strong>Deployment</strong></td>
<td>Model versioning, A/B testing</td>
<td>Prompt versioning, structured outputs</td>
<td>Prompts change more frequently than trained models</td>
</tr>
<tr>
<td><strong>Latency</strong></td>
<td>&lt;100ms inference</td>
<td>~10-30s LLM calls</td>
<td>LLMs are slower; need async patterns</td>
</tr>
<tr>
<td><strong>Cost Model</strong></td>
<td>Fixed compute cost</td>
<td>Token-based pricing</td>
<td>GenAI has per-call variable costs</td>
</tr>
<tr>
<td><strong>Observability</strong></td>
<td>Model predictions, features</td>
<td>LLM traces, prompt-response pairs</td>
<td>Need to trace multi-step reasoning chains</td>
</tr>
<tr>
<td><strong>Feedback Loop</strong></td>
<td>Labeled data, retraining</td>
<td>Human approval, prompt iteration</td>
<td>GenAI improves via prompt engineering, not retraining</td>
</tr>
</tbody>
</table>
<p><strong>Collaboration Protocol:</strong></p>
<p><strong>Monthly Sync (1 hour):</strong></p>
<ul>
<li>Share learnings on monitoring patterns</li>
<li>Discuss infrastructure evolution (K8s, observability)</li>
<li>Identify opportunities for shared tooling</li>
<li>Review cost optimization strategies</li>
</ul>
<p><strong>Shared Documentation:</strong></p>
<ul>
<li>Maintain a <strong>PLATFORM_HANDBOOK.md</strong> covering:
<ul>
<li>Shared infrastructure (Kubernetes, Prometheus)</li>
<li>Deployment patterns</li>
<li>Incident response procedures</li>
<li>Cost management guidelines</li>
</ul>
</li>
</ul>
<p><strong>Divergent Documentation:</strong></p>
<ul>
<li>Your team: <strong>GenAI_PATTERNS.md</strong> covering:
<ul>
<li>Prompt engineering workflows</li>
<li>LLM evaluation methodologies</li>
<li>Human-in-the-loop patterns</li>
<li>Token cost optimization</li>
</ul>
</li>
<li>Their team: <strong>ML_PATTERNS.md</strong> covering:
<ul>
<li>Model training pipelines</li>
<li>Feature engineering</li>
<li>A/B testing frameworks</li>
</ul>
</li>
</ul>
<p><strong>Practical Integration Points:</strong></p>
<ol>
<li>
<p><strong>Shared Prometheus Metrics:</strong></p>
<pre class="hljs"><code><div><span class="hljs-comment"># Both ML and GenAI use same metric format</span>
<span class="hljs-keyword">from</span> prometheus_client <span class="hljs-keyword">import</span> Counter, Histogram

prediction_requests = Counter(
    <span class="hljs-string">'prediction_requests_total'</span>,
    <span class="hljs-string">'Total prediction requests'</span>,
    [<span class="hljs-string">'service'</span>, <span class="hljs-string">'model_type'</span>]  <span class="hljs-comment"># model_type: 'ml' or 'genai'</span>
)
</div></code></pre>
</li>
<li>
<p><strong>Shared Grafana Dashboards:</strong></p>
<ul>
<li>Top-level: System health (CPU, memory, requests/sec)</li>
<li>ML-specific: Model latency, prediction drift</li>
<li>GenAI-specific: LLM latency, token usage, recommendation acceptance</li>
</ul>
</li>
<li>
<p><strong>Shared GitHub Actions Base:</strong></p>
<pre class="hljs"><code><div><span class="hljs-comment"># .github/workflows/base-checks.yml (shared)</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Run</span> <span class="hljs-string">Security</span> <span class="hljs-string">Scan</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Check</span> <span class="hljs-string">Code</span> <span class="hljs-string">Quality</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Build</span> <span class="hljs-string">Docker</span> <span class="hljs-string">Image</span>

<span class="hljs-comment"># .github/workflows/ml-pipeline.yml (ML team)</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Run</span> <span class="hljs-string">Model</span> <span class="hljs-string">Tests</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Evaluate</span> <span class="hljs-string">on</span> <span class="hljs-string">Test</span> <span class="hljs-string">Set</span>

<span class="hljs-comment"># .github/workflows/genai-pipeline.yml (Your team)</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Run</span> <span class="hljs-string">LLM</span> <span class="hljs-string">Evaluation</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Test</span> <span class="hljs-string">Golden</span> <span class="hljs-string">Dataset</span>
</div></code></pre>
</li>
<li>
<p><strong>Example Collaboration: Campaign Metrics</strong></p>
<pre class="hljs"><code><div><span class="hljs-comment"># Shared: Data science team provides campaign features</span>
<span class="hljs-comment"># src/shared/features.py (maintained by DS team)</span>
<span class="hljs-keyword">class</span> <span class="hljs-title class_">CampaignFeatures</span>:
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_cpa_trend</span>(<span class="hljs-params">self, campaign_id: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">float</span>:
        <span class="hljs-string">"""Predictive model for CPA trend"""</span>
        <span class="hljs-comment"># ML model trained by data science team</span>
        
<span class="hljs-comment"># GenAI Usage: You consume these features</span>
<span class="hljs-comment"># src/agent/marketing_agent.py</span>
features = CampaignFeatures()
predicted_cpa = features.get_cpa_trend(campaign_id)

<span class="hljs-comment"># Use in agent prompt context</span>
context = <span class="hljs-string">f"Predicted CPA trend: <span class="hljs-subst">{predicted_cpa:<span class="hljs-number">.2</span>f}</span>"</span>
</div></code></pre>
</li>
</ol>
<p><strong>Decision Framework: When to Converge vs. Diverge</strong></p>
<p><strong>Use Shared Infrastructure When:</strong></p>
<ul>
<li>✅ It's a commodity (Kubernetes, Prometheus, Docker)</li>
<li>✅ No GenAI-specific requirements</li>
<li>✅ Reduces operational overhead</li>
<li>✅ Enables cross-team knowledge sharing</li>
</ul>
<p><strong>Build Separate When:</strong></p>
<ul>
<li>✅ GenAI has unique requirements (LLM tracing, prompt versioning)</li>
<li>✅ Iteration speed matters (don't block on other team)</li>
<li>✅ Cost/complexity of integration &gt; cost of duplication</li>
</ul>
<p><strong>Key Principle:</strong> <em>"Share infrastructure, diverge on workflows."</em></p>
<h3 id="12.5-communication-channels" tabindex="-1">12.5 Communication Channels</h3>
<p><strong>Internal:</strong></p>
<ul>
<li><strong>Slack Channel</strong> <code>#marketing-agent</code> - Daily updates, questions</li>
<li><strong>Slack Channel</strong> <code>#ml-platform</code> - Cross-team collaboration with data science</li>
<li><strong>Weekly Sync</strong> - 30 min with marketing team</li>
<li><strong>Monthly MLOps Sync</strong> - 1 hour with data science team</li>
<li><strong>Monthly Review</strong> - Stakeholder presentation on progress</li>
</ul>
<p><strong>Documentation:</strong></p>
<ul>
<li><strong>README</strong> - Setup instructions</li>
<li><strong>Architecture Decision Records (ADRs)</strong> - Key design choices</li>
<li><strong>Prompt Changelog</strong> - Version history with performance impact</li>
<li><strong>Runbook</strong> - Incident response procedures</li>
<li><strong>PLATFORM_HANDBOOK.md</strong> - Shared infrastructure guide (co-maintained with DS team)</li>
</ul>
<p><strong>External (Optional):</strong></p>
<ul>
<li><strong>Blog Posts</strong> - Share learnings (with data anonymized)</li>
<li><strong>Conference Talks</strong> - GenAI in production</li>
</ul>
<hr>
<h2 id="appendices" tabindex="-1">Appendices</h2>
<h3 id="appendix-a%3A-glossary" tabindex="-1">Appendix A: Glossary</h3>
<p><strong>Agent</strong>: AI system that can reason and take actions autonomously
<strong>Workflow</strong>: Predefined sequence of operations (less flexible than agent)
<strong>LangGraph</strong>: Framework for building stateful, multi-step AI workflows
<strong>LangSmith</strong>: Observability platform for LLM applications
<strong>Golden Dataset</strong>: Curated test cases with known correct answers
<strong>LLM-as-Judge</strong>: Using an LLM to evaluate another LLM's outputs
<strong>Prompt Engineering</strong>: Crafting instructions for LLMs to perform tasks
<strong>Human-in-the-Loop (HITL)</strong>: System that requires human approval/input
<strong>Graduated Autonomy</strong>: Slowly reducing human oversight as trust builds
<strong>Confidence Calibration</strong>: Ensuring confidence scores match actual accuracy</p>
<h3 id="appendix-b%3A-risk-mitigation" tabindex="-1">Appendix B: Risk Mitigation</h3>
<table>
<thead>
<tr>
<th>Risk</th>
<th>Likelihood</th>
<th>Impact</th>
<th>Mitigation</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Poor recommendation quality</strong></td>
<td>Medium</td>
<td>High</td>
<td>- Extensive evaluation before launch<br>- Human approval for all recs initially<br>- Clear acceptance threshold (70%)</td>
</tr>
<tr>
<td><strong>LLM API downtime</strong></td>
<td>Low</td>
<td>Medium</td>
<td>- Fallback to rule-based system<br>- Retry logic with exponential backoff<br>- Circuit breaker pattern</td>
</tr>
<tr>
<td><strong>Cost overruns</strong></td>
<td>Medium</td>
<td>Low</td>
<td>- Budget alerts ($100/day limit)<br>- Model selection by complexity<br>- Response caching</td>
</tr>
<tr>
<td><strong>Data quality issues</strong></td>
<td>Medium</td>
<td>Medium</td>
<td>- Validation on all collector outputs<br>- Graceful degradation with partial data<br>- Health checks on collectors</td>
</tr>
<tr>
<td><strong>Marketing team rejection</strong></td>
<td>Low</td>
<td>High</td>
<td>- Early and continuous involvement<br>- Weekly feedback sessions<br>- Iterate based on their input</td>
</tr>
<tr>
<td><strong>Prompt injection/manipulation</strong></td>
<td>Low</td>
<td>Low</td>
<td>- Input sanitization<br>- Output validation<br>- Audit logging</td>
</tr>
</tbody>
</table>
<h3 id="appendix-c%3A-success-metrics-checklist" tabindex="-1">Appendix C: Success Metrics Checklist</h3>
<p><strong>Month 1-2: Foundation</strong></p>
<ul>
<li><input type="checkbox" id="checkbox52"><label for="checkbox52">Dev environment working</label></li>
<li><input type="checkbox" id="checkbox53"><label for="checkbox53">Data collectors functional</label></li>
<li><input type="checkbox" id="checkbox54"><label for="checkbox54">First recommendation generated</label></li>
<li><input type="checkbox" id="checkbox55"><label for="checkbox55">5 golden test cases created</label></li>
</ul>
<p><strong>Month 3-4: MVP</strong></p>
<ul>
<li><input type="checkbox" id="checkbox56"><label for="checkbox56">Agent matches human decision &gt;50% on golden set</label></li>
<li><input type="checkbox" id="checkbox57"><label for="checkbox57">&lt;30s latency consistently</label></li>
<li><input type="checkbox" id="checkbox58"><label for="checkbox58">Reasoning is explainable</label></li>
<li><input type="checkbox" id="checkbox59"><label for="checkbox59">Evaluation runs automatically</label></li>
</ul>
<p><strong>Month 5-6: Launch</strong></p>
<ul>
<li><input type="checkbox" id="checkbox60"><label for="checkbox60">UI deployed</label></li>
<li><input type="checkbox" id="checkbox61"><label for="checkbox61">Marketing team trained</label></li>
<li><input type="checkbox" id="checkbox62"><label for="checkbox62">20+ real recommendations generated</label></li>
<li><input type="checkbox" id="checkbox63"><label for="checkbox63">Acceptance rate &gt;60%</label></li>
<li><input type="checkbox" id="checkbox64"><label for="checkbox64">Monitoring dashboards live</label></li>
</ul>
<p><strong>Month 7-8: Optimization</strong></p>
<ul>
<li><input type="checkbox" id="checkbox65"><label for="checkbox65">Acceptance rate &gt;70%</label></li>
<li><input type="checkbox" id="checkbox66"><label for="checkbox66">Positive impact &gt;80% when followed</label></li>
<li><input type="checkbox" id="checkbox67"><label for="checkbox67">Cost &lt;$500/month</label></li>
<li><input type="checkbox" id="checkbox68"><label for="checkbox68">Weekly iterations deployed</label></li>
</ul>
<p><strong>Month 9+: Trust Building</strong></p>
<ul>
<li><input type="checkbox" id="checkbox69"><label for="checkbox69">First graduated autonomy scenario identified</label></li>
<li><input type="checkbox" id="checkbox70"><label for="checkbox70">100+ recommendations with outcomes tracked</label></li>
<li><input type="checkbox" id="checkbox71"><label for="checkbox71">Agreement with experts &gt;75%</label></li>
<li><input type="checkbox" id="checkbox72"><label for="checkbox72">Plan for next GenAI application</label></li>
</ul>
<h3 id="appendix-d%3A-reference-architecture-diagram" tabindex="-1">Appendix D: Reference Architecture Diagram</h3>
<p>[See full Mermaid diagram above]</p>
<h3 id="appendix-e%3A-prompt-templates-repository-structure" tabindex="-1">Appendix E: Prompt Templates Repository Structure</h3>
<pre class="hljs"><code><div>prompts/
├── signal_analysis/
│   ├── v1.yaml        # Initial version
│   ├── v2.yaml        # Improved based on feedback
│   ├── v3.yaml        # Added few-shot examples
│   └── latest.yaml -&gt; v3.yaml
├── recommendation_generation/
│   ├── v1.yaml
│   └── latest.yaml -&gt; v1.yaml
├── critique/
│   ├── v1.yaml
│   └── latest.yaml -&gt; v1.yaml
└── README.md          # Changelog and versioning guide
</div></code></pre>
<h3 id="appendix-f%3A-further-reading" tabindex="-1">Appendix F: Further Reading</h3>
<p><strong>AI Agent Patterns:</strong></p>
<ul>
<li><a href="https://www.anthropic.com/research/building-effective-agents">Building Effective Agents - Anthropic</a></li>
<li><a href="https://docs.langchain.com/oss/python/langgraph/overview">LangGraph Documentation</a></li>
</ul>
<p><strong>Evaluation:</strong></p>
<ul>
<li><a href="https://docs.langchain.com/langsmith/evaluation">LangSmith Evaluation Guide</a></li>
<li><a href="https://www.promptfoo.dev/docs/intro/">promptfoo Documentation</a></li>
</ul>
<p><strong>Production GenAI:</strong></p>
<ul>
<li><a href="https://platform.openai.com/docs/guides/production-best-practices">GenAI Engineering Best Practices - OpenAI</a></li>
<li><a href="https://www.promptingguide.ai/">Prompt Engineering Guide</a></li>
</ul>
<p><strong>MLOps:</strong></p>
<ul>
<li><a href="https://huyenchip.com/2023/04/11/llm-engineering.html">Building LLM Applications for Production - Chip Huyen</a></li>
</ul>
<hr>
<h2 id="13.-future-roadmap-%26-next-applications" tabindex="-1">13. Future Roadmap &amp; Next Applications</h2>
<h3 id="13.1-post-launch-strategy" tabindex="-1">13.1 Post-Launch Strategy</h3>
<p><strong>Context:</strong>
Once the marketing agent is deployed and stable, you'll identify the next high-value GenAI application together with the business. We're not starting with a five-year roadmap because the best next problem will emerge from how the business actually uses the agent.</p>
<p><strong>Guiding Principles:</strong></p>
<ol>
<li>
<p><strong>Learn from Production:</strong></p>
<ul>
<li>What works: Which reasoning patterns are most reliable?</li>
<li>What's missing: Where does the agent still need human intervention?</li>
<li>Where GenAI creates leverage: Which tasks benefit most from AI assistance?</li>
</ul>
</li>
<li>
<p><strong>Separate Signal from Noise:</strong></p>
<ul>
<li>Not every problem needs GenAI</li>
<li>Focus on problems with:
<ul>
<li>✅ High context complexity (many data sources to synthesize)</li>
<li>✅ Reasoning requirements (not just pattern matching)</li>
<li>✅ Contained blast radius (failures are recoverable)</li>
<li>✅ Human verification possible (can validate outputs)</li>
<li>✅ Clear evaluation criteria (can measure quality)</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Build on Foundations:</strong></p>
<ul>
<li>Reuse evaluation frameworks</li>
<li>Extend monitoring infrastructure</li>
<li>Leverage learned patterns (prompt engineering, human-in-the-loop)</li>
</ul>
</li>
</ol>
<h3 id="13.2-candidate-next-applications" tabindex="-1">13.2 Candidate Next Applications</h3>
<p><strong>These are speculation</strong> - the actual choice depends on production learnings. Examples:</p>
<p><strong>1. Creative Performance Predictor</strong></p>
<ul>
<li><strong>Problem:</strong> Marketing team creates multiple ad variants, unsure which will perform</li>
<li><strong>GenAI Solution:</strong> Analyze creative elements (copy tone, visuals, CTA) + historical performance → predict which variants will succeed</li>
<li><strong>Why Later:</strong> Builds on marketing agent's campaign knowledge</li>
<li><strong>Evaluation:</strong> Predicted vs. actual performance correlation</li>
</ul>
<p><strong>2. Competitive Intelligence Summarizer</strong></p>
<ul>
<li><strong>Problem:</strong> Manual monitoring of competitor campaigns across platforms</li>
<li><strong>GenAI Solution:</strong> Aggregate competitor data → generate weekly strategic summary with actionable insights</li>
<li><strong>Why Later:</strong> Extends competitor analysis from marketing agent</li>
<li><strong>Evaluation:</strong> Marketing team finds insights actionable</li>
</ul>
<p><strong>3. Campaign Briefing Assistant</strong></p>
<ul>
<li><strong>Problem:</strong> Creating campaign briefs requires synthesizing brand guidelines, past performance, market insights</li>
<li><strong>GenAI Solution:</strong> Generate first-draft campaign brief from minimal input</li>
<li><strong>Why Later:</strong> Upstream of campaign execution (where agent currently operates)</li>
<li><strong>Evaluation:</strong> Draft quality, time saved</li>
</ul>
<p><strong>4. Multi-Channel Attribution Explainer</strong></p>
<ul>
<li><strong>Problem:</strong> Attribution models are black boxes to marketing team</li>
<li><strong>GenAI Solution:</strong> Explain attribution decisions in plain language with supporting evidence</li>
<li><strong>Why Later:</strong> Builds trust in data-driven decisions</li>
<li><strong>Evaluation:</strong> Understanding improvement, decision confidence</li>
</ul>
<h3 id="13.3-discovery-process" tabindex="-1">13.3 Discovery Process</h3>
<p><strong>Months 6-9: Production Stabilization + Discovery</strong></p>
<p><strong>Weekly Discovery Questions:</strong></p>
<ul>
<li>Where is the marketing team still spending significant manual time?</li>
<li>What decisions are they making that could benefit from AI reasoning?</li>
<li>What feedback are they giving about the agent's gaps?</li>
<li>What adjacent problems are they asking about?</li>
</ul>
<p><strong>Monthly Review:</strong></p>
<ul>
<li>Track time savings from current agent</li>
<li>Identify 2-3 candidate next problems</li>
<li>Rough scope each (complexity, value, fit for GenAI)</li>
</ul>
<p><strong>Quarter-End Decision:</strong></p>
<ul>
<li>Select next application based on:
<ul>
<li>Business value (time saved, revenue impact)</li>
<li>Technical feasibility (data available, evaluation possible)</li>
<li>Strategic fit (builds on existing capabilities)</li>
<li>Team readiness (lessons from first agent applied)</li>
</ul>
</li>
</ul>
<h3 id="13.4-scaling-genai-capabilities" tabindex="-1">13.4 Scaling GenAI Capabilities</h3>
<p><strong>As Additional Applications are Built:</strong></p>
<p><strong>Shared Components:</strong></p>
<pre class="hljs"><code><div>genai-platform/
├── core/
│   ├── llm_clients/          # Reusable LLM wrappers
│   ├── evaluation/           # Shared eval framework
│   ├── monitoring/           # Common observability
│   └── cost_tracking/        # Unified cost management
├── applications/
│   ├── marketing_agent/      # First application (this project)
│   ├── creative_predictor/   # Future application #2
│   └── competitive_intel/    # Future application #3
└── infrastructure/
    ├── kubernetes/           # Shared deployment configs
    ├── ci_cd/                # Reusable pipelines
    └── monitoring/           # Grafana dashboards
</div></code></pre>
<p><strong>Platform Team Evolution:</strong></p>
<ul>
<li><strong>Months 1-6:</strong> You own everything for marketing agent</li>
<li><strong>Months 7-12:</strong> Extract shared components as you build application #2</li>
<li><strong>Year 2+:</strong> Potentially grow to 2-3 person GenAI team owning platform + applications</li>
</ul>
<h3 id="13.5-success-criteria-for-platform-maturity" tabindex="-1">13.5 Success Criteria for Platform Maturity</h3>
<p><strong>Phase 1: Single Application (Months 1-6)</strong></p>
<ul>
<li>✅ Marketing agent in production</li>
<li>✅ Evaluation framework established</li>
<li>✅ Monitoring and CI/CD patterns proven</li>
</ul>
<p><strong>Phase 2: Platform Emergence (Months 7-12)</strong></p>
<ul>
<li>✅ Second application using shared components</li>
<li>✅ Reusable evaluation framework</li>
<li>✅ Documented GenAI patterns</li>
<li>✅ Cost per application decreasing (leverage shared infra)</li>
</ul>
<p><strong>Phase 3: Scaled Platform (Year 2+)</strong></p>
<ul>
<li>✅ 3+ applications in production</li>
<li>✅ Self-service GenAI toolkit for other teams</li>
<li>✅ Proven ROI on GenAI investment</li>
<li>✅ Clear decision framework: when to use GenAI vs. traditional ML vs. rules</li>
</ul>
<h3 id="13.6-what-we're-not-doing" tabindex="-1">13.6 What We're NOT Doing</h3>
<p><strong>Avoiding Common Pitfalls:</strong></p>
<p>❌ <strong>Building GenAI for Everything</strong></p>
<ul>
<li>Not every problem needs an LLM</li>
<li>Traditional ML, rules engines, and human processes still have their place</li>
</ul>
<p>❌ <strong>Five-Year Roadmap Upfront</strong></p>
<ul>
<li>Technology evolves too quickly</li>
<li>Business needs change based on actual usage</li>
<li>Better to earn the roadmap through shipping</li>
</ul>
<p>❌ <strong>Autonomous Agents Without Guardrails</strong></p>
<ul>
<li>Marketing agent has human approval for good reason</li>
<li>Future applications should have similar safety mechanisms</li>
<li>Trust is earned gradually, not assumed</li>
</ul>
<p>❌ <strong>Optimizing Prematurely</strong></p>
<ul>
<li>First agent focuses on quality, not cost</li>
<li>Optimization happens once patterns are proven</li>
<li>Don't sacrifice reliability for marginal cost savings</li>
</ul>
<h3 id="13.7-long-term-vision" tabindex="-1">13.7 Long-Term Vision</h3>
<p><strong>What Success Looks Like in 2 Years:</strong></p>
<ol>
<li><strong>Marketing Agent:</strong> Fully automated with 80%+ acceptance rate, minimal human oversight</li>
<li><strong>GenAI Platform:</strong> Reusable components enabling rapid new application development</li>
<li><strong>Team Capability:</strong> 2-3 GenAI engineers owning multiple production applications</li>
<li><strong>Business Impact:</strong> Measurable ROI through time savings, decision quality, efficiency gains</li>
<li><strong>Cultural Shift:</strong> Marketing team trusts AI recommendations, uses GenAI as a thought partner</li>
</ol>
<p><strong>Commitment:</strong>
We're establishing GenAI capabilities properly - the specific roadmap will be earned through shipping and learning. Focus is on systematic progress, quality, and building trust.</p>
<hr>
<h2 id="conclusion" tabindex="-1">Conclusion</h2>
<p>This implementation guide provides a complete blueprint for building a production-grade Marketing Reasoning Agent. Key takeaways:</p>
<ol>
<li><strong>Start Simple</strong>: Workflow-based architecture, not fully autonomous agent</li>
<li><strong>Evaluation-Driven</strong>: Build golden dataset, measure systematically</li>
<li><strong>Human Trust</strong>: Human-in-the-loop initially, graduate to autonomy</li>
<li><strong>Production-Grade</strong>: Monitoring, CI/CD, and evaluation from day one</li>
<li><strong>Iterative</strong>: Weekly improvements based on real feedback</li>
<li><strong>Platform Thinking</strong>: Build for today's needs, design for tomorrow's scale</li>
</ol>
<p>The first 3-6 months focus on establishing quality foundations. Production deployment happens when the agent proves reliable through systematic evaluation, not because of arbitrary deadlines.</p>
<p>Success is measured by:</p>
<ul>
<li>Recommendation acceptance rate &gt;70%</li>
<li>Positive impact when followed &gt;80%</li>
<li>Marketing team trust and adoption</li>
<li>Systematic, measurable progress</li>
<li>Foundations for future GenAI applications</li>
</ul>
<p>This is a marathon, not a sprint. Build trust through consistent, reliable recommendations. The roadmap will evolve based on what actually works in production - signal over noise, quality over speed.</p>
<p><strong>Immediate Next Steps:</strong></p>
<ol>
<li>Review this document with stakeholders</li>
<li>Set up development environment (Week 1)</li>
<li>Start data integration (Week 2-3)</li>
<li>First recommendation generation (Week 4)</li>
<li>Weekly marketing team sync (ongoing)</li>
</ol>
<p><strong>Long-Term Vision:</strong></p>
<ul>
<li>Marketing agent deployed and stable</li>
<li>Discover next high-value application from production learnings</li>
<li>Build GenAI platform capabilities through systematic iteration</li>
<li>Establish patterns that work together with traditional ML (data science team)</li>
<li>Create genuine business leverage through intelligent automation</li>
</ul>
<p>Good luck building! 🚀</p>
<hr>
<p><strong>Document Version</strong>: 1.0<br>
<strong>Last Updated</strong>: February 11, 2026<br>
<strong>Maintained By</strong>: GenAI Engineering Team<br>
<strong>Next Review</strong>: March 2026</p>

    </div>



    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    </body></html>